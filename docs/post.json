[
    
        
            {
                "ref": "https://blog.dakatsuka.jp/2021/01/10/ocaml-binding-operators.html",
                "title": "OCaml 4.08.0から使えるBinding operatorsが便利だった",
                "section": "post",
                "date" : "2021.01.10",
                "body": "OCaml 4.08.0 で Binding operators 1 という機能が導入されていました。これでOCamlでもHaskellのdo記法やScalaのfor式に近いかたちでモナディックな計算が可能になります。\n4.08.0は結構前に出ているので今更感はありますが\u0026hellip; 普段触っていないのがバレてしまう！\nオプションモナドは以下のように書くことができます。\n(* int -\u0026gt; int -\u0026gt; int option *) let div x y = try Some (x / y) with Division_by_zero -\u0026gt; None (* binding operators を定義 *) let ( let* ) x f = Option.bind x f let result = let* r1 = div 100 2 in let* r2 = div r1 10 in let* r3 = div r2 0 in (* None *) Some (r3 + 10) in match result with | Some _ -\u0026gt; \u0026#34;\u0026#34; | None -\u0026gt; \u0026#34;上のコードだとr3の計算結果はNoneになるのでr3 + 10は実行されない\u0026#34; モナドごとにモジュールを作ってローカルオープンするのが可読性も高くなり良さそうです。\nmodule Option_ops = struct let ( let* ) x f = Option.bind x f let return = Option.some end let result = let open Option_ops in let* r1 = div 100 2 in let* r2 = div r1 10 in let* r3 = div r2 0 in return (r3 + 10) ちなみに let* 以外にも let+ や and+ なども定義出来ます。使用できる記号はドキュメント2 を参照してください。\n応用編 Binding operators は自分で定義しなければいけないという若干の面倒臭さがある反面、異なるモナドがネストしているような値に対しても柔軟に対応することができます。\n例えば下記のように任意の型を内包できる Io 型があり、その中に Result 型が入っているケースです。IOは非同期処理の成功・失敗を表現し、Resultはビジネスロジックの成功・失敗を表現するような使い方ですね。\n(* オレオレIO型 *) module Io : sig type (\u0026#39;a, \u0026#39;e) t = Success of \u0026#39;a | Failure of \u0026#39;e val bind : (\u0026#39;a, \u0026#39;b) t -\u0026gt; (\u0026#39;a -\u0026gt; (\u0026#39;c, \u0026#39;b) t) -\u0026gt; (\u0026#39;c, \u0026#39;b) t end = struct type (\u0026#39;a, \u0026#39;e) t = Success of \u0026#39;a | Failure of \u0026#39;e let bind io f = match io with Success v -\u0026gt; f v | Failure _ as e -\u0026gt; e end 次のように実装すると Io.Success 且つ Result.Ok のときだけ値を取り出して後続に処理を渡していくことができます。\nmodule Io_result_ops = struct let ( let* ) x f = match x with | Io.Success (Ok v) -\u0026gt; f v | Io.Success (Error _ as e) -\u0026gt; Io.Success e | _ as e -\u0026gt; e let return x = Io.Success (Ok x) end let result = let open Io_result_ops in let* io1 = Io.Success (Ok 10) in let* io2 = Io.Success (Ok (io1 * 10)) in let* io3 = Io.Success (Ok (io2 * 10)) in let* io4 = Io.Success (Ok (io3 * 10)) in return io4;; (* val result : ((int, \u0026#39;a) result, \u0026#39;b) Io.t = Io.Success (Ok 10000) *) let result = let open Io_result_ops in let* io1 = Io.Success (Ok 10) in let* io2 = Io.Failure (\u0026#34;Internal Server Error\u0026#34;) in let* io3 = Io.Success (Ok (io2 * 10)) in let* io4 = Io.Success (Ok (io3 * 10)) in return io4;; (* val result : ((int, \u0026#39;a) result, string) Io.t = Io.Failure \u0026#34;Internal Server Error\u0026#34; *) let result = let open Io_result_ops in let* io1 = Io.Success (Ok 10) in let* io2 = Io.Success (Error(-1)) in let* io3 = Io.Success (Ok (io2 * 10)) in let* io4 = Io.Success (Ok (io3 * 10)) in return io4;; (* val result : ((int, int) result, \u0026#39;a) Io.t = Io.Success (Error (-1)) *) こういうとき、ScalaやHaskellなどはモナドトランスフォーマーを使いますがOcamlのBinding operatorsでも似たようなことは出来ますよというお話でした。\n  8.23 Binding operators \u0026#x21a9;\u0026#xfe0e;\n core-operator-char \u0026#x21a9;\u0026#xfe0e;\n   "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2020/12/10/hugo.html",
                "title": "Migrate to Hugo",
                "section": "post",
                "date" : "2020.12.10",
                "body": "このブログで使っている静的サイトジェネレーターをMiddlemanからHugoに移行しました。また、良い機会だったのでホスティングサービスもGitHub Pagesに引っ越しをしました。\nMiddlemanからHugoへの移行作業について特にあれこれと語ることはないのですが、強いて言うなら、各記事のパーマリンクを変えたくなかったのでUglyURLsオプションを有効にしたところ、これに対応してるテーマが全然なくて地味に苦戦を強いられたくらいですかね。\nこのブログで使うことにしたHarborというテーマもうまく動かなかったのですが、ちょっとの手直しで対応できることが分かったのでPRを出しました。無事マージもされたので、もし既存のブログのURLが*.html終わりになっていてそのまま移行したい人がいたら参考になると思います。\nそれにしても3年間もブログを放置してしまいました。また少しずつ更新を再開していくつもりですが、全然ネタがないので果たしてどうなるやら。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2017/02/18/akka-http-onsuccess-magnet.html",
                "title": "The Magnet PatternでAkka HTTPのonSuccessで処理できる型を増やす",
                "section": "post",
                "date" : "2017.02.18",
                "body": "onSuccessはThe Magnet Patternで実装されているのでOnSuccessMagnet型クラスのインスタンスさえ定義してしまえば割りと何でも受け取ることができる。型がM[Future[A]]になっているオブジェクトをそのままonSuccessに渡したくなった時のために覚えておくと良いかもしれない。\n例えば、次のコードでDirective[Tuple1[Future[A]]]に対応することが可能。\nimplicit def directiveIncludingFuture[T](futureDirective: Directive[Tuple1[Future[T]]])(implicit tupler: Tupler[T]): OnSuccessMagnet { type Out = tupler.Out } = { new OnSuccessMagnet { type Out = tupler.Out val directive: Directive[Out] = futureDirective.flatMap { future =\u0026gt; Directive[tupler.Out] { inner =\u0026gt; ctx =\u0026gt; import ctx.executionContext future.fast.flatMap(t =\u0026gt; inner(tupler(t))(ctx)) }(tupler.OutIsTuple) }(tupler.OutIsTuple) } } Directive[Tuple1[Future[A]]]なんてそう滅多に出てこないでしょ…と思いきや複数のDirective1から取得した値を非同期で処理するというシチュエーションはそれなりにあるかもしれない。\nこんな感じのやつ。\nval result = for { value1 \u0026lt;- directive1 value2 \u0026lt;- directive2 } yield hogeAsyncRepository.findBy(value1, value2) // resultの型は Directive[Tuple1[Future[Option[A]]]] になる  onSuccess(result) { case Some(_) =\u0026gt; complete(OK) case None =\u0026gt; complete(NotFound) } "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2017/02/04/akka-http-directive.html",
                "title": "Akka HTTPのDirective0の使い勝手が良くないのでどうにかする話",
                "section": "post",
                "date" : "2017.02.04",
                "body": "まずDirective0とDirective1の型定義を見て欲しい。\ntype Directive0 = Directive[Unit] type Directive1[T] = Directive[Tuple1[T]] Directive0がDirective1[Unit]であればそこまで問題なかったのだが、このように型パラメータはUnitとTuple1[T]となっている。なぜこのような定義になっているのかは正確には分からないけど、おそらくDSLとしての使い勝手を優先したのだと思う。directive0 { _ =\u0026gt; ... } よりは directive0 { } と書けたほうが良い的な。\nまたDirective1にはimplicit conversionでmapとflatMapが実装されているのでfor式で扱うことができるが、Directive0にはその2つのメソッドは存在しない（代わりにtmapとtflatMapはある）つまり両方を同時にfor式で処理することができないという問題が発生する。\n次のようなコードは動かない。\nfor { value1 \u0026lt;- directive1A _ \u0026lt;- directive0A value2 \u0026lt;- directive1B } yield (value1, value2) Directive0はそんなに利用頻度は高くないのだけど、バリデーションや認可など値を返さずに処理を通すか通さないかだけを判断するところでは使うので、これではちょっと困る。Akka HTTP的にはfor式など使わずにひたすらネストさせていくのを推奨しているのかもしれないけど。。。でもfor式も使いたい！\nというわけでimplicit conversionでDirective0にmapとflatMapを生やす。ついでにDirective1[Unit]としても振る舞えるように型変換もしておく。\nimplicit class Directive0ForComprehensionSupport(directive0: Directive0) { def map[T](f: Unit =\u0026gt; T): Directive1[T] = directive0.tmap(f) def flatMap[T](f: Unit =\u0026gt; Directive1[T]): Directive1[T] = directive0.tflatMap(f) } implicit def directive0ToDirective1(directive0: Directive0): Directive1[Unit] = directive0.tflatMap(provide) ちょっとワークアラウンドっぽいやり方だけどやりたい事は実現できる。ご利用は計画的に👻\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2017/01/03/asset-allocation-2016.html",
                "title": "2016年12月末の資産分配",
                "section": "post",
                "date" : "2017.01.03",
                "body": "実は数年前から細々とインデックス投資を実践している。その前は個別銘柄（日本株式の現物）を買い漁ってスイングトレードをして、まぁ程々に利益は出せていたのだけど、仕事中に株価が気にならないかと言われると嘘になる。精神衛生上良くないし、そもそもあぶく銭を得るためにやってる訳でも無かったので、毎月淡々と積立ができるインデックス投資のほうが自分には合っていた。\nわたしの場合、インデックス投資のセオリーに則り、日本株式、先進国株式、新興国株式、日本債権、外国債権、REITに分散投資するスタイルにしている。年に2回程度、比率を確認してリバランスを行っているので、せっかくだしブログに結果を残しておこうと思う。\n当然ですが、投資は自己責任です。あまり他人のは参考にしないほうが良いと思われます。\n2016年12月末 資産分配（アセットアロケーション）   2016年12月末 資産分配   アメリカ大統領選挙の影響で日本株式と先進国株式が後半にかけて伸び、日本債権が30%を切ってしまった。個人的には日本債権の比率=年齢くらいにしておきたいので、リバランスを計画中。2017年は国外の政治経済が流動的になりそうだけど、焦らずにまったりやっていく。\n現在積立中の商品\n 日本株式インデックスｅ 外国株式インデックスｅ ｅＭＡＸＩＳ　新興国株式インデックス 日本債券インデックスｅ 外国債券インデックスｅ ｅＭＡＸＩＳ　国内リートインデックス ニッセイグローバルリートインデックスＦ  2016年12月末 資産内訳   2016年12月末 資産内訳   貯蓄全てをインデックス投資に突っ込んでいるかというとそうではなく、現預金も一応それなりに確保している。去年はカメラや洗濯機を買って現金を減らしてしまったので、今年は自重して現金も増やしておきたい。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2017/01/01/bought-in-2016.html",
                "title": "2016年に買ってよかったもの",
                "section": "post",
                "date" : "2017.01.01",
                "body": "あけましておめでとうございます。去年のうちに書くのをすっかり忘れていましたが、流行り？に乗って買ってよかったものをまとめておきます。あまり人にすすめられるものではないので完全にチラシの裏という感じです。\n書いてて気付いたのだけど散財しすぎなので今年は節約を心がける所存。\nCanon EOS M2とFUJIFILM X-E2とRICOH GRを持っていたのだけど、当然のようにそんなに持っていても使いこなせるわけがなかった。そこでFUJINONレンズを残して全て売却。2月に新発売したFUJIFILM X-Pro2を購入して一本化しました。\n旅行が好きなので旅先で写真をたくさん撮ったりして活躍中。2016年後半は仕事が忙しくて防湿庫で眠りっぱなしになっていたので、もう少し稼働率を上げたいところ。\nX-Pro2買ってしばらくしてから購入。元々XF35mm F1.4のほうを持っていたけどこの小ささに惹かれた。見た目的にもX-Pro2にとても似合う。\n我が家の洗濯事情に革命が起きた。結婚した時に買った洗濯機が壊れたので仕方なく買い替えという感じなのだけど、もっと早く買い替えておけば良かったと後悔。これは便利だ。\n会社で薦められて半ば衝動買いした。会社内でも自分と同じように衝動買いした人が数名いるくらいには評判が良い。音質面では今一歩と感じるとこはあるけれど、仕事に集中したい時や新幹線、飛行機などでゆっくり音楽を聞きたいという人には最高なアイテムだと思う。\nもともと会社に置いてあったものが壊れたので同じ機種を再度買った。よく投げるメンバーで出し合って買ったので共同所有って感じだけど、ScalaのコンパイルやCI待ってる間の微妙な時間を潰すのに最適です。身体を動かすとまではいかないけど、席を立つので足腰や血流にも良くて頭もリフレッシュするので個人的には◎\n映画「オデッセイ」の原作。すらすら読めるので映画を観た人も観ていない人にもおすすめ。とか言っておいて自分は映画観てないですが。。。\n少年の青春時代、主に夏休みの出来事が書かれた短編小説…という体をしたミステリー小説です。\nポケモンは安定して面白い。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2016/12/05/akka-http-authentication.html",
                "title": "Akka HTTPで認証機能を手軽に実装する方法",
                "section": "post",
                "date" : "2016.12.05",
                "body": "これはScala Advent Calendar 2016の5日目です。埋まっていなかったので1日遅れでしれっと書くよ。\nAkka HTTPには AuthenticationDirective という認証のためのディレクティブが標準で用意されていて、Bearer Token を自前で認証したいケースで使える。使いかたはコードを見たほうが分かりやすいと思うのでサンプルを乗せた。\nimport akka.actor.ActorSystem import akka.http.scaladsl.Http import akka.http.scaladsl.model.headers.{HttpChallenge, OAuth2BearerToken} import akka.http.scaladsl.server.directives.{AuthenticationDirective, AuthenticationResult} import akka.http.scaladsl.server.Directives._ import akka.stream.ActorMaterializer import scala.concurrent.Future case class Account(name: String) object Main extends App { implicit val system = ActorSystem() implicit val materializer = ActorMaterializer() val route = pathEndOrSingleSlash { authenticate { account =\u0026gt; complete(account.name) } } Http().bindAndHandle(route, \u0026#34;\u0026#34;, 8080) private def authenticate: AuthenticationDirective[Account] = { authenticateOrRejectWithChallenge[OAuth2BearerToken, Account] { case Some(OAuth2BearerToken(token)) if token == \u0026#34;123456789\u0026#34; =\u0026gt; Future.successful(AuthenticationResult.success(Account(\u0026#34;user\u0026#34;))) case _ =\u0026gt; Future.successful(AuthenticationResult.failWithChallenge( HttpChallenge(\u0026#34;bearer\u0026#34;, None, Map(\u0026#34;error\u0026#34; -\u0026gt; \u0026#34;invalid_token\u0026#34;))) ) } } } sbt run して curl で動作確認をしてみる。正しいトークンでアクセスすると complete(account.name) が実行されることが確認できる。\n$ curl -H \u0026quot;Authorization: Bearer 123456789\u0026quot; --dump-header - http://localhost:8080/ HTTP/1.1 200 OK Server: akka-http/10.0.0 Date: Tue, 06 Dec 2016 02:28:29 GMT Content-Type: text/plain; charset=UTF-8 Content-Length: 4 user トークンが間違っていた場合\n$ curl -H \u0026quot;Authorization: Bearer invalid\u0026quot; --dump-header - http://localhost:8080/ HTTP/1.1 401 Unauthorized WWW-Authenticate: bearer,error=invalid_token Server: akka-http/10.0.0 Date: Tue, 06 Dec 2016 02:31:10 GMT Content-Type: text/plain; charset=UTF-8 Content-Length: 38 The supplied authentication is invalid Authorizationヘッダーを付けなかった場合\n$ curl --dump-header - http://localhost:8080/ HTTP/1.1 401 Unauthorized WWW-Authenticate: bearer,error=invalid_token Server: akka-http/10.0.0 Date: Tue, 06 Dec 2016 02:32:42 GMT Content-Type: text/plain; charset=UTF-8 Content-Length: 77 The resource requires authentication, which was not supplied with the request ちなみに AuthenticationDirective[T] のようなディレクティブは簡単に作ることができる。よく使うのは Directive0 と Directive1[T] の2つで、AuthenticationDirectiveもDirective1[T]が元になっている。前者は値を返さないディレクティブで後者は次の処理に値を渡す。\nDirective0はpassかrejectでハンドリングする。Directive1はprovideで返す値を包む。汎用的なディレクティブを作っておけば、RailsのActionControllerのfilterのように使うことが出来るので活用していきましょう。\ndef directive0(str: String): Directive0 = if (str == ????) pass else reject() def directive1(str: String): Directive1[String] = if (str == ????) provide(str.toUpperCase) else reject() val routes = path(\u0026#34;users\u0026#34; / Segment) { str =\u0026gt; directive0(str) { directive1(str) { result =\u0026gt; complete(result) } } } "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2016/02/22/ocaml-luhn.html",
                "title": "OCamlでLuhnアルゴリズムを書いてみる",
                "section": "post",
                "date" : "2016.02.22",
                "body": "OCamlに慣れるために何か書こうと思ったけど、あまりいいネタが思い浮かばなかったのでLuhnアルゴリズムを書いてみた。クレジットカードの番号などを検証することができる。\n#load \u0026#34;str.cma\u0026#34;;; let check_number number = let calculate i x = if i mod 2 = 0 then int_of_string x else let d = int_of_string x * 2 in d mod 10 + d / 10 in Str.split (Str.regexp \u0026#34;\u0026#34;) number |\u0026gt; List.rev |\u0026gt; List.mapi calculate |\u0026gt; List.fold_left (fun x y -\u0026gt; x + y) 0 |\u0026gt; fun i -\u0026gt; i mod 10 = 0 let _ = (* テスト用のクレジットカード番号 *) let numbers = [ \u0026#34;5555555555554444\u0026#34;; \u0026#34;5105105105105100\u0026#34;; \u0026#34;4111111111111111\u0026#34;; \u0026#34;4012888888881881\u0026#34;; \u0026#34;3530111333300000\u0026#34;; \u0026#34;3566002020360505\u0026#34;; \u0026#34;30569309025904\u0026#34;; \u0026#34;38520000023237\u0026#34;; \u0026#34;378282246310005\u0026#34;; \u0026#34;371449635398431\u0026#34;; \u0026#34;378734493671000\u0026#34;; \u0026#34;6011111111111117\u0026#34;; \u0026#34;6011000990139424\u0026#34;; ] in List.iter (fun n -\u0026gt; n |\u0026gt; check_number |\u0026gt; string_of_bool |\u0026gt; print_string) numbers 参考文献  チェックディジット - Wikipedia Luhnアルゴリズム - Wikipedia クレジットカード番号についてのメモ at softelメモ  追記 有益な情報をいただきました。演算子気をつけよう\n@d_akatsuka == じゃなくて = を使ったほうが良いです。そのコードでは問題ないんですけども、ポインタ比較を間違って使ってハマる人多いので\n\u0026mdash; Jun Furuse 🐫🌴 (@camloeba) February 22, 2016  "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2016/01/31/setup-ocaml.html",
                "title": "OCamlの開発環境を整えた",
                "section": "post",
                "date" : "2016.01.31",
                "body": "本当はローカルのMac OS X上に開発環境を構築したのだけど、メモを取り忘れていたので、改めてVagrantで起動したUbuntu 15.10上で開発環境を整えてみた。\nまずシステムにOcamlとOPAMをインストールする。2016年1月時点ではOCaml 4.02.3が入った。\n$ sudo add-apt-repository ppa:avsm/ppa $ sudo apt-get update $ sudo apt-get install ocaml ocaml-native-compilers camlp4-extra opam m4 git mercurial darcs バージョンを確認。\n$ ocaml -version The OCaml toplevel, version 4.02.3 $ opam --version 1.2.2 OPAMを使うためには初期化が必要。このコマンドを実行すると ~/.opam が作られる。\n$ opam init 初期化が終わると下記メッセージが出てくるので指示に従う。\n1. To configure OPAM in the current shell session, you need to run: eval `opam config env` 2. To correctly configure OPAM for subsequent use, add the following line to your profile file (for instance ~/.profile): . /home/vagrant/.opam/opam-init/init.sh \u0026gt; /dev/null 2\u0026gt; /dev/null || true 3. To avoid issues related to non-system installations of `ocamlfind` add the following lines to ~/.ocamlinit (create it if necessary): let () = try Topdirs.dir_directory (Sys.getenv \u0026quot;OCAML_TOPLEVEL_PATH\u0026quot;) with Not_found -\u0026gt; () ;; システムワイドにインストールされたOcaml環境はクリーンに保っておきたいので、開発用に新しい環境を用意しよう。opam switchコマンドで環境の作成や切り替えなどが行える。OPAMはパッケージ管理と環境管理がセットになったものと思っておけば良いだろう 1\n$ opam switch install dev --alias-of 4.02.3 OCamlのソースコードをダウンロードしてきてコンパイルまでやってくれる。少し時間がかかるが、昨今のPCなら数分程度で終わるはず。\n=-=- Installing compiler 4.02.3 -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= [default.comp] http://caml.inria.fr/pub/distrib/ocaml-4.02/ocaml-4.02.3.tar.gz downloaded Now compiling OCaml. This may take a while, please bear with us... Done. =-=- Gathering sources =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= =-=- Processing actions -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= ∗ installed base-bigarray.base ∗ installed base-ocamlbuild.base ∗ installed base-threads.base ∗ installed base-unix.base Done. # To setup the new switch in the current shell, you need to run: eval `opam config env` evalして環境を適用する。ocamlコマンドやopamコマンドのパスが変わっていることが確認できる。\n$ eval `opam config env` $ which ocaml /home/vagrant/.opam/dev/bin/ocaml VimやEmacsなどのエディタで補完を有効にするためにmerlinというライブラリを入れる。\n$ opam install merlin .vimrc に下記コードを追加すれば .merlin ファイルの存在するプロジェクトではオムニ補完が働くようになる。このファイルに依存するパッケージやモジュールを指定しないと駄目なのでちょっと面倒くさい。\nsyntax onfiletype plugin onlet g:opamshare = substitute(system(\u0026#39;opam config var share\u0026#39;),\u0026#39;\\n$\u0026#39;,\u0026#39;\u0026#39;,\u0026#39;\u0026#39;\u0026#39;\u0026#39;)execute \u0026#34;set rtp+=\u0026#34; . g:opamshare . \u0026#34;/merlin/vim\u0026#34;あとはutopやoasisなどをOPAMでインストールしておけば開発に取り掛かれると思う。なお、utopで日本語の扱いが残念なので~/.ocamlinitファイルを作って下記コードを書いておくと良い。\nlet printer ppf = Format.fprintf ppf \u0026#34;\\\u0026#34;%s\\\u0026#34;\u0026#34;;; #install_printer printer   RubyでいうところのGem + Bundler + rbenvがひとつのコマンドに集約された感じ \u0026#x21a9;\u0026#xfe0e;\n   "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2015/12/30/lookback.html",
                "title": "2015年振り返り",
                "section": "post",
                "date" : "2015.12.30",
                "body": "仕事全般 2013年にA社を退職したあと、しばらくフリーランスをやっていたのだけど、紆余曲折あって2014年の途中から古巣に戻って、現場でコードも書きつつ経営にもコミットしてました。良いこともあったし盛大に失敗したこともあったけど、そこそこ充実してた1年だった気がする。\n  毎日コードを書く…というのは残念ながら無理だった。が、自分が書かなくても仕事がまわる状況になってきたという意味では正しいかたちなのかもしれない。\n来年はもう少しプライベートでコードを書く機会を増やしたい。\nScala 仕事面では、去年から開発が続いているScalaプロジェクトが2本あり、無事にローンチすることができた。安定して運用もできている。どちらもスマートフォン向けゲームのバックエンドだったので、ひたすらJSONを返すAPIの実装だった。\n自分は開発初期の基盤設計や開発方針・環境整備・テスト周りを整えるなどの作業が中心で、実際の実装はチームに任せっきりだった。一部設計がイケてなくて迷惑を掛けたかもしれない。\n開発方針は、関数型の側面はあまり出さずPlay + ScalikeJDBCでDDDという方針にした。混乱もなく概ねうまくいったと思っているが、リポジトリに実装したメソッドの戻り型がほとんどTry[A]になっていて、引きずられるようにサービスレイヤーもTryだらけになっていた気がする。これで良いのかと若干の不安は残る。\nなお、開発後期はずっとコンパイルの遅さとテストの遅さに悩まされる日々だった 1\nプライベートではScalaz, Finagle, Finch, http4sなどを弄って遊んでいた。http4sにはしょうもないPRを送ったりするなどしていた。来年も引き続きScalaは使っていきたい。\nPython Pythonで直接何かを開発していた訳ではないが、Scalaの仕事をしているときに、sbtのタスクがあまりにも使いにくくてInvokeというPython製ツールで代用していた。Invokeで書いたタスクはのちにFabricに全面移行したけど、今年は間接的にPythonをよく読み書きした気がする。ああ、AnsibleもPythonだった。\nRuby APIや管理画面の開発に使った。もうRuby（とRuby on Rails）は長いこと使っているのだけど、限られた時間のなかですぐ形にして出すという要求には強いなと改めて思った 2\nあとRakeが何だかんだいって便利。\nRubyは来年も変わらず手に馴染むツールとして使ってると思う。\nGolang 社内でも使われている言語なので把握くらいはしておこうと思いつつ、全然できていない。\nHaskell すごいH本を読みながら細々と家でコード書いたりしている。モナ◯や型クラスなどの概念はScalaで把握していたのでそこで躓くことは無さそう。ただ独特の構文に慣れるには書く頻度を増やさないとダメだ。\nOCaml Haskellをやりつつ最近はOCamlに浮気している。Real World OCaml読んで年越し予定。まだかじった程度だけど悪くなさそう。\nC++ 自分がC++を書くことが当面無さそう。ただ仕事でC++プロジェクトに少しだけ関わる雰囲気が出てきたので、ビルド周りなどを調べてた。Bazel良さそう。\nAnsible 今年はよくAnsibleのYAMLを書いていた気がする。慣れていない初期は書いては実行し、失敗し、の繰り返しで正直嫌いになりかけた。\n社内のプロジェクトは全てCircleCIから自動的にプロビジョニングするようになっていたけど、CircleCIからの多段SSHがとても不安定で、一部プロジェクトではCircleCIからAnsibleを実行するのは止めたようだ（直近関わっているプロジェクトでは多段SSHでプロビジョニングしているが安定はしてる。ただし遅い）\nまぁ文句ばかり言ってるがChefよりは使いやすいと思っているので、きっと来年も使っていると思う。\nDocker 本番環境で運用してみたいと思いつつ、出来ずにいる。\n開発に必要なミドルウェアの提供やテスト環境の再現をするために一部プロジェクトで利用してる程度になって留まってしまっている。来年はもう少し活用の幅を広げたいなぁ。\nElectron 眺めていただけ。フロントエンドの技術には置いて行かれている感がある。やばい\n健康 概ね健康体を維持できているが、昔より疲労を覚えることが多くなってきた。単に運動不足だろって気もするが、なるほどこれが老いか。\nあと天皇誕生日にウイルス性胃腸炎という一足早いステキなクリスマスプレゼントを頂いた。おかげで今年の最終出社日が22日になってしまい、年末年始の休日数だけは過去最高になった気がする。\n学問 関数型言語を本格的に触り始めた影響で、数学や論理学を再勉強しはじめている。あまり捗っていないけど、これからも少しずつ勉強していくと思う。\n  結局CircleCIを捨てて、AWSにc4.2xlargeインスタンスを借りてDroneを動かす感じにしてしまった。 \u0026#x21a9;\u0026#xfe0e;\n 4人で半年くらいかけて1サービスがローンチできた \u0026#x21a9;\u0026#xfe0e;\n   "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2015/12/27/numeric-typeclass.html",
                "title": "ScalaでNumeric型クラスをつかう",
                "section": "post",
                "date" : "2015.12.27",
                "body": "すごいHaskell本の序盤に次のような関数が出てくる。この関数はxが整数でも浮動小数点数でも動く。\ndoubleMe x = x + x ScalaでもNumeric型クラスをつかうことで同じように振る舞える。\ndef doubleMe[A](x: A)(implicit num: Numeric[A]): A = num.plus(x, x) 型クラスのインスタンスにしてしまえばどんな型にも対応できる。たとえば…\nimplicit val numericString = new Numeric[String] { def plus(x: String, y: String): String = x + y def minus(x: String, y: String): String = x - y def times(x: String, y: String): String = x * y def negate(x: String): String = s\u0026#34;-$x\u0026#34; def toInt(x: String): Int = 0 def toLong(x: String): Long = 0 def toFloat(x: String): Float = 0 def toDouble(x: String): Double = 0 def fromInt(x: Int): String = x.toString def compare(x: String, y: String): Int = x compare y } doubleMe(\u0026#34;a\u0026#34;) // String = \u0026#34;aa\u0026#34; "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2015/12/15/finagle-mysql-readert.html",
                "title": "finagle-mysqlのClient (IO Context) をReaderTで受け取る",
                "section": "post",
                "date" : "2015.12.15",
                "body": "下準備としてパッケージオブジェクトあたりに以下のおまじないを書いておく1 この時点ですでに面倒だ！\nimport com.twitter.util.Future import scalaz._ import Scalaz._ implicit def FutureFunctor: Functor[Future] = new Functor[Future] { def map[A, B](f: Future[A])(map: A =\u0026gt; B): Future[B] = f.map(map(_)) } implicit def FutureMonad: Monad[Future] = new Monad[Future] { def point[A](a: =\u0026gt; A) = Future.value(a) def bind[A, B](f: Future[A])(fmap: A =\u0026gt; Future[B]) = f.flatMap(fmap(_)) } type ReaderTFuture[A, B] = ReaderT[Future, A, B] object ReaderTFuture extends KleisliInstances with KleisliFunctions { def apply[A, B](f: A =\u0026gt; Future[B]): ReaderTFuture[A, B] = kleisli(f) } Finch + MySQLでREST APIサーバを構築するで書いたUserがimplicit parameterを使ってClientを受け取っているので、これをReaderTに置き換えてみた。\nimport com.twitter.finagle.exp.mysql._ case class User(id: Long, email: String, screen_name: String) object User { def find(id: Long): ReaderTFuture[Client, Option[User]] = ReaderTFuture { client =\u0026gt; client.prepare(\u0026#34;SELECT * FROM users WHERE id = ?\u0026#34;)(id) map { result =\u0026gt; result.asInstanceOf[ResultSet].rows.map(convertToEntity).headOption } } def create(email: String, screen_name: String): ReaderTFuture[Client, Long] = ReaderTFuture { client =\u0026gt; client.prepare(\u0026#34;INSERT INTO users (email, screen_name) VALUES(?, ?)\u0026#34;)(email, screen_name) map { result =\u0026gt; result.asInstanceOf[OK].insertId } } def convertToEntity(row: Row): User = { val LongValue(id) = row(\u0026#34;id\u0026#34;).get val StringValue(email) = row(\u0026#34;email\u0026#34;).get val StringValue(screen_name) = row(\u0026#34;screen_name\u0026#34;).get User(id, email, screen_name) } } こんな感じで使うことができる。\nval client = Mysql.client .withCredentials(\u0026#34;user\u0026#34;, \u0026#34;password\u0026#34;) .withDatabase(\u0026#34;database\u0026#34;) .newRichClient(\u0026#34;127.0.0.1:3306\u0026#34;) (for { id \u0026lt;- User.create(\u0026#34;user1@example.com\u0026#34;, \u0026#34;user1\u0026#34;) user \u0026lt;- User.find(id) } yield user match { case Some(v) =\u0026gt; Created(v) case _ =\u0026gt; NotFound(new Exception(\u0026#34;xxxxx\u0026#34;)) }).run(client) 上記のように.runでまとめて渡すことも出来るしval user = User.find(id)(client)と直接渡すことも出来るので、使いやすいほうを選べば良さそう。\n参考文献  独習 Scalaz — モナド変換子 Scala における Repository の実装パターンを考える -模索篇- - sandbox Scala で IO コンテキストの共有を implicit 以外で解決する方法 (0) - sandbox Scalaにおける最適なDependency Injectionの方法を考察する 〜なぜドワンゴアカウントシステムの生産性は高いのか〜 - Qiita 【Scala Days 2014】The Reader Monad for Dependency Injection を解説してみた | Scala Tech Blog    FutureをFunctorとMonadの型クラスのインスタンスにしておく必要がある。ReaderTではなくReader使う場合は不要。 \u0026#x21a9;\u0026#xfe0e;\n   "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2015/12/13/finch-endpoint-test.html",
                "title": "FinchのEndpointのテスト方法を調べた",
                "section": "post",
                "date" : "2015.12.13",
                "body": "Finchはエンドポイントを作るときに戻り値を型で縛れるので、正常系のレスポンスに関してはコンパイラを信用して大丈夫だろう。ただし、ステータスコードまでは検証出来ないので、リクエストパラメータによってステータスコードが変わる場合などはしっかりとテストを書いておきたい。\nFinchのEndpoint型はtoService関数でcom.twitter.finagle.Service型に変わり、これにRequestを渡せばResponse型が返ってくるらしい。REPLで確認してみた。\nscala\u0026gt; import io.finch._ import io.finch._ scala\u0026gt; import com.twitter.finagle.http._ import com.twitter.finagle.http._ scala\u0026gt; import com.twitter.util.Await import com.twitter.util.Await scala\u0026gt; val endpoint: Endpoint[String] = get(\u0026quot;foo\u0026quot; / string) { s: String =\u0026gt; Ok(s) } endpoint: io.finch.Endpoint[String] = GET /foo/:string scala\u0026gt; val service = endpoint.toService service: com.twitter.finagle.Service[com.twitter.finagle.http.Request,com.twitter.finagle.http.Response] = \u0026lt;function1\u0026gt; scala\u0026gt; service(Request(\u0026quot;/foo/bar\u0026quot;)) res0: com.twitter.util.Future[com.twitter.finagle.http.Response] = Promise@886121853(state=Done(Return(Response(\u0026quot;HTTP/1.1 Status(200)\u0026quot;)))) scala\u0026gt; val response = Await.result(service(Request(\u0026quot;/foo/bar\u0026quot;))) response: com.twitter.finagle.http.Response = Response(\u0026quot;HTTP/1.1 Status(200)\u0026quot;) scala\u0026gt; response.status res1: com.twitter.finagle.http.Status = Status(200) scala\u0026gt; response.contentString res2: String = bar ちゃんと返ってきた。問題なさそう。\n参考文献  finch/EndToEndSpec.scala · finagle/finch  "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2015/12/10/luaj.html",
                "title": "ScalaでLuaスクリプトを動かして遊ぶ",
                "section": "post",
                "date" : "2015.12.10",
                "body": "これはScala Advent Calendar 2015（Adventar版）10日目です。9日目はShinpeimさんの既存のクラスをScalazで定義されている型クラスのインスタンスにするの巻でした。\nさて、ScalaでLuaです。みんなScala上でLua動かしたいですよね！？1\nluaj 2を入れましょう\nlibraryDependencies += \u0026#34;org.luaj\u0026#34; % \u0026#34;luaj-jse\u0026#34; % \u0026#34;3.0.1\u0026#34; ただ実行するだけならJsePlatform.standardGlobals().loadを使います。またloadFileメソッドでファイルも指定できるようです。\nimport org.luaj.vm2.lib.jse._ val globals = JsePlatform.standardGlobals() val chunk = globals.load(\u0026#34;print \u0026#39;hello, world\u0026#39;\u0026#34;) chunk.call $ sbt run [info] Set current project to (...) [info] Compiling 1 Scala source to ... [info] Running Main hello, world ScalaからLuaに値を渡したり、逆にLuaから値を受けとりたくなりますよね。もちろん可能です。\nimport javax.script.ScriptEngineManager val manager = new ScriptEngineManager() val engine = manager.getEngineByName(\u0026#34;luaj\u0026#34;) engine.put(\u0026#34;x\u0026#34;, 10) engine.put(\u0026#34;y\u0026#34;, 20) engine.eval(\u0026#34;z = x + y\u0026#34;) val result = engine.get(\u0026#34;z\u0026#34;) println(result) // =\u0026gt; 30 調子に乗ってLuaスクリプトを非同期で実行してみました。\nimport javax.script.ScriptEngineManager import scala.concurrent.duration.Duration import scala.concurrent.{Await, Future} import scala.concurrent.ExecutionContext.Implicits.global object Main { def executeLua[T](script: String, returnVariable: String, binds: Map[String, Any]): Future[T] = Future { val manager = new ScriptEngineManager() val engine = manager.getEngineByName(\u0026#34;luaj\u0026#34;) binds.foreach { bind =\u0026gt; engine.put(bind._1, bind._2) } engine.eval(script) engine.get(returnVariable).asInstanceOf[T] } def main(args: Array[String]): Unit = { val luaScript = \u0026#34;\u0026#34;\u0026#34; |function fib(n) | if n \u0026lt; 2 then return n end | return fib(n - 2) + fib(n - 1) |end | |result = fib(x) \u0026#34;\u0026#34;\u0026#34;.stripMargin val f1 = executeLua[Int](luaScript, \u0026#34;result\u0026#34;, Map(\u0026#34;x\u0026#34; -\u0026gt; 10)) val f2 = executeLua[Int](luaScript, \u0026#34;result\u0026#34;, Map(\u0026#34;x\u0026#34; -\u0026gt; 38)) val f3 = executeLua[Int](luaScript, \u0026#34;result\u0026#34;, Map(\u0026#34;x\u0026#34; -\u0026gt; 10)) f1.onSuccess { case r: Int =\u0026gt; println(r) } f2.onSuccess { case r: Int =\u0026gt; println(r) } f3.onSuccess { case r: Int =\u0026gt; println(r) } Await.ready(f1, Duration.Inf) Await.ready(f2, Duration.Inf) Await.ready(f3, Duration.Inf) } } $ ./sbt run [info] Set current project to (...) [info] Compiling 1 Scala source to ... [info] Running Main 55 55 39088169 [success] Total time: 26 s, completed 2015/12/09 3:14:23   ネタっぽい感じですが、ゲーム業界だとLuaの需要がそれなりにあるので、現場によっては意外と使えるかも？ゲームバランスに影響するロジックをLuaに切り出しておくと開発終盤にプランナーが幸せになれるかもしれない \u0026#x21a9;\u0026#xfe0e;\n JavaライブラリなのでScala以外でも使えます \u0026#x21a9;\u0026#xfe0e;\n   "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2015/12/07/finch.html",
                "title": "Finch + MySQLでREST APIサーバを構築する",
                "section": "post",
                "date" : "2015.12.07",
                "body": "これはScala Advent Calendar 2015（Adventar版）7日目です。6日目はHiroyuki-NagataさんのScalatraとnon-blocking APIについてメモ - なんとな～くしあわせ？の日記でした。\nさて、7日目はFinchというFinagleラッパーを紹介しようと思います。よくあるSinatraライクなマイクロフレームワークのひとつです。Hello Wordをブラウザに出力してはい終わりというのも味気ないので、MySQLに接続してレコードを取り出したり登録出来るところまで持っていきます。\nはじめに 今回は以下のエンドポイントを作ることにします（更新と削除は面倒になったので無し！ごめんなさい）\nGET /users GET /users/:id POST /users コードを書く前にMySQLにテーブルを作っておきましょう。\nCREATE TABLE `users` ( `id` BIGINT NOT NULL AUTO_INCREMENT, `email` VARCHAR(255) NOT NULL, `screen_name` VARCHAR(255) NOT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB; 依存関係 開発版の0.9.2-SNAPSHOTを利用します。またMySQLに繋ぐためにfinagle-mysqlも入れます。\nbuild.sbtは下記のようになります。\nname := \u0026#34;finchtest\u0026#34; version := \u0026#34;0.1.0\u0026#34; scalaVersion := \u0026#34;2.11.7\u0026#34; resolvers += Resolver.sonatypeRepo(\u0026#34;snapshots\u0026#34;) libraryDependencies ++= Seq( \u0026#34;com.twitter\u0026#34; %% \u0026#34;finagle-mysql\u0026#34; % \u0026#34;6.30.0\u0026#34;, \u0026#34;com.github.finagle\u0026#34; %% \u0026#34;finch-core\u0026#34; % \u0026#34;0.9.2-SNAPSHOT\u0026#34; changing(), \u0026#34;com.github.finagle\u0026#34; %% \u0026#34;finch-argonaut\u0026#34; % \u0026#34;0.9.2-SNAPSHOT\u0026#34; changing() ) 実装 日本語の情報がほとんどないことや公式のドキュメントがやや分かりづらいことを除けば1Finch自体の使いかたはそんなに難しくないです。Finchよりもfinagle-mysqlの使いかたを調べるのに苦労したのは内緒です。\n今回はDBのCRUD操作をするUser.scalaとMain.scalaの2ファイル書きました。\npackage jp.dakatsuka.finch import argonaut.Argonaut._ import argonaut.CodecJson import com.twitter.finagle.exp.mysql._ import com.twitter.util.Future case class User(id: Long, email: String, screen_name: String) object User { implicit val userCodec: CodecJson[User] = casecodec3(User.apply, User.unapply)(\u0026#34;id\u0026#34;, \u0026#34;email\u0026#34;, \u0026#34;screen_name\u0026#34;) def all()(implicit client: Client): Future[Seq[User]] = client.select(\u0026#34;SELECT * FROM users\u0026#34;)(convertToEntity) def find(id: Long)(implicit client: Client): Future[Option[User]] = client.prepare(\u0026#34;SELECT * FROM users WHERE id = ?\u0026#34;)(id) map { result =\u0026gt; result.asInstanceOf[ResultSet].rows.map(convertToEntity).headOption } def create(email: String, screen_name: String)(implicit client: Client): Future[Long] = client.prepare(\u0026#34;INSERT INTO users (email, screen_name) VALUES(?, ?)\u0026#34;)(email, screen_name) map { result =\u0026gt; result.asInstanceOf[OK].insertId } def convertToEntity(row: Row): User = { val LongValue(id) = row(\u0026#34;id\u0026#34;).get val StringValue(email) = row(\u0026#34;email\u0026#34;).get val StringValue(screen_name) = row(\u0026#34;screen_name\u0026#34;).get User(id, email, screen_name) } } package jp.dakatsuka.finch import com.twitter.finagle.Http import com.twitter.finagle.exp.Mysql import com.twitter.util.Await import io.finch._ import io.finch.argonaut._ object Main { implicit val client = Mysql.client .withCredentials(\u0026#34;user\u0026#34;, \u0026#34;password\u0026#34;) .withDatabase(\u0026#34;database\u0026#34;) .newRichClient(\u0026#34;127.0.0.1:3306\u0026#34;) case class UserParams(email: String, screen_name: String) val userParams: RequestReader[UserParams] = for { email \u0026lt;- param(\u0026#34;email\u0026#34;) screen_name \u0026lt;- param(\u0026#34;screen_name\u0026#34;) } yield UserParams(email, screen_name) val listUser: Endpoint[Seq[User]] = get(\u0026#34;users\u0026#34;) { Ok(User.all) } val showUser: Endpoint[User] = get(\u0026#34;users\u0026#34; / long) { id: Long =\u0026gt; User.find(id).map { case Some(user) =\u0026gt; Ok(user) case _ =\u0026gt; NotFound(new Exception(\u0026#34;Record Not Found\u0026#34;)) } } val createUser: Endpoint[User] = post(\u0026#34;users\u0026#34; ? userParams) { p: UserParams =\u0026gt; (for { id \u0026lt;- User.create(p.email, p.screen_name) user \u0026lt;- User.find(id) } yield user) map { case Some(user) =\u0026gt; Created(user) case _ =\u0026gt; NotFound(new Exception(\u0026#34;Record Not Found\u0026#34;)) } } val userService = (listUser :+: showUser :+: createUser).toService def main(args: Array[String]): Unit = { Await.ready(Http.serve(\u0026#34;:8080\u0026#34;, userService)) } } 動かしてみよう いつものコマンドでサーバが起動します。\n$ sbt run [info] Set current project to finchtest (in build file:/path/to/project/) [info] Compiling 1 Scala source to /path/to/project/target/scala-2.11/classes... [info] Running jp.dakatsuka.finch.Main 12 05, 2015 11:30:49 午後 com.twitter.finagle.Init$$anonfun$1 apply$mcV$sp 情報: Finagle version 6.30.0 (rev=745578b931893c432e51da623287144e548cc489) built at 20151015-163818 curlでリクエストを送ってみましょう。\n$ curl http://localhost:8080/users [] $ curl http://localhost:8080/users/1 Record Not Found $ curl -X POST http://localhost:8080/users Required param 'email' not present in the request. $ curl -X POST -d \u0026quot;email=user1@example.com\u0026quot; http://localhost:8080/users Required param 'screen_name' not present in the request. $ curl -X POST -d \u0026quot;email=user1@example.com\u0026quot; -d \u0026quot;screen_name=user1\u0026quot; http://localhost:8080/users {\u0026quot;id\u0026quot;:1,\u0026quot;email\u0026quot;:\u0026quot;user1@example.com\u0026quot;,\u0026quot;screen_name\u0026quot;:\u0026quot;user1\u0026quot;} $ curl -X POST -d \u0026quot;email=user2@example.com\u0026quot; -d \u0026quot;screen_name=user2\u0026quot; http://localhost:8080/users {\u0026quot;id\u0026quot;:2,\u0026quot;email\u0026quot;:\u0026quot;user2@example.com\u0026quot;,\u0026quot;screen_name\u0026quot;:\u0026quot;user2\u0026quot;} $ curl http://localhost:8080/users [{\u0026quot;id\u0026quot;:1,\u0026quot;email\u0026quot;:\u0026quot;user1@example.com\u0026quot;,\u0026quot;screen_name\u0026quot;:\u0026quot;user1\u0026quot;},{\u0026quot;id\u0026quot;:2,\u0026quot;email\u0026quot;:\u0026quot;user2@example.com\u0026quot;,\u0026quot;screen_name\u0026quot;:\u0026quot;user2\u0026quot;}] $ curl http://localhost:8080/users/1 {\u0026quot;id\u0026quot;:1,\u0026quot;email\u0026quot;:\u0026quot;user1@example.com\u0026quot;,\u0026quot;screen_name\u0026quot;:\u0026quot;user1\u0026quot;} 期待通りの動きですね 😏\nまとめ Finchはいかがでしたか？\nFinagleのエコシステムの上に乗っているので、Finagleに慣れている人がサクッとREST APIを実装するには良い選択肢だと思います。finagle-*なライブラリも当然使えます。Finagle使ったことない人にも、静的型付けの恩恵を受けながらSinatraライクに開発出来るというのは魅力的に映るかもしれませんね。\n個人的にはエンドポイントの戻り値が型で保証出来るのが高ポイントです！\nちなみに、似たようなフレームワークとしてFinagle, Akka HTTP, Scalatra, http4sなどがあります。http4sはScalaのHTTPインターフェース http4s 超入門で雑に紹介しているので、興味ある方はどうぞ。\n  Scalaライブラリにはよくあることなので頑張って貢献したい… \u0026#x21a9;\u0026#xfe0e;\n   "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2015/12/01/https.html",
                "title": "HTTPSに移行した",
                "section": "post",
                "date" : "2015.12.01",
                "body": "さくらのSSL1でRapidSSLが1年分無料になるキャンペーンをやっていたので、このブログを思い切ってHTTPSに移行した。最初はCloudFlareを使おうかと考えていたのだけど、どうせならHTTP/2にしたいと思い、さくらのVPSにnginx 1.9.7を入れて運用してみることにした。\n概ね問題なく移行出来た気がするけど、まぁぶっちゃけた話、個人サイトでHTTPS, HTTP/2に急いで移行するメリットは無さそうだ。画像やJavaScript, CSSが大量に使われているサイトなら効果出るかもしれない？\n作業内容は主に下記4点。これといって難しいことはしていない。\n nginxを最新の1.9.7に上げた2 Strict-Transport-Securityヘッダを返すようにした HTTPはHTTPSに301リダイレクトするようにした サイト内のパーマリンク修正  また、ずっと放置していた検索エンジン向けの対応もついでに行った。\n robots.txt用意した sitemap.xml用意した  参考にしたサイト  HTTPSへ - Weblog - Hail2u.net nginxでHTTP2接続(not spdy3.1)の検証 - Qiita Nginx 1.9.5 でHTTP2を試そう！ - あすのかぜ    SSLの証明書を販売するサービスがHTTPのままなのでとてもシュール \u0026#x21a9;\u0026#xfe0e;\n http://nginx.org/en/download.html \u0026#x21a9;\u0026#xfe0e;\n   "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2015/11/22/http4s-with-ssl.html",
                "title": "http4sでHTTPSを有効にする",
                "section": "post",
                "date" : "2015.11.22",
                "body": "SSLSupportパッケージをインポートしてBlazeBuilderの.withSSLにKeyStoreの情報を渡せばHTTPSが有効になる。代わりにHTTPは無効になってしまうので注意。\nimport org.http4s.server.blaze.BlazeBuilder import org.http4s.server.SSLSupport._ BlazeBuilder .bindHttp(8080) .withSSL( keyStore = StoreInfo(\u0026#34;/path/to/keystore\u0026#34;, \u0026#34;password\u0026#34;), keyManagerPassword = \u0026#34;password\u0026#34; ) .mountService(servie) .run .awaitShutdown() OpenSSLで生成した鍵や証明書からKeyStoreファイルを作る方法、毎回ググってる気がするのでメモっておく。\n$ openssl pkcs12 -inkey server.key -in server.crt -export -out server.pkcs12 $ keytool -importkeystore -srckeystore ./server.pkcs12 -srcstoretype PKCS12 -destkeystore server.keystore $ keytool -keystore ./server.keystore -import -alias ServerChain -file ./server.ca -trustcacerts ちなみにBlazeBuilderで.enableHttp2(true)を書けばHTTP/2が有効になるらしいが、手元ではうまく動かなかった。なにか設定が足りないのかもしれない。。。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2015/11/21/2007.html",
                "title": "2007年頃に書いていた技術ブログのエントリをリカバリーした",
                "section": "post",
                "date" : "2015.11.21",
                "body": "その昔 http://d.hatena.ne.jp/CLA という技術ブログを書いていた。なぜ消したのか最早記憶にはないが、特に隠す内容のものでも無さそうだったので、このブログにインポートすることにした。せっかく書いた訳だし自身の記録として残しておこうかと。\nちなみに肝心の内容だが、Ubuntu 7.04（Feisty）を弄くってどうこうするというエントリがほとんどで、今となっては全く役に立たないだろう。時代を感じる。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2015/11/18/activerecord-import.html",
                "title": "activerecord-importとelasticsearch-railsでメソッドが被る問題",
                "section": "post",
                "date" : "2015.11.18",
                "body": "どちらのgemもActiveRecordモデルにimportメソッドを生やそうとする。\nいい感じに共存させる方法をググっていたら同じことをIssueで質問している人がいて、解決方法が書いてあったので助かった。config/application.rbでactiverecord-import側のメソッド名を変更する。\nrequire File.expand_path(\u0026#39;../boot\u0026#39;, __FILE__) require \u0026#39;rails/all\u0026#39; # https://github.com/zdennis/activerecord-import/issues/149 require \u0026#39;activerecord-import/base\u0026#39; class ActiveRecord::Base class \u0026lt;\u0026lt; self alias :bulk_insert :import remove_method :import end end Bundler.require(*Rails.groups) .... 参考文献  elasticsearch-rails activerecord-import Name clash with the elasticsearch gem · Issue #149 · zdennis/activerecord-import  "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2015/11/15/diary.html",
                "title": "退社後の軽い運動",
                "section": "post",
                "date" : "2015.11.15",
                "body": "この2年間で6キロくらい太った。食べる量は変わっていないので単純に運動不足だと思う。まぁストレスも多少影響しているかも。\n最近は退社後に、西新宿五丁目にあるオフィスから中野駅まで歩いたりしているが（調子が良くないと中野坂上駅や東中野駅がゴールになる）残念ながらまだ体重低下には繋がっていない。ぶっちゃけ軽い運動にもなっていないのでは…と薄々思い始めているが、こういうのは継続が大事ということなのでもう暫く続けてみるつもり。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2015/11/14/http4s.html",
                "title": "ScalaのHTTPインターフェース http4s 超入門",
                "section": "post",
                "date" : "2015.11.14",
                "body": "What\u0026rsquo;s http4s RackやWSGIのScala版といったところ。公式サイトの説明も次のように書いてある。\n http4s is a minimal, idiomatic Scala interface for HTTP. http4s is Scala\u0026rsquo;s answer to Ruby\u0026rsquo;s Rack, Python\u0026rsquo;s WSGI, Haskell\u0026rsquo;s WAI, and Java\u0026rsquo;s Servlets.\n まだまだ開発途中でドキュメントなどはあまり整備されていなくて、まともに使おうと思ったらソースコードを読む必要が出てきそう。次期Scalatraのバックエンドになるとかならないとか噂されているけどはてさて？もしかしたらAkkaやFinagleに押されて流行らずに終わる可能性もある。\nちなみにscalaz-streamが使われている。\nInstall 最小構成で使う場合は http4s-server と http4s-blaze-server だけで良い。\nresolvers += \u0026#34;Scalaz Bintray Repo\u0026#34; at \u0026#34;http://dl.bintray.com/scalaz/releases\u0026#34; libraryDependencies ++= Seq( \u0026#34;org.http4s\u0026#34; %% \u0026#34;http4s-server\u0026#34; % \u0026#34;0.10.1\u0026#34;, \u0026#34;org.http4s\u0026#34; %% \u0026#34;http4s-blaze-server\u0026#34; % \u0026#34;0.10.1\u0026#34; ) Specification http4sの仕様に準拠したアプリケーション（http4sではサービスという）として最低限必要なことは次の通り。\n org.http4s.server.HttpService 型であること  以上！めちゃくちゃシンプルですね。HttpServiceの定義を覗いてみるとこう書いてある。\ntype Service[A, B] = Kleisli[Task, A, B] type HttpService = Service[Request, Response] 実際はHttpServiceを作るための関数が HttpService.apply として用意されているのでこれを使っていく。この関数はRequest型を受け取ってTask[Response]型を返すPartialFunctionを引数に取る。\nobject HttpService { def apply(pf: PartialFunction[Request, Task[Response]], default: HttpService = empty): HttpService } Rackなどを触ったことがある人ならピンと来るはず。\nIntroduction アクセスすると画面にHello WorldとQueryStringを表示する簡単なサービスを作ってみる。\n// src/main/scala/jp/dakatsuka/http4stest/Bootstrap.scala package jp.dakatsuka.http4stest import org.http4s.{Status, Response} import org.http4s.server.HttpService import org.http4s.server.blaze.BlazeBuilder object Bootstrap { val service = HttpService { case req =\u0026gt; Response() .withStatus(Status.Ok) .withBody(s\u0026#34;Hello World!! ${req.queryString}\u0026#34;) } def main(args: Array[String]): Unit = BlazeBuilder .bindHttp(8080) .mountService(service) .run .awaitShutdown() } sbt runを実行してブラウザで http://localhost:8080/?foo=bar\u0026amp;fizz=buzz にアクセス。次のような文字がブラウザ上に表示されるはず。\nHello World!! foo=bar\u0026amp;fizz=buzz Middleware ミドルウェアも簡単につくれる。ミドルウェアは既存のHttpServiceに組み込んで（合成して）使う。試しにX-HTTP4S-MESSAGEというヘッダーを付与するミドルウェアを作ってみる。\n// src/main/scala/jp/dakatsuka/http4stest/MessageMiddleware.scala package jp.dakatsuka.http4stest import org.http4s.Header import org.http4s.server.HttpService object MessageMiddleware { def apply(service: HttpService, message: String): HttpService = HttpService.lift { req =\u0026gt; service.map { res =\u0026gt; res.putHeaders(Header(\u0026#34;X-HTTP4S-MESSAGE\u0026#34;, message)) }.apply(req) } } 組み込み方はこう。\ndef main(args: Array[String]): Unit = BlazeBuilder .bindHttp(8080) .mountService(MessageMiddleware(service, \u0026#34;Hello!!!!!\u0026#34;)) .run .awaitShutdown() ちゃんとヘッダーに追加されていることが分かる。\n$ curl --dump-header - http://localhost:8080 HTTP/1.1 200 OK Content-Length: 14 Content-Type: text/plain; charset=UTF-8 X-HTTP4S-MESSAGE: Hello!!!!! Date: Sat, 14 Nov 2015 13:30:32 GMT Hello World!! http4s-dsl http4s-dslというパッケージを追加すればSinatraのようにDSLを使ってルーティングを定義できる。\nbuild.sbtに依存関係を追加する。\nlibraryDependencies ++= Seq( \u0026#34;org.http4s\u0026#34; %% \u0026#34;http4s-server\u0026#34; % \u0026#34;0.10.1\u0026#34;, \u0026#34;org.http4s\u0026#34; %% \u0026#34;http4s-dsl\u0026#34; % \u0026#34;0.10.1\u0026#34;, \u0026#34;org.http4s\u0026#34; %% \u0026#34;http4s-blaze-server\u0026#34; % \u0026#34;0.10.1\u0026#34; ) DSLを使うと次のように直感的にルーティングできるようになる。ちょっとしたマイクロサービスを作りたいときにはこれで十分な気がする。\nimport org.http4s._ import org.http4s.dsl._ import org.http4s.server.HttpService import jp.dakatsuka.http4stest.model.User val service = HttpService { case GET -\u0026gt; Root =\u0026gt; Ok(\u0026#34;Document Root\u0026#34;) case GET -\u0026gt; Root / \u0026#34;users\u0026#34; =\u0026gt; Ok(User.all) case GET -\u0026gt; Root / \u0026#34;users\u0026#34; / LongVar(id) =\u0026gt; User.find(id) match { case Some(user) =\u0026gt; Ok(user) case _ =\u0026gt; NotFound() } case GET -\u0026gt; Root / \u0026#34;users\u0026#34; / screen_name =\u0026gt; User.findOneByScreenName(screen_name) match { case Some(user) =\u0026gt; Ok(user) case _ =\u0026gt; NotFound() } case req @ POST -\u0026gt; Root / \u0026#34;users\u0026#34; =\u0026gt; req.decode[UrlForm] { data =\u0026gt; val UserParams = for { email \u0026lt;- data.getFirst(\u0026#34;email\u0026#34;) screen_name \u0026lt;- data.getFirst(\u0026#34;screen_name\u0026#34;) } yield UserParams(email, screen_name) ??? } } JSON レスポンスを返したい 厳密にはcase classをOkやNotFoundに渡したらJSON文字列に変換してレスポンスを返して欲しい。になる。\nhttp4sは EntityEncoder[T] を定義しておけばどんな型でもレスポンスとして返せるという仕組みがある（逆のEntityDecoderもある）JSONに関しては http4s-argonaut という公式パッケージが用意されているのでそれを利用するのが良いだろう。Argonautが嫌な人はJson4s用のパッケージも用意されているのでそちらを。\nlibraryDependencies ++= Seq( \u0026#34;org.http4s\u0026#34; %% \u0026#34;http4s-server\u0026#34; % \u0026#34;0.10.1\u0026#34;, \u0026#34;org.http4s\u0026#34; %% \u0026#34;http4s-dsl\u0026#34; % \u0026#34;0.10.1\u0026#34;, \u0026#34;org.http4s\u0026#34; %% \u0026#34;http4s-blaze-server\u0026#34; % \u0026#34;0.10.1\u0026#34;, \u0026#34;org.http4s\u0026#34; %% \u0026#34;http4s-argonaut\u0026#34; % \u0026#34;0.10.1\u0026#34; ) // src/main/scala/jp/dakatsuka/http4stest/model/User.scala package jp.dakatsuka.http4s.model import argonaut.Argonaut._ import argonaut.CodecJson import org.http4s.argonaut._ import org.http4s.EntityEncoder case class User(id: Long, email: String, screen_name: String) object User { implicit val userCodec: CodecJson[User] = casecodec3(User.apply, User.unapply)(\u0026#34;id\u0026#34;, \u0026#34;email\u0026#34;, \u0026#34;screen_name\u0026#34;) implicit val userEntityEncoder: EntityEncoder[User] = jsonEncoderOf[User] implicit val usersEntityEncoder: EntityEncoder[List[User]] = jsonEncoderOf[List[User]] def all(): List[User] = ??? def find(id: Long): Option[User] = ??? def findOneByScreenName(screen_name: String): Option[User] = ??? } まとめ 駆け足でhttp4sを紹介してみたけど、個人的にはかなり使い勝手が良いと思う。Akka, Playframeworkのような重厚感もないし http4s-dsl を使えば簡単にAPIの実装も出来るだろう。お手軽感って大事だと思う。ルーティングやレスポンスを型安全に書けるのもポイントが高い。\n懸念点としては最初にも書いたようにライバルが多くて消えてしまうのでは…ってところ。http4sはServletでも動くので頑張って欲しい。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2015/11/07/future-to-task-transformer.html",
                "title": "scala.concurrent.Futureをscalaz.concurrent.Taskに変換する方法",
                "section": "post",
                "date" : "2015.11.07",
                "body": "あまり良い方法では無さそうだけど他に思いつかなかった\nimport scala.concurrent.Future import scala.concurrent.ExecutionContext.Implicits.global import scala.util.{Success, Failure} import scalaz.concurrent.Task import scalaz.syntax.either._ implicit class FutureToTaskTransformer[+A](future: Future[A]) { def toTask: Task[A] = { Task.async { register =\u0026gt; future.onComplete { case Success(v) =\u0026gt; register(v.right) case Failure(e) =\u0026gt; register(e.left) } } } } Future型を返してくる何かをhttp4sで使いたいときに使えるかも？\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2015/08/22/elasticsearch-on-circleci.html",
                "title": "CircleCIでElasticsearchを使うならDockerがよさそう",
                "section": "post",
                "date" : "2015.08.22",
                "body": "CircleCIでElasticsearchの最新版とKuromojiを使うならDockerが便利だった。circle.ymlでwgetして頑張るよりは1こちらのほうがスマートだし、ここで用意したDockerfileはCI以外でも使える。\n下記コードをcontainers/elasticsearch/Dockerfileに保存する。\nFROMelasticsearch:1.7.1RUN plugin install mobz/elasticsearch-headRUN plugin install elasticsearch/elasticsearch-analysis-kuromoji/2.7.0circle.ymlでDockerを有効化して、dependenciesでコンテナを起動するだけ。\nmachine: services: - docker dependencies: override: - docker build -t foobar/elasticsearch:1.7.1 ./containers/elasticsearch - docker run -d -p 9200:9200 -p 9300:9300 foobar/elasticsearch:1.7.1 で、このエントリを書いている最中に https://github.com/circleci/docker-elasticsearch そのものズバリのリポジトリを発見した。こちらのほうがイメージのキャッシュまでしているので参考になると思う。\n  Install a custom version of Elasticsearch \u0026#x21a9;\u0026#xfe0e;\n   "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2015/06/11/play-multiple-project.html",
                "title": "Play Framework 2.x でマルチプロジェクト構成にするには",
                "section": "post",
                "date" : "2015.06.11",
                "body": "ドメイン層（普通のScalaプロジェクト）とアプリケーション層（Play）でsbtプロジェクトを分けたい場合は、sbtのマルチプロジェクトを使うと良い。\n完全にリポジトリごとに分けても良いのだけど、IDEのリファクタリング機能などの便利機能の恩恵を受けたいとか、開発初期でドメインの更新が頻繁にあるなら、同一リポジトリでマルチプロジェクト構成のほうがおすすめ。\nディレクトリ構成は下記のようにする。\nsbtはサブプロジェクト内のprojectディレクトリを無視するので、Playのsbt-pluginなどはメインプロジェクトで読み込む。\nproject/pugin.sbt\nresolvers += \u0026#34;Typesafe repository\u0026#34; at \u0026#34;http://repo.typesafe.com/typesafe/releases/\u0026#34; addSbtPlugin(\u0026#34;com.typesafe.play\u0026#34; % \u0026#34;sbt-plugin\u0026#34; % \u0026#34;2.4.0\u0026#34;) またライブラリの依存関係はサブプロジェクトのbuild.sbtでは行わず、全てメインプロジェクトのbuild.sbtに記述していく。commonSettingsで共通の設定や依存ライブラリを定義しておくと便利。\nbuild.sbt\nname := \u0026#34;myapplication\u0026#34; lazy val commonSettings = scalariformSettings ++ Seq( organization := \u0026#34;org.example\u0026#34;, scalaVersion := \u0026#34;2.11.6\u0026#34;, resolvers += \u0026#34;scalaz-bintray\u0026#34; at \u0026#34;https://dl.bintray.com/scalaz/releases\u0026#34;, libraryDependencies ++= Seq( \u0026#34;org.specs2\u0026#34; %% \u0026#34;specs2-core\u0026#34; % \u0026#34;3.6.1\u0026#34; % \u0026#34;test\u0026#34;, \u0026#34;org.specs2\u0026#34; %% \u0026#34;specs2-mock\u0026#34; % \u0026#34;3.6.1\u0026#34; % \u0026#34;test\u0026#34;, \u0026#34;org.specs2\u0026#34; %% \u0026#34;specs2-junit\u0026#34; % \u0026#34;3.6.1\u0026#34; % \u0026#34;test\u0026#34;, \u0026#34;ch.qos.logback\u0026#34; % \u0026#34;logback-classic\u0026#34; % \u0026#34;1.1.+\u0026#34; ) ) lazy val domain = project.in(file(\u0026#34;domain\u0026#34;)) .settings(commonSettings: _*) .settings( libraryDependencies ++= Seq( \u0026#34;mysql\u0026#34; % \u0026#34;mysql-connector-java\u0026#34; % \u0026#34;5.1.31\u0026#34;, \u0026#34;org.scalikejdbc\u0026#34; %% \u0026#34;scalikejdbc\u0026#34; % \u0026#34;2.2.+\u0026#34;, \u0026#34;org.scalikejdbc\u0026#34; %% \u0026#34;scalikejdbc-config\u0026#34; % \u0026#34;2.2.+\u0026#34;, \u0026#34;org.scalikejdbc\u0026#34; %% \u0026#34;scalikejdbc-test\u0026#34; % \u0026#34;2.2.+\u0026#34; % \u0026#34;test\u0026#34; ) ) lazy val api = (project.in(file(\u0026#34;api\u0026#34;))) .enablePlugins(PlayScala) .settings(commonSettings: _*) .settings( libraryDependencies ++= Seq( jdbc, cache, ws, \u0026#34;com.typesafe.play\u0026#34; %% \u0026#34;play-specs2\u0026#34; % \u0026#34;2.4.0\u0026#34; % \u0026#34;test\u0026#34;, \u0026#34;org.scalikejdbc\u0026#34; %% \u0026#34;scalikejdbc-play-initializer\u0026#34; % \u0026#34;2.4.0.RC1\u0026#34;, \u0026#34;org.scalikejdbc\u0026#34; %% \u0026#34;scalikejdbc-play-fixture\u0026#34; % \u0026#34;2.4.0.RC1\u0026#34;, ) ) .dependsOn(domain) サブプロジェクトのbuild.sbtにはname version javaOptionsなどを個別に定義していく。\nPlayでサーバを起動する場合は下記コマンドを使う。テストをサブプロジェクト単位で実行する場合も同様。\n$ sbt \u0026quot;project api\u0026quot; run $ sbt \u0026quot;project api\u0026quot; test $ sbt \u0026quot;project domain\u0026quot; test $ sbt test // all test "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2015/06/10/horrible-code.html",
                "title": "今年に入って生み出した糞コード",
                "section": "post",
                "date" : "2015.06.10",
                "body": "PackerのログからAMI IDを取得するコードがInvokeのタスクに書かれていた。全然書いた記憶がないのだけど（すごい忙しかったという記憶だけはある）blameしてみると自分なのできっと妖精さんが書いたのだろう。。。\nami_id = commands.getoutput(\u0026#34;ruby -e \u0026#39;puts `tail -n1 /tmp/packer.log`.split(\\\u0026#34;: \\\u0026#34;).last\u0026#39;\u0026#34;) 書きなおすとしたらこうかな。Pythonはたまにしか書かないのでもっと良い書き方がある気がする。\nwith open(\u0026#34;/tmp/packer.log\u0026#34;, \u0026#34;r\u0026#34;) as file: xs = file.read().split(\u0026#34;\\n\u0026#34;) ami_id = [x for x in xs if x][-1].split(\u0026#34;: \u0026#34;)[-1] 別にtailコマンド使うのは良い気がしてきた。\nami_id = commands.getoutput(\u0026#34;tail -n1 /tmp/packer.log\u0026#34;).split(\u0026#34;: \u0026#34;)[-1] 追記：これだ\nami_id = commands.getoutput(\u0026#34;tail -n1 /tmp/packer.log | sed -e \u0026#39;s/^ami: //\u0026#39;\u0026#34;) "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2015/05/16/sbt-publish-to-s3.html",
                "title": "sbtでAmazon S3をMavenリポジトリとして扱う方法",
                "section": "post",
                "date" : "2015.05.16",
                "body": "fm-sbt-s3-resolverというプラグインを入れることでS3をMaven Repositoryとして扱えるようになります。社内のサーバにリポジトリを構築するよりお手軽です。\nSetup project/plugin.sbt:\naddSbtPlugin(\u0026#34;com.frugalmechanic\u0026#34; % \u0026#34;fm-sbt-s3-resolver\u0026#34; % \u0026#34;0.5.0\u0026#34;) 事前にAWS_ACCESS_KEY_IDとAWS_SECRET_ACCESS_KEYを環境変数で定義しておくこと。またはProperty Fileを$HOME/.sbt以下に作成しておく。\n$ export AWS_ACCESS_KEY_ID=xxxxxx $ export AWS_SECRET_ACCESS_KEY=xxxxx or $ cat ~/.sbt/.bucket-name_s3credentials accessKey = xxxxxx secretKey = xxxxxx Publish build.sbtにPublish先を設定する。\npublishTo := Some(\u0026#34;Hoge Snapshots\u0026#34; at \u0026#34;s3://hoge-maven.s3-ap-northeast-1.amazonaws.com/hoge/snapshots\u0026#34;) これでsbt publishコマンドでS3にPublishできる。\nUsage resolversにS3に置いたMavenリポジトリを追加する。\nresolvers += \u0026#34;Hoge Snapshots\u0026#34; at \u0026#34;s3://hoge-maven.s3-ap-northeast-1.amazonaws.com/hoge/snapshots\u0026#34; あとはライブラリと同様にlibraryDependenciesに依存関係を書いていくだけ。\nlibraryDependencies ++= Seq( \u0026#34;foo.bar\u0026#34; %% \u0026#34;hoge-project\u0026#34; % \u0026#34;1.0-SNAPSHOT\u0026#34; ) "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2015/03/24/amazon-sns-to-slack.html",
                "title": "CloudWatchやAuto ScalingのアラームをSlackに通知するようにした",
                "section": "post",
                "date" : "2015.03.24",
                "body": "CloudWatchやAuto Scalingのアラームは、Amazon SNSのTopicにPublishする仕組みになっていて、通常はこのTopicに通知先のメールアドレスを設定することが多いと思う。\nメールでもあまり困らないんだけど、社内ではChatOpsを進めていてコミュニケーションツールにSlackを使っているので、ほとんどメールの出番がない。必然的にメーラーよりSlackを立ち上げている時間が長いので、通知系はSlackに集約したくなった。\nこんな感じでチャットに流れてくるようになって満足度高い。\n    念のためメールアドレスにも通知するようにはしているけど、今のところSlackに通知が来なかったり遅れてくることはない。スマートフォンへのプッシュもSlack任せにしている。\n仕組み Amazon SNSから直接Slackにリクエストを送ることは出来ないので、中継サーバを立てる必要がある。今回はSinatraでサクッと実装してHerokuにデプロイして使ってます。中継サーバが死んだ場合は当然通知は来ないので、この辺はそのうち考えたい。\nコードを整理してGitHubに公開したのでご自由に使ってください。CloudWatchとAuto Scaling以外に対応したい場合も簡単に追加できる仕組みにはなってます。PRもお待ちしてます。\ndakatsuka/amazon-sns-to-slack\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2015/02/19/rbenv-sudo.html",
                "title": "rbenv-sudoが便利",
                "section": "post",
                "date" : "2015.02.19",
                "body": "理想\n$ sudo bundle exec rake 現実\n$ sudo bundle exec rake sudo: bundle: command not found sudoで実行すると環境変数が初期化されているので当然の挙動ですが、システムワイドに入れていないrbenv環境下でもroot権限で実行したいことが稀にあります（docker-api使いたいとか\nそういう時はrbenv-sudoを使うと解決します。自分でパスを弄ったりしなくても良いのでお手軽。rbenvのプラグインなので~/.rbenv/pluginsにcloneするだけで使えます。\n$ rbenv sudo bundle exec rake "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2015/01/28/use-packer-on-circleci.html",
                "title": "CircleCIでPackerを使う",
                "section": "post",
                "date" : "2015.01.28",
                "body": "コンテナ起動後にLinux版Packerをダウンロードして、パスの通っている場所に配置すれば動く。毎回Packerをダウンロードするのは無駄なのでキャッシュしておく。\n# circle.yml machine: post: - \u0026#34;if [[ ! -e ~/packer ]]; then cd ~ \u0026amp;\u0026amp; wget --no-check-certificate https://dl.bintray.com/mitchellh/packer/packer_0.7.5_linux_amd64.zip \u0026amp;\u0026amp; unzip -d packer packer_0.7.5_linux_amd64.zip ;fi\u0026#34; - \u0026#34;if [[ ! -e ~/bin/packer ]]; then ln -s ~/packer/packer ~/bin/packer ;fi\u0026#34; dependencies: cache_directories: - ~/packer deployment: production: branch: deployment/production commands: - packer build amazon-ebs.json timeout: 600 AMIの作成は時間がかかるので、念のためタイムアウトの閾値は上げておいたほうが安心。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2014/08/28/symfony2-subdomain.html",
                "title": "Symfony2でサブドメインに対応したサイトを作る",
                "section": "post",
                "date" : "2014.08.28",
                "body": "Symfony2では特定のBundleをサブドメインに切り出すことができる。正しくはBundle毎に任意のドメインを割り当てることができる。もちろん開発用のビルトインサーバでも使うことが可能。\n将来的にサブドメインを使う想定があるならば、事前にBundleは分割しておくと良い。\nExample AcmeWebBundleは www.example.com へ、AcmeSmartphoneBundleは sp.example.com に割り当てるようにする。\nまずapp/config/parameters.yml にドメインを書いておく。パラメータ名は自由に決められるが、今回は下記のようにした。\nparameters: acme.www.host: www.example.com acme.smartphone.host: sp.example.com app/config/routing.ymlでルーティングを下記のように設定する。通常のルーティングの設定にhost項目を増やすだけなので簡単ですね。どちらもprefixは / にしておくこと。\nacme_web: resource: \u0026#34;@AcmeWebBundle/Controller\u0026#34; type: annotation prefix: / host: \u0026#34;%acme.www.host%\u0026#34; acme_smartphone: resource: \u0026#34;@AcmeSmartphoneBundle/Controller\u0026#34; type: annotation prefix: / host: \u0026#34;%acme.smartphone.host%\u0026#34; これでAcmeWebBundleとAcmeSmartphoneBundle内のコントローラには指定したドメイン以外ではアクセス出来なくなる。また Twig の path 関数もよしなにやってくれる。ローカルで動作確認をしたい場合は/etc/hostsやDNSを書き換えて127.0.0.1に向けよう。\nただしローカル開発環境ではサブドメインではなくhttp://localhost:8000/sp/ でアクセス出来るようにしておくと開発しやすいケースもあると思うので、その場合は routing_dev.yml を次のようにする。\n_main: resource: routing.yml acme_web: resource: \u0026#34;@AcmeWebBundle/Controller\u0026#34; type: annotation prefix: / acme_smartphone: resource: \u0026#34;@AcmeSmartphoneBundle/Controller\u0026#34; type: annotation prefix: /sp "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2014/08/24/play2-on-circleci.html",
                "title": "Play framework を CircleCI でテストする",
                "section": "post",
                "date" : "2014.08.24",
                "body": "Play framework 2.3 (Scala版）で開発しているアプリをTravis ProでCIしていたのだけど、ビルド時間がネックになってきたのでインスタンス性能が高いと噂のCircleCIに移行することにした。\nCircleCIの対応言語の中にScalaは入っていないが、Javaが使えるので特に問題はない（何故かちょっと古いsbtが入っていたのでexperimental扱いなのかな？）\ncircle.ymlは下記のようにしてる。\ndependencies: cache_directories: - ~/.m2 - ~/.ivy2 - ~/.sbt override: - \u0026#34;./activator update\u0026#34; database: override: - cp ./conf/test.conf.circleci ./conf/test.conf test: override: - \u0026#34;./activator clean test\u0026#34; deployment: development: branch: master commands: - pip install -r requirements.txt - fab dev deploy Travis ProからCircleCIに移行して、CIにかかる時間が4分の1に短縮されて満足度高い。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2014/08/01/play2-scaldi.html",
                "title": "Play framework 2.3.x と Scaldi で Dependency Injection",
                "section": "post",
                "date" : "2014.08.01",
                "body": "Play2でDIをどうしようか悩んでいたところscaldiというライブラリが目に止まった。Playに組み込むためのライブラリをあるし、公式サイトも作り込まれているし、これは試すしかない。\nただし日本語の情報は無いに等しい。Guiceほどメジャーでもないし人柱感覚で使う必要がありそうだ。\nインストール build.sbtのlibraryDependenciesにscaldiを追加する。\nlibraryDependencies ++= Seq( \u0026#34;org.scaldi\u0026#34; %% \u0026#34;scaldi-play\u0026#34; % \u0026#34;0.4.1\u0026#34; ) インジェクションの種類 コンストラクタ・インジェクションとバインディング・インジェクションの2種類があるようだ。\nコンストラクタ・インジェクション 名前の通り、コンストラクタで依存を受け取るパターン。scaldiに全く依存しないので通常はこのパターンを使うのが良いと思う。\npackage services import repositories.AccountRepository class AccountManager(accountRepository: AccountRepository) バインディング・インジェクション ScaldiのInjector（コンテナ）を暗黙の引数で渡すパターン。コントローラなどはこちらを使う。\npackage controllers import scaldi.{Injectable, Injector} class Application(implicit inj: Injector) extends Controller with Injectable { val accountManager = inject [AccountManager] } モジュールの作成 Injector（コンテナ）にサービスを登録するには Module を作成する必要がある。置く場所はどこでも良いのだがPlayならapp/modulesあたりに入れておくのが分かりやすいと思う。Moduleは複数定義して結合することが出来るので、うまく分割しておけばテストの時だけ別のModuleに差し替えるといったことが可能になる。\npackage modules import scaldi.Module import repositories._ import services._ class ServiceModule extends Module { bind [AccountRepository] to new AccountRepository bind [AccountManager] to new AccountManager(inject[AccountRepository]) } class ControllerInjector extends Module { binding to new Application binding to new FooController binding to new BarController } bindで型を指定してto以降に同一型のオブジェクトを作っていく感じ。inject[型]でbindで登録したものが取り出せるので各サービスのコンストラクタに渡すことが出来る。\nInjectorを暗黙の引数で受け取るクラスはbinding toで指定していく。\nまた下記のようにbindで登録する時にシンボルで名前を付けることが出来る。Configurationのパラメータを登録しておく時に便利だろう。\nbind [String] identifiedBy \u0026#39;secret to Configuration(ConfigFactory.load()).getString(\u0026#34;secret\u0026#34;).getOrElse(\u0026#34;hoge\u0026#34;) 名前をつけたサービスを取り出す時は下記のようにする。\nval secret = inject[String](\u0026#39;secret) モジュールをPlayに登録 scaldi-playは下記のようにGlobalに書いておくことで、リクエストが来た際に依存関係を自動で解決してくれるようになる。\napp/Global.scal\nimport modules._ import play.api.GlobalSetting import scaldi.play.ScaldiSupport object Global extends GlobalSettings with ScaldiSupport { def applicationModule = new ControllerInjector :: new ServiceModule } まとめ Scaldi悪くないと思う。まだ使い出して日が浅いので罠が待ってるかもしれないけど、今のところ問題なく使えてる。DIの選択肢のひとつとしてどうですか。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2014/04/24/vagrant-hdd-resize.html",
                "title": "Vagrant VMのディスクサイズを後から拡張する方法",
                "section": "post",
                "date" : "2014.04.24",
                "body": "前提条件 Vagrant BoxがファイルシステムにLVM + ext3/4を使っていること。今回はVagrantbox.esで配布されているDebian Wheezyを利用した。\n仮想ディスクを拡張する VMDK形式だとサイズを変更することが出来ないのでVDI形式に変換する必要がある。リサイズが完了したらVirtualBoxのVMの設定画面でHDDをVDIのほうに差し替えておく。\n$ cd ~/VirtualBox\\ VMs/vagrant_default_xxxxx_xxxxx $ VBoxManage clonehd box-disk1.vmdk box-disk1.vdi --format VDI $ VBoxManage modifyhd box-disk1.vdi --resize 20480 パーティションテーブルを変更する ここからはゲスト側での操作。\nfdiskで/dev/sdaの容量が増えている事を確認する。\n$ sudo fdisk -l Disk /dev/sda: 21.5 GB, 21474836480 bytes 255 heads, 63 sectors/track, 2610 cylinders, total 41943040 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk identifier: 0x000e1fac Device Boot Start End Blocks Id System /dev/sda1 * 2048 499711 248832 83 Linux /dev/sda2 501758 20764671 10131457 5 Extended /dev/sda5 501760 20764671 10131456 8e Linux LVM /dev/sda2と/dev/sda5の情報を一度削除して再定義する。\n$ sudo fdisk /dev/sda Command (m for help): d Partition number (1-5): 5 Command (m for help): d Partition number (1-5): 2 Command (m for help): n Partition type: p primary (1 primary, 0 extended, 3 free) e extended Select (default p): e Partition number (1-4, default 2): First sector (499712-41943039, default 499712): Using default value 499712 Last sector, +sectors or +size{K,M,G} (499712-41943039, default 41943039): Using default value 41943039 Command (m for help): n Partition type: p primary (1 primary, 1 extended, 2 free) l logical (numbered from 5) Select (default p): l Adding logical partition 5 First sector (501760-41943039, default 501760): Using default value 501760 Last sector, +sectors or +size{K,M,G} (501760-41943039, default 41943039): Using default value 41943039 再定義できているか確認する。\nCommand (m for help): p Disk /dev/sda: 21.5 GB, 21474836480 bytes 255 heads, 63 sectors/track, 2610 cylinders, total 41943040 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk identifier: 0x000e1fac Device Boot Start End Blocks Id System /dev/sda1 * 2048 499711 248832 83 Linux /dev/sda2 499712 41943039 20721664 5 Extended /dev/sda5 501760 41943039 20720640 83 Linux /dev/sda5をLinux LVMに変更する。\nCommand (m for help): t Partition number (1-5): 5 Hex code (type L to list codes): 8e Changed system type of partition 5 to 8e (Linux LVM) Command (m for help): p Disk /dev/sda: 21.5 GB, 21474836480 bytes 255 heads, 63 sectors/track, 2610 cylinders, total 41943040 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk identifier: 0x000e1fac Device Boot Start End Blocks Id System /dev/sda1 * 2048 499711 248832 83 Linux /dev/sda2 499712 41943039 20721664 5 Extended /dev/sda5 501760 41943039 20720640 8e Linux LVM 変更を保存するして再起動する。\nCommand (m for help): wq The partition table has been altered! Calling ioctl() to re-read partition table. WARNING: Re-reading the partition table failed with error 16: Device or resource busy. The kernel still uses the old table. The new table will be used at the next reboot or after you run partprobe(8) or kpartx(8) Syncing disks. $ sudo shutdown -r now LVMの設定をする pvresizeで物理ボリューム /dev/sda5 をリサイズする。pvscanでちゃんと容量が増えていることを確認する。\n$ sudo pvresize /dev/sda5 Physical volume \u0026quot;/dev/sda5\u0026quot; changed 1 physical volume(s) resized / 0 physical volume(s) not resized $ sudo pvscan PV /dev/sda5 VG debian-7 lvm2 [19.76 GiB / 10.10 GiB free] Total: 1 [19.76 GiB] / in use: 1 [19.76 GiB] / in no VG: 0 [0 ] 次に論理ボリュームをリサイズする。論理ボリューム名はlvscanで確認できる。\n$ sudo lvscan ACTIVE '/dev/debian-7/root' [9.21 GiB] inherit ACTIVE '/dev/debian-7/swap_1' [456.00 MiB] inherit $ sudo lvresize -l +100%FREE /dev/debian-7/root Extending logical volume root to 19.31 GiB Logical volume root successfully resized 再度lvscanで容量が増えているか確認する。\n$ sudo lvscan ACTIVE '/dev/debian-7/root' [19.31 GiB] inherit ACTIVE '/dev/debian-7/swap_1' [456.00 MiB] inherit ファイルシステムをリサイズする resize2fsを使ってファイルシステムをリサイズする。\n$ sudo resize2fs /dev/debian-7/root resize2fs 1.42.5 (29-Jul-2012) Filesystem at /dev/debian-7/root is mounted on /; on-line resizing required old_desc_blocks = 1, new_desc_blocks = 2 Performing an on-line resize of /dev/debian-7/root to 5062656 (4k) blocks. The filesystem on /dev/debian-7/root is now 5062656 blocks long. dfで容量が増えていれば完了！\n$ df Filesystem 1K-blocks Used Available Use% Mounted on rootfs 19932432 7272316 11649560 39% / 参考  How to resize a VirtualBox vmdk file - Stack Overflow virtualbox - How can I increase disk size on a Vagrant VM? - Ask Ubuntu 論理ボリュームの管理  "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2014/04/03/symfony2-travis-ci.html",
                "title": "Symfony2アプリをTravisでCIする",
                "section": "post",
                "date" : "2014.04.03",
                "body": ".travis.ymlを下記のようにした。TravisはComposerもPHPUnitもパスが通った状態になっているため、ダウンロードするスクリプトをわざわざ書く必要はない。\nCIの結果をHipChatに通知したい場合はnotificationsで設定するだけで良い。\nlanguage: php php: - 5.5 before_script: - composer install --dev - php app/console doctrine:database:create --env=test - php app/console doctrine:schema:create --env=test script: phpunit -c app notifications: hipchat: secret_token@room_name "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2014/03/03/rails-jasmine-timezone.html",
                "title": "Rails + Jasmineでテスト実行時のタイムゾーンを変更する",
                "section": "post",
                "date" : "2014.03.03",
                "body": "あまりタイムゾーンに依存するテストって宜しくないと思いますが。。。とはいえ特定のタイムゾーンで固定しておきたい事もあるので調べてみた。\nPhantomJSのIssueをみると、TZという環境変数を設定することでタイムゾーンを変更出来るようなので spec/javascripts/support/jasmine_helper.rb に下記コードを追加する。\nENV[\u0026#34;TZ\u0026#34;] = \u0026#34;UTC\u0026#34; これで rake jasmine:ci 実行時は常にUTCになる。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2014/02/13/mongo-mapper-diagram.html",
                "title": "MongoMapperでER図っぽいものを生成するgemを作った",
                "section": "post",
                "date" : "2014.02.13",
                "body": "モデルの数がそれなりにあるプロジェクトに途中から参加すると、モデル同士の関連を把握するのに結構苦労するので、ER図の存在が重要になってくる。ActiveRecordならRails ERDというgemを使えばER図を生成してくれるのだが、MongoMapper用のツールは無さそうだったので作った。\nこんな感じの画像を生成できる。\n  まだ One-To-Many だけで Many-To-Many や Embedded には対応していないのだけど、ひとまず全体を把握するのには役にたった。余裕があれば対応していきたい。Pull requestも待ってます！\n dakatsuka/mongo_mapper_diagram - GitHub  ちなみにグラフの生成には@merborne氏のGvizを使いました。Rubyから簡単にGraphvizが扱えて便利だった。\n使い方 Gemfileに追加。\ngroup :development do gem \u0026#34;mongo_mapper_diagram\u0026#34; end Rakeタスクを実行するとRails.rootにdiagram.pngとdiagram.dotが生成される。\n$ rake mongo_mapper:diagram "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2013/12/24/autocheck-js.html",
                "title": "テキストフィールドへの入力を検出して数秒おきにサーバに送信する",
                "section": "post",
                "date" : "2013.12.24",
                "body": "サインアップフォームなどでユーザー名が取得可能かどうかAjaxで問い合わせるアレです。\n愚直に実装するとkeyupイベントをキャッチして$.ajax()を使うだけですが、これだと1文字入力する毎にサーバのAPIを叩くことになってしまうので少し工夫。\nAjax通信をしたいテキストフィールドにデータ属性を作ってAPIのURLを書いておく。\n\u0026lt;input type=\u0026#34;text\u0026#34; id=\u0026#34;user_username\u0026#34; name=\u0026#34;user[username]\u0026#34; data-autocheck=\u0026#34;/autocheck/username\u0026#34;\u0026gt; JavaScriptは下記のように書く。\n$(document).on(\u0026#34;keyup\u0026#34;, \u0026#34;input[data-autocheck]\u0026#34;, function() { var elem = $(this); var data = { url: elem.data(\u0026#34;autocheck\u0026#34;), value: elem.val() }; clearTimeout(elem.data(\u0026#34;timer\u0026#34;)); elem.data(\u0026#34;timer\u0026#34;, setTimeout(function() { $.ajax({ type: \u0026#34;POST\u0026#34;, url: data.url, data: { value: data.value } }).done(function(result) { }); }, 400)); }); "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2013/12/19/resolve-target-entity.html",
                "title": "Symfony2ではRelationshipsにAbstract classやInterfaceが指定できる",
                "section": "post",
                "date" : "2013.12.19",
                "body": "Doctrine2のOneToManyやManyToManyのtargetEntityにはAbstract classやInterfaceを指定することができる。普通にリファレンスには書いてあるのだが、日本語の情報は無さそうだったので紹介。\nCoreBundle:\n\u0026lt;?php namespace Acme\\CoreBundle\\Entity; use Doctrine\\ORM\\Mapping as ORM; use Acme\\BlogBundle\\Model\\Article as BaseArticle; use Acme\\BlogBundle\\Model\\Comment as BaseComment; /** * @ORM\\Entity * @ORM\\Table(name=\u0026#34;articles\u0026#34;) */ class Article extends BaseArticle {} /** * @ORM\\Entity * @ORM\\Table(name=\u0026#34;comments\u0026#34;) */ class Comment extends BaseComment {} BlogBundle:\n\u0026lt;?php namespace Acme\\BlogBundle\\Model; use Doctrine\\ORM\\Mapping as ORM; use Doctrine\\Common\\Collections\\ArrayCollection; interface ArticleInterface {} interface CommentInterface {} abstract class Article implements ArticleInterface { /** * @ORM\\OneToMany(targetEntity=\u0026#34;Acme\\BlogBundle\\Model\\CommentInterface\u0026#34;, mappedBy=\u0026#34;article\u0026#34;) * @var ArrayCollection */ protected $comments; } abstract class Comment implements CommentInterface { /** * @ORM\\ManyToOne(targetEntity=\u0026#34;Acme\\BlogBundle\\Model\\ArticleInterface\u0026#34;) * @ORM\\JoinColumn(name=\u0026#34;article_id\u0026#34;, referencedColumnName=\u0026#34;id\u0026#34;) * @var ArticleInterface */ protected $article; } app/config/config.yml でInterface（またはAbstract class）と実装したクラスをマッピングする:\ndoctrine: orm: resolve_target_entities: Acme\\BlogBundle\\Model\\ArticleInterface: Acme\\CoreBundle\\Entity\\Article Acme\\BlogBundle\\Model\\CommentInterface: Acme\\CoreBundle\\Entity\\Comment 使いこなせば抽象度の高い汎用的なBundleを作ることができそうですね。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2013/12/16/freelance.html",
                "title": "個人事業主になりました",
                "section": "post",
                "date" : "2013.12.16",
                "body": "無職から個人事業主にジョブチェンジしました。\n自分でサービスの開発もしていきたいですが、当面は傭兵としてサーバサイドプログラミングやインフラ構築、マークアップエンジニア的なことをやっていく予定です。私は営業やセルフブランディングは苦手な方ですが、ありがたい事に数名の方々からお声を掛けて頂き、何とか無事に仕事をスタートさせています。\n以下、あまり役に立たない備忘録。\n銀行口座 最寄りの三菱東京UFJ銀行で事業用口座を開設しました。別支店の個人用口座の中身を覗かれたりやたら時間がかかったりしましたが、無事に開設出来ました。\nところで、前々職でBizSTATIONというネットバンキングに発狂した経験があるのですが、個人用も事業用だとBizSTATIONなんですね。。。Macで使えないからとても渋い。\nクレジットカード 事業用口座から引き落とし出来るカードは、手持ちだとダイナースのビジネスアカウントカードだけだったので、ひとまずこれを利用することにしました。しかしダイナースが利用できないサービス結構多いのでどうしようか考え中です。\n国民健康保険 退職後すぐ切り替え。とんでもない保険料が請求されて白目になっています。\n複合機 ブラザーの複合機をポチりました。FAXは使うか怪しいけど書類の印刷は結構すると思ったので。\n青色申告 年末という微妙な時期に退職して開業したので、早速数ヶ月後に青色申告です。弥生をポチりました。\n弥生は昔、会計システムの保守をしたときに色々触ったので操作とかは問題無さそう。ただ、勘定科目の仕分とか微妙に自信無いので、近場で良い税理士さんが居ないか探しています。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2013/12/07/install-php55-on-mavericks.html",
                "title": "HomebrewでPHP5.5を入れようと思ったら手間取った話",
                "section": "post",
                "date" : "2013.12.07",
                "body": "MavericksにHomebrewを使ってPHP 5.5をインストールしようと思ったら次のようなエラーが出てきた。\nconfigure: error: freetype.h not found. 対処法はHomebrewを更新してfreetypeを消せば良いようだ。同じMavericksでもMBAのほうではエラーが出なかったので、多分バグが混じったバージョンを踏んでしまったんだと思う。\n$ brew update $ brew upgrade $ brew unpin freetype \u0026amp;\u0026amp; brew unlink freetype \u0026amp;\u0026amp; brew rm freetype $ brew install php55 参考\n error freetype.h not found installing php53 · Issue #885 · josegonzalez/homebrew-php  "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2013/12/05/symfony2-functional-test.html",
                "title": "Symfony2でFunctional Testを快適に行うには",
                "section": "post",
                "date" : "2013.12.05",
                "body": "前置き Symfony2を構成するサービスはほぼDIコンテナの上に乗っているので、ドメインとデータベース、フレームワークがそれぞれ疎結合になっています。そのため、ドメインのテストを行う際はフレームワークの読み込みやデータベースに接続する必要はありません。依存部分はモックに置き換えてしまえば良いわけです。\nとはいえ、コントローラやサービスは実際にデータベースに接続してテストを行っておきたいのが人情。モックで置き換えているユニットテストだと動いたけど、結合してみたら動かない…なんてよくある話ですから。\nそしてSymfony2にはWebTestCaseというテスト用のクラスが用意されていて（中身はPHPUnitです）、これを継承したクラスを作ることでSymfony2が読み込まれた状態でテストをすることが可能になります。主にリクエストやルーティング、ビューのテストに使用するのが目的のようですが、ドメインの結合テストにも使うことが出来ます。\nテストデータの投入 Doctrine Data Fixtures Extensionというライブラリを使えば初期データをデータベースに投入することが出来ます。ただ、これは好みの問題かもしれませんが、自分はあまり使い勝手が良いとは思えませんでした。ただデータを投入するだけなら良いのですが、テストで使おうと思うとEntityを毎回findしてこないといけなくて辛い感じがします。getOrder()メソッドで読み込み順を数値で設定するのもどうなの的な。\nなので私はBlueprintBundleという代替ライブラリを作ってそちらを使っています。データベースに保存した上でエンティティを取得出来るので中々便利に使えています。自画自賛。\n\u0026lt;?php Blueprint::register(\u0026#39;post\u0026#39;, \u0026#39;Acme\\BlogBundle\\Entity\\Post\u0026#39;, function($post, $blueprint) { $post-\u0026gt;setTitle(\u0026#39;Title\u0026#39; . $blueprint-\u0026gt;sequence()); $post-\u0026gt;setBody(\u0026#39;BodyBodyBody\u0026#39;); }); $blueprint = static::$container-\u0026gt;get(\u0026#39;dakatsuka.blueprint\u0026#39;); $post1 = $blueprint-\u0026gt;create(\u0026#39;post\u0026#39;); $post2 = $blueprint-\u0026gt;create(\u0026#39;post\u0026#39;); $post3 = $blueprint-\u0026gt;build(\u0026#39;post\u0026#39;); // DBには保存しない データベースのお掃除 ひとつ前のテストケースの影響を受けないようにするために、テスト毎にデータベースを掃除する必要があります。前述のDoctrine Data Fixtures ExtensionのORMPurgerクラスを使うことで実現出来ます。\nちなみにORMPurgerは2種類のモードがあってPURGE_MODE_DELETEかPURGE_MODE_TRUNCATEを選ぶことができます。トランザクションで制御したい場合は、ORMPurgerは使わずにsetUpでトランザクションを開始してtearDownでロールバックする必要があります。\n\u0026lt;?php abstract class FunctionalTest extends WebTestCase { /** * @var \\Symfony\\Component\\HttpKernel\\Kernel */ static protected $kernel; /** * @var \\Symfony\\Component\\DependencyInjection\\Container */ static protected $container; protected function setUp() { parent::setUp(); static::$kernel = static::createKernel(); static::$kernel-\u0026gt;boot(); static::$container = static::$kernel-\u0026gt;getContainer(); static::$container-\u0026gt;get(\u0026#39;doctrine\u0026#39;)-\u0026gt;getManager(\u0026#39;default\u0026#39;)-\u0026gt;beginTransaction(); } protected function tearDown() { parent::tearDown(); static::$container-\u0026gt;get(\u0026#39;doctrine\u0026#39;)-\u0026gt;getManager(\u0026#39;default\u0026#39;)-\u0026gt;rollback(); foreach (static::$container-\u0026gt;get(\u0026#39;doctrine\u0026#39;)-\u0026gt;getConnections() as $connection) { $connection-\u0026gt;close(); } } } テストの数が多くなってくるとDELETEもTRUNCATEも遅くてつらいので、私はトランザクションを使ってテストケース毎にロールバックする方法を取っています。今のところ特に困ったことにはなっていませんので、テストが遅くて困ってる人は試してみる価値はあると思います。\n最後 Symfony2、あまり情報がなくて自分の方法が正しいのか不安になることが多々。間違っていたりもっと良い方法があったら是非教えてください！\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2013/12/01/rewrite-html-for-blog.html",
                "title": "ブログのHTMLを全面的に書き直した",
                "section": "post",
                "date" : "2013.12.01",
                "body": "ヘッダーとフッターを除いたコンテンツをmainタグで括ってみたり、RSSで配信される内容はarticleタグにしたり、投稿日をtimeタグに置き換えたりした。asideとsectionどちらを使用しようか迷ったところもあったけど、articleで括った内容に関連する付加要素をasideにして、右下に出てる簡易プロフィールはsectionにしておいた。多分問題ないだろう。\n今までPureという軽量CSSフレームワークを利用していたのだけど、一部要素にグリッド機能を使っていた程度だったので今回から外すことにした。この手のツールはどうしても余計なdivタグが増えてしまうのが悩みどころ。便利なんだけどね。\nそういう意味ではsemantic-uiはとても良さそうにみえる。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2013/11/27/rails4-rspec-guard-spring.html",
                "title": "Rails4 + RSpec + Guard + SpringでDEPRECATION WARNINGが出たので対処した",
                "section": "post",
                "date" : "2013.11.27",
                "body": "ちょっと前までのRailsのテスト環境といえば、RSpec + Guardという構成が定番だったように思う。最近はこれにSpringを加えるのが流行のようだ。\nそこそこ時間も出来たので、こちらの記事を参考にして、作りかけて放置していたRailsアプリにSpringを組み込んでみたら、動くには動くのだけどDEPRECATION WARNINGが出てしまった。\n22:16:29 - WARN - Guard::RSpec DEPRECATION WARNING: The :spring option is deprecated. Please customize the new :cmd option to fit your need. 調べてみるとGuardfileの書き方が少し変わったらしい。spring-commands-rspecというgemを追加して1行修正するだけ。\n-guard :rspec, spring: true do +guard :rspec, cmd: \u0026#39;spring rspec\u0026#39; do "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2013/11/26/resignation.html",
                "title": "株式会社オルトプラスを退職しました",
                "section": "post",
                "date" : "2013.11.26",
                "body": "Facebookのほうでは2週間程前に告知していたのですが、2013年11月22日付けで株式会社オルトプラスを退職することとなりました。先週まで有給休暇を消化していて、今週の月曜日からは晴れて無職となっております。\n今後はまだ未定です。時間はたっぷりあるのでゆっくり考えようかと。誰かお茶でもしませんか。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2013/11/24/middleman-build-helper.html",
                "title": "Middlemanでビルド時にだけ特定の要素を出力したい場合",
                "section": "post",
                "date" : "2013.11.24",
                "body": "Livereload環境では特に出力しなくても良いもの、または出力されるとマズいものがあったりする。例えばソーシャルサービス系のシェアボタンやGoogle Analyticsのトラッキングコードなど。\nテンプレート内ではMiddleman::Applicationのメソッドが使えるようなのでbuild?メソッドを利用する。\n- if build? :javascript /** Google Analytics Tracking code */ 確認してないけどdevelopment?は逆の動きをしそう。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2013/11/22/change-from-wordpress-to-middleman.html",
                "title": "WordPressからMiddlemanに移行してGitHub Pagesで運用することにした",
                "section": "post",
                "date" : "2013.11.22",
                "body": "今まで惰性でWordPressを使い続けてきたが、ふと思い立ってMiddlemanで全面的に作り直すことにした。折角作り直すのだからブログのデザインもたまには自分でやってみようと思い、数年ぶりにHTMLやCSSを超時間触ることに。最近はネイティブアプリの案件が多く、JSONを吐く仕事ばかりだったので中々刺激的だった。\nMiddleman MiddlemanはJekyllやOctopress同様、静的サイト生成ツールの類いだ。個人的にはMakrdownで記事が書けてGitで管理出来るのが条件だったのでJekyllやOctopressでも良かったのだが、それぞれをローカル環境で試用してみたらMiddlemanが一番しっくりきた。\n用意されているヘルパーなどはRailsに共通しているところが多いし、Asset Pipelineなどの同様の機能もあるので、Railsに慣れ親しんでいる人なら簡単に使いこなせると思う。\n逆にRubyやRailsを全く触ったことない人やWindows環境の人には扱いづらいかもしれない。あと他ツールに比べてドキュメントがやや少ない気もする。凝ったことをしようと思ったらちょっと面倒かも。例えばテンプレートではたくさんのヘルパーを利用出来るが、公式ドキュメントでは全て紹介されていない。\nGitHub Pages username.github.io というサブドメインでホスティング出来ることは知っていたけど、独自ドメインの割り当ても可能だというのは今回初めて知った。masterブランチの直下にドメイン名を記述したCNAMEというファイルを設置するだけでOKだった。お手軽で良いね。\n将来的にはTravis CIでmasterブランチへのPushを自動化しようと考えてるけど、Travisは反映に少しラグが出るし、今の自分の使い方なら当面はmiddleman-deployで事足りるかもしれない。\nDesign Pureという軽量CSSフレームワークを利用してコーディングを行った。Bootstrapよりは出来ることは少ないんだけど、個人ブログ程度なら丁度良いと思う。\n一応IE10, Firefox, Chromeでちゃんと表示されていることを確認しているが、HTML/CSS供に殴り書きに近いので追々綺麗にする。HTML5から使える新しいタグを活用していきたい。\nまとめ ドメイン、デザイン、ブログエンジンを変更して心機一転。記事の語調もですます調からである調に変えてみた。最近更新ペースが落ちていたので、気を取り直してもっと気軽に更新していこうと思う。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2013/10/18/monolog-fluentd.html",
                "title": "Monologのログ出力先をFluentdに変更してみた",
                "section": "post",
                "date" : "2013.10.18",
                "body": "Symfony2にも採用されているMonologは、HandlerやFormatterを差し替えることでログの出力先やフォーマットを自由に変更することが出来ます。PSR3に準拠しているライブラリですので、今後デファクトスタンダードになっていく気がします。\nデフォルトだとStreamHandlerを使って出力されますが、Handlerを自作してFluentdに出力されるように変更してみます。バックエンドにはfluent-logger-phpを利用しました。\nMonologのHandlerはAbstractProcessingHandlerを継承して作ります。\n\u0026lt;?php namespace Acme\\Handler; use Fluent\\Logger\\FluentLogger; use Monolog\\Handler\\AbstractProcessingHandler; use Monolog\\Logger; class FluentHandler extends AbstractProcessingHandler { protected $logger; public function __construct( $logger = null, $host = FluentLogger::DEFAULT_ADDRESS, $port = FluentLogger::DEFAULT_LISTEN_PORT, $level = Logger::DEBUG, $bubble = true ) { parent::__construct($level, $bubble); if (is_null($logger)) { $logger = new FluentLogger($host, $port); } $this-\u0026gt;logger = $logger; } public function write(array $record) { $tag = $record[\u0026#39;channel\u0026#39;] . \u0026#39;.\u0026#39; . $record[\u0026#39;message\u0026#39;]; $data = $record[\u0026#39;context\u0026#39;]; $data[\u0026#39;level\u0026#39;] = Logger::getLevelName($record[\u0026#39;level\u0026#39;]); $this-\u0026gt;logger-\u0026gt;post($tag, $data); } } 使い方\n\u0026lt;?php use Acme\\Handler\\FluentHandler use Monolog\\Logger; $logger = new Logger(\u0026#39;test\u0026#39;); $logger-\u0026gt;pushHandler(new FluentHandler()); $logger-\u0026gt;debug(\u0026#39;example.monolog\u0026#39;, array(\u0026#39;foo\u0026#39; =\u0026gt; \u0026#39;bar\u0026#39;)); $logger-\u0026gt;info(\u0026#39;example.fluentd\u0026#39;, array(\u0026#39;fizz\u0026#39; =\u0026gt; \u0026#39;buzz\u0026#39;)); 利用しやすいようにGitHubとPackagistに公開しておきました。\n dakatsuka/MonologFluentHandler dakatsuka/monolog-fluent-handler  "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2013/09/03/php-maybe-monad.html",
                "title": "ついカッとなってPHPでMaybeモナドを実装した",
                "section": "post",
                "date" : "2013.09.03",
                "body": "PHPを仕事で使っているとis_nullとかissetとかemptyとか===とかの存在にイライラしてくる訳ですよ。そこでなんちゃってMaybeモナドの登場です。\nなんちゃってモナドなので実用性は怪しいですが、以下のように使えます（注意：ネタ記事なので真に受けないように）\n\u0026lt;?php public function testLookupFunction() { $lookup = function($key) { return function(array $d) use($key) { return isset($d[$key]) ? Maybe::ret($d[$key]) : Maybe::ret(); }; }; $dictionary = [\u0026#39;a\u0026#39; =\u0026gt; [\u0026#39;b\u0026#39; =\u0026gt; [\u0026#39;c\u0026#39; =\u0026gt; 10]]]; $result1 = Maybe::ret($dictionary) [$lookup(\u0026#39;a\u0026#39;)] [$lookup(\u0026#39;b\u0026#39;)] [$lookup(\u0026#39;c\u0026#39;)]; $result2 = Maybe::ret($dictionary) [$lookup(\u0026#39;a\u0026#39;)] [$lookup(\u0026#39;Z\u0026#39;)] [$lookup(\u0026#39;c\u0026#39;)]; $this-\u0026gt;assertInstanceOf(\u0026#39;Just\u0026#39;, $result1); $this-\u0026gt;assertInstanceOf(\u0026#39;Nothing\u0026#39;, $result2); $this-\u0026gt;assertEquals(10, $result1-\u0026gt;get()); $this-\u0026gt;assertEquals(10, $result1-\u0026gt;getOrElse(30)); $this-\u0026gt;assertNull($result2-\u0026gt;get()); $this-\u0026gt;assertEquals(30, $result2-\u0026gt;getOrElse(30)); } モナド則（ちょっと自信無いかも）コードからPHPっぽさが消えた気が…\n\u0026lt;?php /** * return a \u0026gt;\u0026gt;= f ≡ f a */ public function testMonadLaw1() { $f = function($a) { return Maybe::ret($a * 3); }; $l = Maybe::ret(5) [$f]; $r = $f(5); $this-\u0026gt;assertEquals($l, $r); } /** * m \u0026gt;\u0026gt;= return ≡ m */ public function testMonadLaw2() { $m = Maybe::ret(5); $l = $m [function($x) { return Maybe::ret($x); }]; $this-\u0026gt;assertEquals($l, $m); } /** * (m \u0026gt;\u0026gt;= f) \u0026gt;\u0026gt;= g ≡ m \u0026gt;\u0026gt;= (\\x -\u0026gt; f x \u0026gt;\u0026gt;= g) */ public function testMonadLaw3() { $f = function($a) { return Maybe::ret($a * 3); }; $g = function($a) { return Maybe::ret($a * 5); }; $m = Maybe::ret(7); $l = $m [$f] [$g]; $r = $m [function($x) use($f, $g) { return $f($x) [$g]; }]; $this-\u0026gt;assertEquals($l, $r); } 実装 まずはMonadクラスを定義します。PHPは演算子のオーバーロードや新たな演算子を定義出来ないので、\u0026gt;\u0026gt;=はoffsetGetメソッドを書き換えて配列のブラケットで代用することにします。ブラケットの中にfunction {}って書けるので超キモイですね。\n\u0026lt;?php abstract class Monad implements \\ArrayAccess { abstract public function bind(callable $f); public function offsetExists($offset) { throw new \\BadMethodCallException(); } public function offsetGet($offset) { return $this-\u0026gt;bind($offset); } public function offsetSet($offset, $value) { throw new \\BadMethodCallException(); } public function offsetUnset($offset) { throw new \\BadMethodCallException(); } } 次はMaybe、Just、Nothingクラスを定義します。NothingはNothingしか存在しないのでシングルトンにしてみました。また、ScalaのOption型で便利だったいくつかのメソッドを実装しています。\n\u0026lt;?php abstract class Maybe extends Monad { protected $value; public static function ret($value = null) { if (is_null($value)) { return Nothing::ret(); } else { return Just::ret($value); } } public function __construct($value) { $this-\u0026gt;value = $value; } public function bind(callable $f) { if ($this instanceof Just \u0026amp;\u0026amp; is_callable($f)) { return $f($this-\u0026gt;value); } else { return $this; } } abstract public function get(); abstract public function getOrElse($default); abstract public function getOrCall(callable $fn); abstract public function getOrThrow(\\Exception $ex); abstract public function isEmpty(); abstract public function isDefined(); } final class Just extends Maybe { public static function ret($value = null) { return new Just($value); } public function get() { return $this-\u0026gt;value; } public function getOrElse($default) { return $this-\u0026gt;get(); } public function getOrCall(callable $fn) { return $this-\u0026gt;get(); } public function getOrThrow(\\Exception $ex) { return $this-\u0026gt;get(); } public function isEmpty() { return false; } public function isDefined() { return true; } } final class Nothing extends Maybe { private static $instance; public function __construct($value = null) { if (static::$instance) { throw new \\InvalidArgumentException(); } } public static function ret($value = null) { if (is_null(static::$instance)) { return static::$instance = new static(); } else { return static::$instance; } } public function get() { return null; } public function getOrElse($default) { return $default; } public function getOrCall(callable $fn) { return $fn(); } public function getOrThrow(\\Exception $ex) { throw $ex; } public function isEmpty() { return true; } public function isDefined() { return false; } } Enjoy functional PHP!"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2013/09/02/php-infinite-list.html",
                "title": "PHPで無限リストを作る",
                "section": "post",
                "date" : "2013.09.02",
                "body": "PHPで range(0, 10000000); とかやるとメモリ不足で死んでしまうので、無限ループするイテレータを作ってみましょう。\n\u0026lt;?php class Stream implements \\Iterator { private $position; private $offset; private $limit; public function __construct($offset, $limit = null) { $this-\u0026gt;position = $offset; $this-\u0026gt;offset = $offset; $this-\u0026gt;limit = $limit; } public function current() { return $this-\u0026gt;position; } public function next() { $this-\u0026gt;position++; } public function valid() { if ($this-\u0026gt;limit \u0026amp;\u0026amp; $this-\u0026gt;position \u0026gt; $this-\u0026gt;limit) { return false; } return true; } public function key() { return $this-\u0026gt;position; } public function rewind() { $this-\u0026gt;position = $this-\u0026gt;offset; } public function take($n) { return new \\LimitIterator($this, 0, $n); } } 無限ループさせる。\n\u0026lt;?php $stream = new Stream(0); foreach ($stream as $i) { echo $i . \u0026#34;\\n\u0026#34;; } =\u0026gt; // 0 // 1 // 2 // 3 // 4 // . // . 範囲指定してみる。\n\u0026lt;?php $stream = new Stream(50, 55); foreach ($stream as $i) { echo $i . \u0026#34;\\n\u0026#34;; } =\u0026gt; // 50 // 51 // 52 // 53 // 54 // 54 LimitIteratorを使えば無限リストから必要な数だけ取り出すことが出来ます。今回はtakeメソッドでラップしました。\n\u0026lt;?php $stream = new Stream(0); foreach ($stream-\u0026gt;take(5) as $i) { echo $i . \u0026#34;\\n\u0026#34;; } =\u0026gt; // 0 // 1 // 2 // 3 // 4 しかしこれだけだとあまり使い道がないので、せめてmap機能は欲しい気がしますね。イテレータオブジェクトにはarray_系の関数が使えませんので、LazyMapIteratorを作ってみます。\n\u0026lt;?php class LazyMapIterator implements \\Iterator { protected $iterator; protected $callback; public function __construct(\\Iterator $iterator, callable $callback) { $this-\u0026gt;iterator = $iterator; $this-\u0026gt;callback = $callback; } public function getIterator() { return $this-\u0026gt;iterator; } public function current(){ $f = $this-\u0026gt;callback; return $f($this-\u0026gt;iterator-\u0026gt;current()); } public function next() { $this-\u0026gt;iterator-\u0026gt;next(); } public function key() { return $this-\u0026gt;iterator-\u0026gt;key(); } public function valid() { return $this-\u0026gt;iterator-\u0026gt;valid(); } public function rewind() { $this-\u0026gt;iterator-\u0026gt;rewind(); } } Streamクラスにmapメソッドを生やします。\n\u0026lt;?php public function map(callable $f) { return new LazyMapIterator($this, $f); } mapメソッドを使ってみます。\n\u0026lt;?php $stream = new Stream(1, 5); $result = $stream-\u0026gt;map(function($i) { return $i * 10; }); var_dump(iterator_to_array($result)); array(5) { [1] =\u0026gt; int(10) [2] =\u0026gt; int(20) [3] =\u0026gt; int(30) [4] =\u0026gt; int(40) [5] =\u0026gt; int(50) } ちなみにPHPはSPLで色々なイテレータが用意されていますので、PHPの残念な配列操作にイラついている方は是非覗いてみてください（CallbackFilterIteratorを使えばfilter機能もすぐ実装できます）\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2013/08/13/doctrine-enum-bundle.html",
                "title": "Symfony2(Doctrine2)でENUMを使うならDoctrineEnumBundleが便利",
                "section": "post",
                "date" : "2013.08.13",
                "body": "DoctrineEnumBundleというBundleを導入することによって、Doctrine2でMySQLのENUM型を扱うことができます。\nインストール composer.jsonにfresh/doctrine-enum-bundleを追加します。\n{ \u0026#34;require\u0026#34;: { \u0026#34;php\u0026#34;: \u0026#34;\u0026gt;=5.3.3\u0026#34;, \u0026#34;symfony/symfony\u0026#34;: \u0026#34;2.3.*\u0026#34;, ........ \u0026#34;fresh/doctrine-enum-bundle\u0026#34;: \u0026#34;dev-master\u0026#34; } } composer.phar installを実行します。\n$ php composer.phar install app/AppKernel.phpにDoctrineEnumBundleを追加します。\n\u0026lt;?php public function registerBundles() { $bundles = [ new Fresh\\Bundle\\DoctrineEnumBundle\\FreshDoctrineEnumBundle() ]; } 使い方 まずEnumTypeクラスを作成します。\n\u0026lt;?php namespace Acme\\DemoBundle\\EnumType; use Fresh\\Bundle\\DoctrineEnumBundle\\DBAL\\Types\\AbstractEnumType; class GenderType extends AbstractEnumType { const MALE = \u0026#39;male\u0026#39;; const FEMALE = \u0026#39;female\u0026#39;; protected $name = \u0026#39;GenderType\u0026#39;; protected static $choices = [ self::MALE =\u0026gt; \u0026#39;男性\u0026#39;, self::FEMALE =\u0026gt; \u0026#39;女性\u0026#39; ]; } app/config/config.yml で上で作ったEnumTypeをDBALに登録します。\ndoctrine: dbal: mapping_types: enum: string types: GenderType: Acme\\DemoBundle\\EnumType\\GenderType あとはENUM型にしたいメンバ変数に対してアノテーションでマッピングし、app/console doctrine:schema:updateを実行すればENUM型のカラムが作られます。\n\u0026lt;?php namespace Acme\\DemoBundle\\Entity; use Doctrine\\ORM\\Mapping as ORM; /** * @ORM\\Table * @ORM\\Entity */ class User { /** * @ORM\\Column(name=\u0026#34;gender\u0026#34;, type=\u0026#34;GenderType\u0026#34;) */ private $gender; } "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2013/08/12/php-mcrypt-is-too-slow.html",
                "title": "PHPのmcrypt関数が遅すぎて辛い",
                "section": "post",
                "date" : "2013.08.12",
                "body": "DES-ECBの暗号・復号を10万回繰り返すベンチマークを取ってみたらmcrypt関数が遅すぎて涙が出てきました。PHPのことなのでもっと速くなる書き方があると淡い期待をしているのですが、何か良い方法無いですかね(´・ω・`)\n\u0026lt;?php $message = \u0026#39;abcdefgh\u0026#39;; $key = \u0026#39;abcdefgh\u0026#39;; for ($i = 0; $i \u0026lt; 100000; $i++) { $encryptedMessage = mcrypt_encrypt(MCRYPT_DES, $key, $message, MCRYPT_MODE_ECB); $decryptedMessage = mcrypt_decrypt(MCRYPT_DES, $key, $encryptedMessage, MCRYPT_MODE_ECB); } 実行してみる。\n$ php -v PHP 5.4.13 (cli) (built: Apr 17 2013 12:40:07) Copyright (c) 1997-2013 The PHP Group Zend Engine v2.4.0, Copyright (c) 1998-2013 Zend Technologies with Xdebug v2.2.1, Copyright (c) 2002-2012, by Derick Rethans $ time php ./bench.php php ./bench.php 24.26s user 0.73s system 99% cpu 25.000 total 24秒…\n同じ処理をPythonで書いてみました。\nimport Crypto.Cipher.DES message = \u0026#34;abcdefgh\u0026#34; key = \u0026#34;abcdefgh\u0026#34; for i in range(100000): cipher = Crypto.Cipher.DES.new(key, Crypto.Cipher.DES.MODE_ECB) encrypted_message = cipher.encrypt(message) decrypted_message = cipher.decrypt(encrypted_message) 実行してみると\n$ python --version Python 2.7.2 $ time python ./bench.py python ./bench.py 0.92s user 0.01s system 99% cpu 0.930 total 1秒かかってませんね。。。RubyでOpenSSL::Cipherを使った場合もPythonとほぼ同速だったのでmcryptが異様に遅いのでしょうか？\n追記 mcrypt関数ではなくOpenSSL関数 openssl_encrypt openssl_decrypt を使えば爆速になることがわかりました。PHP 5.3.0から使えるようなので特に理由がなければOpenSSLを使ったほうが良さそうです。"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2013/03/10/php54-trait-readonly-array.html",
                "title": "PHP 5.4のトレイトで読み取り専用配列を実装してみる",
                "section": "post",
                "date" : "2013.03.10",
                "body": "traitを使って何か作ってみようと思い立ち、読み取り専用の配列を実装してみました。配列として扱いたい（例えばforeachで回したいとか）けど外側からの変更は受け付けたくないというシチュエーションで使えます。\n\u0026lt;?php trait ReadOnlyArray { private $items = []; public function offsetGet($key) { if (!array_key_exists($key, $this-\u0026gt;items)) { throw new OutOfRangeException(); } return $this-\u0026gt;items[$key]; } public function offsetSet($key, $value) { throw new BadMethodCallException(); } public function offsetExists($key) { return isset($this-\u0026gt;items[$key]); } public function offsetUnset($key) { throw new BadMethodCallException(); } public function getIterator() { return new ArrayIterator($this-\u0026gt;items); } public function count() { return count($this-\u0026gt;items); } } 使い方は以下の通り。\n\u0026lt;?php class ExampleArray implements ArrayAccess, IteratorAggregate, Countable { use ReadOnlyArray; public function __construct() { $this-\u0026gt;items[\u0026#34;foo\u0026#34;] = \u0026#34;bar\u0026#34;; } } $example = new ExampleArray(); $example[\u0026#34;foo\u0026#34;]; // =\u0026gt; \u0026#34;bar\u0026#34; $example[\u0026#34;foo\u0026#34;] = \u0026#34;buu\u0026#34;; // =\u0026gt; BadMethodCallException $example-\u0026gt;count(); // =\u0026gt; 1 "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2012/09/13/rails-backbone-intro.html",
                "title": "Rails3にBackbone.jsを導入する",
                "section": "post",
                "date" : "2012.09.13",
                "body": "最近Backbone.jsを触っています。Backbone.jsをRailsで使いたいならパッケージで導入してしまうのが一番簡単でしょう。\nGemfileにrails-backboneを追加してbundle install\nsource \u0026#39;https://rubygems.org\u0026#39; gem \u0026#39;rails\u0026#39;, \u0026#39;3.2.8\u0026#39; gem \u0026#39;mysql2\u0026#39; group :assets do ... end gem \u0026#39;jquery-rails\u0026#39; gem \u0026#39;rails-backbone\u0026#39; # \u0026lt;- 追加 Backbone.jsを組み込みます。\n$ bundle exec rails g backbone:install insert app/assets/javascripts/application.js create app/assets/javascripts/backbone/routers create app/assets/javascripts/backbone/routers/.gitkeep create app/assets/javascripts/backbone/models create app/assets/javascripts/backbone/models/.gitkeep create app/assets/javascripts/backbone/views create app/assets/javascripts/backbone/views/.gitkeep create app/assets/javascripts/backbone/templates create app/assets/javascripts/backbone/templates/.gitkeep create app/assets/javascripts/backbone/app.js.coffee app/assets/javascript/application.js は以下のように変更されます。\n//= require jquery //= require jquery_ujs //= require underscore //= require backbone //= require backbone_rails_sync //= require backbone_datalink //= require backbone/app //= require_tree . この下から2行目、ファイルでは app/assets/javascript/backbone/app.js.coffee が各モデル・ビュー・テンプレートなどを読み込むようになっています（ファイル名はRailsアプリと同じ名前になります）\n#= require_self #= require_tree ./templates #= require_tree ./models #= require_tree ./views #= require_tree ./routers  window.App = Models: {} Collections: {} Routers: {} Views: {} rails-backboneのお作法は（scaffoldで生成されたコードをみる限り）モデル・ビュー・ルーターをディレクトリに分けて管理するようです。そしてその構造がそのまま名前空間になります。\n例えばUserモデルなら app/assets/javascript/backbone/models/user.js.coffee にファイルを作り、下記のようなコードを書いていきます。\nclass App.Models.User extends Backbone.Model url: -\u0026gt; \u0026#34;/api/users/#{@id}\u0026#34; アプリ名が長いと若干タイプが面倒かなーって印象ですが、まぁ app/* と同じ感覚で作れるのでRails慣れしてる人は違和感なく使えそうです。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2012/07/17/dtrace-nodejs.html",
                "title": "OpenIndiana (Solaris) のDTraceでNode.jsをプロファイリングする",
                "section": "post",
                "date" : "2012.07.17",
                "body": "昨年辺りから開発を進めているNodeアプリが大変残念なパフォーマンスだったので、DTraceでプロファイリングしてボトルネックを探してみる作戦です。\nDTraceはSolaris, FreeBSD, Mac OS X辺りに搭載されているのですが、Profiling Node.js を読むとMacでは動かない上に32bitじゃないと駄目、とだいぶ面倒な制約が付いています。ちなみにFreeBSDもNGのようです。\n仕方がないのでOpenSolarisの後継？にあたるOpenIndianaをVirtualBoxで動かす事にしました。\nNode.jsを入れる OpenIndiana自体のインストール方法は割愛します。普通にF2キーを連打していればインストール出来ると思います。。。それにしてもSolarisを触るのなんて何年ぶりだろうか。\nひとまずインストール済みパッケージを最新版に上げて再起動しておきます。\n$ su - # pkg refresh --full # pkg install package/pkg # pkg image-update # reboot GCCとmath.hをインストールします。\n# pkg install gcc-3 # pkg install header-math OpenSSLは入っているはずなんですが、configureした時に無いって怒られるので改めて入れておきます。\n# mkdir -p /usr/local/src # cd /usr/local/src # wget http://www.sunfreeware.com/intel/10/openssl-0.9.8x-sol10-x86-local.gz # gunzip openssl-0.9.8x-sol10-x86-local.gz # pkgadd -d openssl-0.9.8x-sol10-x86-local Nodeのソースを落としてきてインストールします。v0.8.2は謎のエラーを吐いてビルドに失敗するのでv0.6.20にしました。DTraceを有効にするためにconfigureに–with-dtraceオプションを付与してビルドします。\n# wget http://nodejs.org/dist/v0.6.20/node-v0.6.20.tar.gz # tar zxvf node-v0.6.20.tar.gz # cd node-v0.6.20 # ./configure --prefix=/usr/local --with-dtrace # make # make install DTraceの結果をSVGに加工してくれるstackvisを入れておきます。\n# npm install -g stackvis 実際にプロファイリングしてみる 試しにフィボナッチ数列を計算する関数をひたすらぶん回すコードをトレースしてみます。良いコード無くてごめんなさい。\nfunction fib(i) { if (i == 0 || i == 1) { return i; } return fib(i - 1) + fib(i - 2); } while(1) { var result = fib(30); console.log(result); } Nodeを実行します。これは一般ユーザーでも大丈夫です。\n$ node ./fib.js 832040 832040 832040 832040 ...... Nodeプロセスを動作させたまま、別ターミナルでDTraceをroot権限で実行します。60秒間 stacks.out に記録していきます。\n# dtrace -o stacks.out -n 'profile-97/execname == \u0026quot;node\u0026quot; \u0026amp;\u0026amp; arg1/{ @[jstack(100, 8000)] = count(); } tick-60s { exit(0); }' stackvisを使ってstacks.outをSVG化します。\n# stackvis dtrace flamegraph-svg \u0026lt; stacks.out \u0026gt; stacks.svg 生成されたstacks.svgはこちらになりました（縦がコールスタックの深さで横が処理時間の相対的な長さのはず？）\n  WebSocket-Nodeで実装したエコーサーバーをDTraceしてみた結果はこちら。\n  まとめ 処理に時間がかかっている関数がザックリと分かるのでボトルネック探しに重宝しそうです。\nしかしMacで動かないのが惜しい。Solarisってだけでハードルが上がるような気がします。あと何故かNode v0.8.2がビルド出来ないのでそこら辺が今後の課題ですね。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2012/05/14/rails3-rabbitmq.html",
                "title": "Rails3 + unicornからRabbitMQに接続するには",
                "section": "post",
                "date" : "2012.05.14",
                "body": "ruby-amqpはEventMachineに依存しているので、unicorn上のRailsアプリからRabbitMQに接続する場合は少し手間がかかります。EventMachineで実装されているThinなどはそのまま動くようですが。。。\n下記コードをconfig/unicorn.rbに追記します。\nENV[\u0026#34;UNICORN\u0026#34;] = \u0026#34;true\u0026#34; after_fork do |server, worker| AMQPManager.start end config/amqp.ymlを用意します。\ndevelopment: uri: \u0026#34;amqp://localhost\u0026#34; 開発環境（WebRickなど）からもRabbitMQに接続出来るようにします。\n# config/initializers/amqp.rb require \u0026#39;amqp/utilities/event_loop_helper\u0026#39; require \u0026#39;amqp/integration/rails\u0026#39; module AMQPManager def self.start AMQP::Utilities::EventLoopHelper.run AMQP::Integration::Rails.start do |connection| connection.on_error do |ch, connection_close| raise connection_close.reply_text end connection.on_tcp_connection_loss do |conn, settings| conn.reconnect(false, 2) end connection.on_tcp_connection_failure do |conn, settings| conn.reconnect(false, 2) end channel = AMQP::Channel.new(connection, AMQP::Channel.next_channel_id, :auto_recovery =\u0026gt; true) channel.on_error do |ch, channel_close| raise channel_close.reply_text end AMQP.channel = channel end end end AMQPManager.start unless ENV[\u0026#34;UNICORN\u0026#34;] コントローラからパブリッシュする場合は下記のようにします。\n# coding: utf-8 class AmqpController \u0026lt; ApplicationController def publish AMQP::Utilities::EventLoopHelper.run do AMQP.channel.default_exchange.publish(\u0026#34;Hello World!!!!!\u0026#34;, routing_key: \u0026#34;queue.name\u0026#34;) end head :created end end "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2012/04/18/rabbitmq-cluster-on-ec2.html",
                "title": "Ubuntu on EC2でRabbitMQクラスタを構築する手順",
                "section": "post",
                "date" : "2012.04.18",
                "body": "EC2 で動かしている Ubuntu Server 11.10 に RabbitMQ クラスタを構築したのでその時の手順をブログに残しておきます。ホスト名の設定で若干手こずりました…。\nRabbitMQをインストール オフィシャルで配布されているパッケージを使うのがお手軽です。\ncd /tmp wget wget http://www.rabbitmq.com/releases/rabbitmq-server/v2.8.1/rabbitmq-server_2.8.1-1_all.deb sudo apt-get install erlang-nox sudo dpkg -i rabbitmq-server_2.8.1-1_all.deb 下記コマンドでエラーが出なければ、正常にRabbitMQが起動しています。\nsudo rabbitmqctl status RabbitMQの初期設定 RabbitMQはデフォルトでノード名がインストールしたサーバのhostname -sになっています。このノード名を変更するには /etc/rabbitmq/rabbitmq-env.conf でNODENAMEを指定すれば良いのですが、何故かNODENAMEにはFQDNが使えません。\nこのままだと、別のRabbitMQサーバをクラスタに追加する時にノード名の不一致が起き、正常に追加出来ないという罠が待っています。まぁ、/etc/hosts に全サーバのホスト名を書いていけば問題無いのですが、EC2だとインスタンスの再起動でIPとホスト名が変わったりするので、あまり現実的ではありませんね。極力ドメイン名で処理したいところです。\nそこで /etc/rabbitmq/rabbitmq-env.conf でFQDNが使えるようにRabbitMQ本体に若干手を加えます。といってもオプションを書き換えるだけです。\n書き換える前にサーバを停止しておきます。\nsudo /etc/init.d/rabbitmq-server stop /usr/lib/rabbitmq/lib/rabbitmq_server-2.8.1/sbin/rabbitmq-server\n--- rabbitmq-Server2012-04-18 16:17:39.168100001 +0900 +++ rabbitmq-Server2012-04-18 16:17:13.304100001 +0900 @@ -102,7 +102,7 @@  exec erl \\ ${RABBITMQ_EBIN_PATH} \\ ${RABBITMQ_START_RABBIT} \\ - -sname ${RABBITMQ_NODENAME} \\ + -name ${RABBITMQ_NODENAME} \\  -boot ${RABBITMQ_BOOT_FILE} \\ ${RABBITMQ_CONFIG_ARG} \\ +W w \\ /usr/lib/rabbitmq/lib/rabbitmq_server-2.8.1/sbin/rabbitmqctl\n--- rabbitmqctl2012-04-18 16:12:54.016100001 +0900 +++ rabbitmqctl2012-04-18 16:12:32.828100000 +0900 @@ -31,7 +31,7 @@  -noinput \\ -hidden \\ ${RABBITMQ_CTL_ERL_ARGS} \\ - -sname rabbitmqctl$$ \\ + -name rabbitmqctl$$ \\  -s rabbit_control \\ -nodename $RABBITMQ_NODENAME \\ -extra \u0026#34;$@\u0026#34; /etc/rabbitmq/rabbitmq-env.conf は下記のようにします。\nNODENAME=rabbit@rabbit1.foo.bar.internal これでRabbitMQを再度起動させてエラーが出なければ設定完了です。\nクラスタ化する rabbit1.foo.bar.internal と rabbit2.foobar.internal に対して、上記手順に則ってRabbitMQをインストールしたと仮定します。\nrabbit1を初期化する\nrabbit1% sudo rabbitmqctl stop_app rabbit1% sudo rabbitmqctl reset rabbit1上でrabbit2をクラスタに参加させる\nrabbit1% sudo rabbitmqctl cluster rabbit2.foo.bar.internal rabbit1% sudo rabbitmqctl start_app クラスタに追加されているか確認する\nrabbit1% sudo rabbitmqctl cluster_status Cluster status of node 'rabbit@rabbit1.foo.bar.internal' ... [{nodes,[{disc,['rabbit@rabbit2.foo.bar.internal']}, {ram,['rabbit@rabbit1.foo.bar.internal']}]}, {running_nodes,['rabbit@rabbit2.foo.bar.internal', 'rabbit@rabbit1.foo.bar.internal']}] ...done. 追加されてますね。rabbit2からも確認してみます。\nrabbit2% sudo rabbitmqctl cluster_status Cluster status of node 'rabbit@rabbit2.foo.bar.internal' ... [{nodes,[{disc,['rabbit@rabbit2.foo.bar.internal']}, {ram,['rabbit@rabbit1.foo.bar.internal']}]}, {running_nodes,['rabbit@rabbit1.foo.bar.internal', 'rabbit@rabbit2.foo.bar.internal']}] ...done. これでrabbit1, rabbit2どちらに接続してもキューをpublish, subscribeすることが出来ます。クラスタ化自体はそこまで難しくないと思います。\n詳しくはオフィシャルドキュメントに全部書いてあるので、そちらを参照してください。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2012/03/07/sharding-mongoose.html",
                "title": "シャーディング環境で Mongoose を使う",
                "section": "post",
                "date" : "2012.03.07",
                "body": "MongooseでSchemaを定義する時に、Shard keyの情報を渡してあげる事で insert, update, remove等の処理がTargetedオペレーションで実行されるようになります。便利ですね。\nvar mongoose = require(\u0026#39;mongoose\u0026#39;) , Schema = mongoose.Schema , ObjectId = Schema.ObjectId; var Footprint = new Schema({ user_id: { type: ObjectID }, visitor_id: { type: ObjectID }, seconds: { type: Number, default: (new Date()).getSeconds() }, created_at: { type: Date, default: Date.now } }, { shardkey: { user_id: 1, seconds: 1 } }); ※ シャーディングの設定自体は予めMongoDB側で済ませておく必要があります。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2012/01/10/node-uuid.html",
                "title": "Node.jsでUUIDを生成するには",
                "section": "post",
                "date" : "2012.01.10",
                "body": "node-uuid というモジュールを使うことで手軽に生成出来ます。Node.js で分散ネットワークを構築したい時に活躍しそうです。\n使い方 npm でインストールできます。\nnpm install node-uuid サンプル\nvar uuid = require(\u0026#39;node-uuid\u0026#39;); console.log(uuid.v1()); // =\u0026gt; eb6b8030-3b57-11e1-9c04-c9b9178cf34e console.log(uuid.v4()); // =\u0026gt; 4d9a29f8-8993-40cd-819b-862b9c7b78b2 UUIDの本来の目的とは違いますが、加工して32文字のランダムな文字列としても使えますね（パフォーマンス的にどうなのかは未検証です）\nvar uuid = require(\u0026#39;node-uuid\u0026#39;); var rand = uuid.v4().split(\u0026#39;-\u0026#39;).join(\u0026#39;\u0026#39;); // 661708030ec74627a12d3f6c6f8f5dd2 "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2011/12/08/chef-install.html",
                "title": "Chefで始めるシステム構成管理入門 その2 – インストールと初期設定",
                "section": "post",
                "date" : "2011.12.08",
                "body": "前回に引き続き Chef に関するエントリです。このエントリではChef Serverのインストールと初期設定、更にNodeの接続までを書いていこうと思います。自分のメモ書きを整理して書き出しているので、何かおかしな箇所があったら是非指摘してください！\nさて、作業を進めていく上で複数のマシンが出てくるので、便宜上、下図のようなネットワーク構成にしようと思います。192.168.50.100はグローバルIPだと思ってください。また、Chef Server, 各Nodeは全てUbuntu 11.10 Serverと仮定します（Debian squeezeでも大丈夫）。\n  Chef Server はパッケージシステムからインストールするのが無難 前回の「Chefの仕組み」でも書いたように、自力で Chef Server をセットアップするのは骨が折れます。サーバの構築を自動化したいのに肝心のChefで手間取るなど本末転倒ですね。なるべくならディストリビューション付属のパッケージシステムで導入したいところです。\n有り難いことに開発元の Opscode が、Debina/Ubuntu用のAPT Repositoryを提供して下さっていますので迷わず利用しましょう。…CentOSは…美味しいんでしょうか…\n作業手順は下記の通り。まずChef ServerにSSHでログインし、KeyとRepositoryを登録して apt-get で chef-server をインストールします。\n# Ubuntu chefserver:$ echo \u0026quot;deb http://apt.opscode.com/ `lsb_release -cs`-0.10 main\u0026quot; | sudo tee /etc/apt/sources.list.d/opscode.list # Debian chefserver:$ echo \u0026quot;deb http://apt.opscode.com/ squeeze-0.10 main\u0026quot; | sudo tee /etc/apt/sources.list.d/opscode.list chefserver:$ sudo apt-get update chefserver:$ sudo apt-get install opscode-keyring chefserver:$ sudo apt-get update chefserver:$ sudo apt-get install chef-server インストールの途中で3回質問が出ますので入力が必要になります。\n  これはChef Server内にインストールされるChef ClientからみたChef Server APIのURIを入力します。同一サーバなのでここでは http://localhost:4000 と入力してください。\n  AMQP Server（RabbitMQ）のパスワードを入力します。任意の文字列を入力してください。ここで入力したパスワードは /etc/chef/solr.rb 内に記述されます。\n  WebUIの初期ユーザー（admin）のパスワードを設定します。任意の文字列を入力してください。\nインストールが無事終わるとChef Serverが自動的に立ち上がります。結構な量のパッケージが入りますので多少時間がかかると思います。\n管理用Clientを登録する Chef Serverのインストールが終わったら管理用Clientを登録します。ここで登録するClientはChef Server内でのみ使用します。\nまずホームディレクトリに.chefディレクトリを作成し、鍵二種類を/etc/chefからコピーしてきます。\nchefserver:$ mkdir -p ~/.chef chefserver:$ sudo cp /etc/chef/validation.pem /etc/chef/webui.pem ~/.chef chefserver:$ sudo chown -R $USER:$USER ~/.chef そのあとにknifeコマンドで初期設定を行います。\nchefserver:$ knife configure -i WARNING: No knife configuration file found Where should I put the config file? [~/.chef/knife.rb] [ENTER] Please enter the chef server URL: [http://chefserver:4000] http://localhost:4000 Please enter a clientname for the new client: [username] master Please enter the existing admin clientname: [chef-webui] [ENTER] Please enter the location of the existing admin client's private key: [/etc/chef/webui.pem] /home/username/.chef/webui.pem Please enter the validation clientname: [chef-validator] [ENTER] Please enter the location of the validation key: [/etc/chef/validation.pem] /home/username/.chef/validation.pem Please enter the path to a chef repository (or leave blank): [ENTER] Creating initial API user... Created client[master] Configuration file written to /home/username/.chef/knife.rb これでmasterという管理用Clientが登録されました。試しに下記コマンドを叩いてみましょう。\nchefserver:$ knife client list 次のように返ってくれば成功です。\nchefserver:$ knife client list chef chef-validator chef-webui master Clientの詳細をみることも出来ます。\nchefserver:$ knife client show master _rev: 1-2901b7c2eb6d33b01f8f12951933b709 admin: true chef_type: client json_class: Chef::ApiClient name: master public_key: -----BEGIN RSA PUBLIC KEY----- snip -----END RSA PUBLIC KEY----- ローカル環境用に管理用Clientを作成する 今後、Chefの操作はほぼKnifeコマンドで行う事になるのですが、毎回サーバにログインして作業するのは微妙です。Cookbookなどは別の環境で作成してGitなどのSCMで管理したいですよね。\nですので別の環境からでもアクセス出来る管理用Clientを作成したいと思います。\n下記コマンドを実行しましょう。これはakatsukaという管理用Clientを作成するコマンドになります。Client名は適宜置き換えて下さい。\nchefserver:$ knife client create akatsuka -n -a -f /tmp/akatsuka.pem Created client[akatsuka] ちゃんと作成出来ているか確認します。\nchefserver:$ knife client list akatsuka chef chef-validator chef-webui master あとは上記コマンドで生成された/tmp/akatsuka.pemと~/.chef/validation.pemの二つの鍵をSCPなどでローカル環境にコピーしてください。\nローカル環境の準備 ローカル環境側はknifeコマンドを使うだけですので、RubyとRubygemsが入っていればgem installだけで済みます（Rubyのインストールは割愛します）。\nworkstation:$ gem install chef インストールが終わったら先ほどSCPで持ってきた akatsuka.pem と validation.pem を ~/.chef にコピーして、下記コマンドを実行します。\nworkstation: $ knife configure WARNING: No knife configuration file found Where should I put the config file? [~/.chef/knife.rb] [ENTER] Please enter the chef server URL: [http://workstation:4000] http://192.168.50.100:4000 Please enter an existing username or clientname for the API: [username] akatsuka Please enter the validation clientname: [chef-validator] [ENTER] Please enter the location of the validation key: [/etc/chef/validation.pem] /Users/username/.chef/validation.pem Please enter the path to a chef repository (or leave blank): [ENTER] ***** You must place your client key in: /Users/username/.chef/akatsuka.pem Before running commands with Knife! ***** You must place your validation key in: /Users/username/.chef/validation.pem Before generating instance data with Knife! ***** Configuration file written to /Users/username/.chef/knife.rb ローカル環境からでも接続出来るか確認してみましょう。\nworkstation:$ knife client list akatsuka chef chef-validator chef-webui master Chef Server APIをHTTPSにしてセキュアにする Chef Server APIのプロトコルは普通のHTTPなので、フロントエンドに nginx を置いてHTTPSに対応させます。\nchefserver:$ sudo apt-get install nginx OpenSSLを使って鍵を生成します。\nchefserver:$ cd /etc/nginx chefserver:$ sudo mkdir ssl chefserver:$ sudo openssl req -new -key ssl/server.key -out ssl/server.csr chefserver:$ sudo openssl x509 -in ssl/server.csr -out ssl/server.crt -req -signkey ssl/server.key -days 365 chefserver:$ sudo chmod 400 ssl/server.* nginxのデフォルトファイルを削除します。\nsudo rm -rf /etc/nginx/sites-enabled/default /etc/nginx/conf.d/proxy.confを作成します。\n# /etc/nginx/conf.d/proxy.conf proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-Host $host; proxy_set_header X-Forwarded-Server $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto https; /etc/nginx/sites-available/sslを作成します。\n# /etc/nginx/sites-available/ssl server { listen 443; server_name localhost; ssl on; ssl_certificate /etc/nginx/ssl/server.crt; ssl_certificate_key /etc/nginx/ssl/server.key; ssl_session_timeout 5m; ssl_protocols SSLv2 SSLv3 TLSv1; ssl_ciphers ALL:!ADH:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP; ssl_prefer_server_ciphers on; location / { proxy_pass http://127.0.0.1:4000/; } } 上で作ったファイルのシンボリックリンクを/etc/nginx/sites-enabled内に作成します。\nchefserver:$ sudo ln -s /etc/nginx/sites-available/ssl /etc/nginx/sites-enabled/ssl nginxを起動させます。\nchefserver:$ sudo /etc/init.d/nginx start これでChef ServerはHTTPS対応になりました。ローカル環境のほうもHTTPSで繋がるように変更しておきましょう。~/.chef/knife.rbを開いてchef_server_urlの値を修正します。\n-chef_server_url \u0026#39;http://192.168.50.100:4000\u0026#39; +chef_server_url \u0026#39;https://192.168.50.100\u0026#39; まとめ うーん・・・。書いていて思ったのはやはり手間ですね！もう少し何とかならないものか・・・。あと完全にWebUIをスルーしておりますが、今後もスルーする方向で行こうと思っています。理由は、WebUIだけだと出来ない事がある、何故かOpenIDを使ってログイン出来てしまう（致命的なような…）、そもそも使い勝手的にどうなんだ、といったところです。あと設定ファイルもローカルに残らないのでそれもマイナスですね。\nさて、次はいよいよNodeを登録して実際にレシピを書いていこうと思います。年内に書ければいいなぁ\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2011/12/05/chef-introduction.html",
                "title": "Chefで始めるシステム構成管理入門 その1",
                "section": "post",
                "date" : "2011.12.05",
                "body": "最近 Chef というシステムの構成を自動で管理するツールを使い始めました。同様のツールとして Puppet が有名ですが、レシピを内部DSLで記述出来るほうが自分には合っていると思ったので、今回は Chef を採用しました。折角覚えたので復習も兼ねてエントリを起こしてみます。このエントリがChefの導入を検討している方への手助けになれば幸いです。\nChefの仕組み – 意外と依存関係が面倒なChef Server   Chefの基本的な仕組みは、サーバに設定を置き、クライアントがサーバに問い合わせるPull型のシステムです。クライアントはサーバからのレスポンスに従いパッケージのインストールなどを行います。しかし、Chef ServerはRuby(Merb), CouchDB, RabbitMQなど依存が多く、お世辞にもシンプルなシステムとは言えません。そのせいかネットで検索して出てくる情報もサーバを必要としない Chef-Solo を使ったものが多い印象です。\n最低限覚えておきたい用語 Chefをインストールする前に覚えておきたい用語集です。たくさんありますがどれもChefを使いこなすためには必須の用語と言えるでしょう。ざっくりと概要を書いてみます。\nknife Chef Server上で使用する管理コマンドです。後述のClinet, Node, Environmentなど全てこのコマンドで制御します。\nClient Chef Serverに接続するもの全てを指します。Chef Serverからみた場合、Chefで管理するサーバ群は勿論のこと、knifeコマンドを使用する管理者もClinetになります。\nNode Nodeは、Chef Serverに接続するClientのうち、Chefで管理するサーバ／マシンを指します。Clientとごっちゃになりやすいので注意。\n  ClientとNodeの関係を図で表すと上のようなイメージになります。\nAttributes Attributesは、NodeのKernelのバージョンやディストリビューションの種類・バージョン、IPアドレスなどの様々な情報が記述されています。これらの情報はCookbookから参照することが可能で、Cookbook, Role, Environmentで値を追加・上書きすることも出来ます。\nCookbook Cookbookは、NodeにソフトウェアをインストールためのレシピでChefのメイン機能ですね。実際はインストールだけではなくてサーバの各種設定を変更したりユーザーやグループを作成したりと何でも出来ます。ERBで記述するTemplatesを使って動的に*.confを生成する事も可能です。CookbookはNodeに直接割り当てるか、もしくはRole経由で使用します。\nRole Roleは、Cookbookを複数束ねることができ、同じ構成のNodeをたくさん作るときに使用します。例えば昨今のWebサービスですと proxy, app, db という風に定義をするとイイ感じです。RoleはNodeに対して複数割り当てることが可能です。\nEnvironment Environmentは、環境名を定義してNodeに割り当てる事ができます。RailsのEnvironmentと同じ概念ですね。環境毎にAttributesの値を変えたり、使用するCookbookのバージョンを指定・固定したり出来ます。本番環境とステージング環境ではデータベースのアドレスが違うだけなんて構成はよくあると思いますが、そういう時にこのEnvironmentが活躍します。\nEnvironmentとRoleを制する者はChefを制す（大げさ）\n と、長くなったのでその1はここで終了です。その2では実際にChef Serverをインストールして環境を整えるところまで書こうと思います。多分今週中には…\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2011/11/25/express-pjax.html",
                "title": "Express + jQueryでpjaxを使う",
                "section": "post",
                "date" : "2011.11.25",
                "body": "先日、暇つぶしに Express で噂の pjax を使って遊んでみました。pjax 自体は jquery-pjax を使う事で手間をかけずに実現出来ますね。サーバ側もHTTPリクエストヘッダにX-PJAXがあるかどうか判定し、あった場合はlayout: falseとするだけなのでとても簡単です。\napp.js のコードはこんな感じに。\napp.get(\u0026#39;/\u0026#39;, function(req, res) { if (req.header[\u0026#39;X-PJAX\u0026#39;]) { res.render(\u0026#39;index\u0026#39;, { layout: false }); } else { res.render(\u0026#39;index\u0026#39;); } }); しかし毎回if文を書くのも面倒なので、pjaxなリクエストが来た時だけlayout: falseになるようにrenderメソッドをラップした新しいメソッドを作成しました。npmでインストール出来ます。\nnpm install express-pjax 使い方：\nvar express = require(\u0026#39;express\u0026#39;); var pjax = require(\u0026#39;express-pjax\u0026#39;); var app = express.createServer(); app.configure(function() { app.use(pjax()); }); app.get(\u0026#39;/\u0026#39;, function(req, res) { res.renderPjax(\u0026#39;index\u0026#39;, { locals: { hello: \u0026#34;Hello World!\u0026#34; } }); }); 本当はrender自体をカスタマイズしたかったのですが、Expressのソースを見た限りではちょっと難しそうだったので新たにrenderPjaxというメソッドを作りました。そのうちリダイレクトにも対応したいですね。\n dakatsuka/express-pjax – GitHub  "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2011/10/20/simplecov.html",
                "title": "Ruby 1.9.2 + Rails3でテストカバレッジを取るにはSimpleCovが良さそう",
                "section": "post",
                "date" : "2011.10.20",
                "body": "Ruby (Rails) でテストカバレッジといえば Rcov ですね。\nしかし Rcov は Ruby 1.9.x に非対応なので Ruby 1.9.2 + Rails3 な環境で開発をしている方は SimpleCov を使うと幸せになれます。名前にSimpleと付いていますが高機能で見た目も綺麗です。また simplecov-rcov を併用すれば Rcov のフォーマットで出力することも出来るので、Jenkins などのCIツールとの連携も難しくないはずです。\n colszowka/simplecov – GitHub fguillen/simplecov-rcov – GitHub  使い方 Gemfileに下記コードを追加してbundle installします。\ngroup :test do gem \u0026#34;simplecov\u0026#34;, :require =\u0026gt; false end spec/spec_helper.rb の最上位に下記コードを追記します。\nrequire \u0026#39;simplecov\u0026#39; SimpleCov.start \u0026#39;rails\u0026#39; 準備完了。rake specを実行すれば coverage ディレクトリの中に結果が生成されています。\nそういえば 以前 cover_me の紹介記事を書いた事を今更思い出しました。こちらのライブラリも引き続き開発が続けられているようです。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2011/10/13/node-cap-upstart.html",
                "title": "Node.js アプリをデプロイして Upstart で起動させる Capistrano レシピを書いた",
                "section": "post",
                "date" : "2011.10.13",
                "body": "Node.js アプリをデプロイする場合、Heroku などの PaaS を使っているとすごく簡単なのですが、デプロイ先が VPS や専用サーバの場合、何かしらのツールを使ってデプロイをする事になると思います。\n今回はデプロイツールに Capistrano を使うことにしました。ただ、Capistrano はそのままだと Rails 用になっているので、Node.js 用に少しレシピを書き換えます。ちなみに当初の予定では起動・監視ツールに Node.js製の Forever を使うはずだったのですが、v0.5系でうまく動作しなかったので急遽 Upstart で代用することにしました。他にも Upstart + God という組み合わせも良さそうですがまだ未検証。\n# This program is free software. It comes without any warranty, to # the extent permitted by applicable law. You can redistribute it # and/or modify it under the terms of the Do What The Fuck You Want # To Public License, Version 2, as published by Sam Hocevar. See # http://sam.zoy.org/wtfpl/COPYING for more details. set :application, \u0026#34;nodeapp\u0026#34; set :scm, :git set :repository, \u0026#34;git://github.com:hogehoge/foobar.git\u0026#34; set :branch, \u0026#34;master\u0026#34; set :deploy_via, :remote_cache set :deploy_to, \u0026#34;/home/nodeapp/#{application}\u0026#34; set :node_path, \u0026#34;/opt/node-current/bin\u0026#34; set :node_script, \u0026#34;app.js\u0026#34; set :user, \u0026#34;nodeapp\u0026#34; set :use_sudo, true set :default_run_options, :pty =\u0026gt; true role :app, \u0026#34;xxx.xxx.xxx.xxx\u0026#34; set :shared_children, %w(log node_modules) namespace :deploy do task :default do update start end task :cold do update start end task :setup, :expect =\u0026gt; { :no_release =\u0026gt; true } do dirs = [deploy_to, releases_path, shared_path] dirs += shared_children.map { |d| File.join(shared_path, d) } run \u0026#34;mkdir -p #{dirs.join(\u0026#39; \u0026#39;)}\u0026#34; run \u0026#34;chmod g+w #{dirs.join(\u0026#39; \u0026#39;)}\u0026#34; if fetch(:group_writable, true) end task :finalize_update, :except =\u0026gt; { :no_release =\u0026gt; true } do run \u0026#34;chmod -R g+w #{latest_release}\u0026#34; if fetch(:group_writable, true) run \u0026lt;\u0026lt;-CMD  rm -rf #{latest_release}/log #{latest_release}/node_modules \u0026amp;\u0026amp; ln -s #{shared_path}/log #{latest_release}/log \u0026amp;\u0026amp; ln -s #{shared_path}/node_modules #{latest_release}/node_modules CMD end task :start, :roles =\u0026gt; :app do run \u0026#34;#{sudo}restart #{application}|| #{sudo}start #{application}\u0026#34; end task :stop, :roles =\u0026gt; :app do run \u0026#34;#{sudo}stop #{application}\u0026#34; end task :restart, :roles =\u0026gt; :app do start end task :npm, :roles =\u0026gt; :app do run \u0026lt;\u0026lt;-CMD  export PATH=#{node_path}:$PATH \u0026amp;\u0026amp; cd #{latest_release} \u0026amp;\u0026amp; npm install CMD end task :write_upstart_script, :roles =\u0026gt; :app do upstart_script = \u0026lt;\u0026lt;-UPSTART_SCRIPT description \u0026#34;#{application}upstart script\u0026#34; start on (local-filesystem and net-device-up) stop on shutdown respawn respawn limit 5 60 script chdir #{current_path} exec sudo -u #{user} NODE_ENV=\u0026#34;production\u0026#34; #{node_path}/node #{node_script} \u0026gt;\u0026gt; log/production.log 2\u0026gt;\u0026amp;1 end script UPSTART_SCRIPT put upstart_script \u0026#34;/tmp/#{application}.conf\u0026#34; run \u0026#34;#{sudo}mv /tmp/#{application}.conf /etc/init\u0026#34; end end after \u0026#39;deploy:setup\u0026#39;, \u0026#39;deploy:write_upstart_script\u0026#39; after \u0026#39;deploy:finalize_update\u0026#39;, \u0026#39;deploy:npm\u0026#39; 使い方 set :node_pathで Node.js がインストールされているパスを指定し、set :node_scriptで起動したいJSファイルを指定します。あとの項目は通常のデプロイと変わらないと思います（上のレシピはGit前提で書いていますが）\nデプロイ先に必要なディレクトリや Upstart のスクリプトを作成するには下記コマンドを使います。\ncap deploy:setup デプロイしてアプリを起動するには下記コマンドを使います。リポジトリに package.json を置いておけば自動的にnpm installが動いて node_modules にインストールされます。\ncap deploy:cold 以上です。それでは、良い Node.js 生活を。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2011/10/06/node-fakeweb.html",
                "title": "Node.jsで使えるHTTP偽装モジュール node-fakeweb",
                "section": "post",
                "date" : "2011.10.06",
                "body": "主に外部のAPIが絡んでくるアプリのテストに使えるモジュールです。Node.jsの標準モジュールであるhttpではなく、requestというモジュール経由のHTTPアクセスを乗っ取ってレスポンスを偽装します。\n ctide/fakeweb – GitHub  npmで入れることが出来ます。\nnpm install request node-fakeweb 使い方は下記のようにします。\nvar request = require(\u0026#39;request\u0026#39;); var fakeweb = require(\u0026#39;node-fakeweb\u0026#39;); fakeweb.allowNetConnect = false; fakeweb.registerUri({ uri: \u0026#34;http://www.google.co.jp:80/\u0026#34;, statusCode: 200, body: \u0026#34;Hello World!\u0026#34; }); request.get({uri: \u0026#34;http://www.google.co.jp:80/\u0026#34;}, function(err, response, body) { console.log(\u0026#34;StatusCode:\u0026#34; + response.statusCode); console.log(\u0026#34;Body:\u0026#34; + body); }); 実行してみると\n$ node test.js StatusCode:200 Body:Hello World! ちゃんとレスポンスが偽装されていますね。私はVowsと組み合わせて使っています。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2011/09/30/nested-has-one.html",
                "title": "has_one関連でaccepts_nested_attributes_for / fields_forを使う",
                "section": "post",
                "date" : "2011.09.30",
                "body": "先日、has_one関連でaccepts_nested_attributesを使ってフォームを作ろうとしたら、ネスト先のフィールドが画面に出てこなくて小一時間ハマりました。そういえば以前も同じ事で悩んだような気がしたのでブログに残しておきます。\nUserモデルとProfileモデルが存在し、1対1の関連で結ばれているよくある構成を例にします。ユーザー登録を行うフォームで同時にプロフィールも登録出来るようにします。\nUserモデル\nclass User \u0026lt; ActiveRecord::Base has_one :profile accepts_nested_attributes_for :profile end Profileモデル\nclass Profile \u0026lt; ActiveRecord::Base belongs_to :profile end _form.html.hamlビュー\n= form_for @user do |f| = f.fields_for :profile, @user.profile || Profile.new do |p| .field = p.label :nickname = p.text_field :nickname 上のコードのように fields_for の第二引数で@user.profileが存在するかチェックし、存在しない場合はProfileのインスタンスを新規に作成します。こうすることで new, edit 両方に対応することが出来ます。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2011/09/26/vows-setup-teardown.html",
                "title": "Vowsで前処理・後処理を行うには",
                "section": "post",
                "date" : "2011.09.26",
                "body": "Vowsの場合、前処理はtopic内で行い、後処理はteardownを使用します。RSpecの after(:all) の動作に近い感じです。\nvows .describe(\u0026#34;Hoge\u0026#34;) .addBatch \u0026#39;a instance\u0026#39;: # 前処理  topic: -\u0026gt; \u0026#39;should hogehoge\u0026#39;: (topic) -\u0026gt; assert.ok topic.hogehoge # 後処理  teardown: (topic) -\u0026gt; また、別のアプローチでaddBatchを利用する事も出来そうです。addBatchは順に実行されるので、前処理・後処理というよりは、一番最初・最後に実施したいテストなどがある場合に有効かもしれません。\nsuite = vows.describe(\u0026#34;Hoge\u0026#34;) suite.addBatch \u0026#39;first test\u0026#39;: topic: -\u0026gt; suite.addBatch \u0026#39;second test\u0026#39;: topic: -\u0026gt; suite.addBatch \u0026#39;last test\u0026#39;: topic: -\u0026gt; suite.export module ※ addBatch は、バッチごとにグローバルスコープが独立していますので、グローバルスコープに影響が出る処理（console.log をモック化する時など）に最適かも。\nどうもそうでは無いようです…\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2011/09/21/nodejs-tdd.html",
                "title": "Node.js + Vowsではじめるテスト駆動開発",
                "section": "post",
                "date" : "2011.09.21",
                "body": "Node.jsで使えるTDD, BDDフレームワークはいくつかあるのですが（nodeunit, Jasmine, etc）コールバック・イベント周りのテストのしやすさとCoffeeScriptが利用出来る Vows が非常に熱い感じです。\n特にテストコードをCoffeeScriptで（別途コンパイルせずに）そのまま記述出来るのは、テストコードの可読性を考えると大きなメリットだと思います。\nVowsのインストール VowsはNode Package Manager（npm）でインストールする事が出来ます。vowsコマンドを有効にするためにカレントディレクトリの node_modules の他にグローバルにも入れておきましょう。\nnpm install vows npm install -g vows Vowsを使った開発手順 サンプルとして自分のフルネームを返す事しか出来ないPersonクラスを実装してみます。まずはVowsでテストを書きます。今回は単機能なので下記コードを一気に書きました。\nvows = require(\u0026#39;vows\u0026#39;) assert = require(\u0026#39;assert\u0026#39;) Person = require(\u0026#39;./person\u0026#39;) vows .describe(\u0026#39;Person\u0026#39;) .addBatch \u0026#39;a instance\u0026#39;: topic: -\u0026gt; new Person(\u0026#34;Nobita\u0026#34;, \u0026#34;Nobi\u0026#34;) \u0026#39;should return full name\u0026#39;: (topic) -\u0026gt; assert.equal topic.name(), \u0026#34;Nobita Nobi\u0026#34; .export module この状態でテストを実行してみます。\n$ vows test-person.coffee --spec node.js:205 throw e; // process.nextTick error, or 'error' event on first tick ^Error: Cannot find module './person' そもそもテストの対象となるファイルが存在しないのでエラーになりますね。\n次に person.coffee を作成します。ひとまず Person クラスを定義します。\nclass Person module.exports = Person 再度テストを実行してみます。\n$ vows test-person.coffee --spec ♢ Person a instance ✗ should return full name TypeError: Object \u0026lt;Person\u0026gt; has no method 'name' エラーが出ました。nameメソッドが無いと怒っていますので作りましょう。\nclass Person name: -\u0026gt; module.exports = Person nameメソッドを定義したら再度テストを実行してみます。\n$ vows test-person.coffee --spec ♢ Person a instance ✗ should return full name » expected 'Nobita Nobi', got undefined (==) // vows.js:93 ✗ Broken » 1 broken (0.004s) ようやくテストが動作しました。が、nameメソッドには何も実装していないので勿論テストは通りません。後はテストが通るまでせっせとコードを書いていきましょう。\nせっせと書いたコードはこちら。\nclass Person constructor: (firstName, lastName) -\u0026gt; @firstName = firstName @lastName = lastName name: -\u0026gt; \u0026#34;#{@firstName}#{@lastName}\u0026#34; module.exports = Person テストを実行します。\n$ vows test-person.coffee --spec ♢ Person a instance ✓ should return full name ✓ OK » 1 honored (0.002s) 無事にグリーンになりました！\nところで、こんなしょぼいコードでもリファクタリングの余地が残されています。CoffeeScriptはコンストラクタの引数をそのままインスタンスのプロパティに割り当てる構文があるので、それに書き換えてみます。\nclass Person + constructor: (@firstName, @lastName) -\u0026gt; - @firstName = firstName - @lastName = lastName  name: -\u0026gt; \u0026#34;#{@firstName} #{@lastName}\u0026#34; module.exports = Person テストを実行。\n$ vows test-person.coffee --spec ♢ Person a instance ✓ should return full name ✓ OK » 1 honored (0.002s) うむ。\nVowsでモック・スタブを使うには Vowsでモック・スタブを使いたい場合は Sinon.JS を利用しましょう。Sinon.JS は Node Package Manager（npm）で入れる事が出来ます。\nnpm install sinon 下記はモックを使った例。\nvows = require(\u0026#39;vows\u0026#39;) sinon = require(\u0026#39;sinon\u0026#39;) assert = require(\u0026#39;assert\u0026#39;) class Twitter tweet: (message) -\u0026gt; class Person constructor: (@twitter) -\u0026gt; tweet: (message) -\u0026gt; @twitter.tweet(message) vows .describe(\u0026#39;Person\u0026#39;) .addBatch \u0026#39;when tweet message\u0026#39;: topic: -\u0026gt; twitter = new Twitter() twitterMock = sinon.mock(twitter) twitterMock.expects(\u0026#34;tweet\u0026#34;).once().withArgs(\u0026#34;hello\u0026#34;) person = new Person(twitter) person.tweet(\u0026#34;hello\u0026#34;) return twitterMock \u0026#39;should call twitter.tweet\u0026#39;: (topic) -\u0026gt; topic.verify() .export module Vowsで非同期イベントのテストを行うには Vowsで非同期イベントのテストを行う場合、this.callbackとpromiseの2種類が用意されています。私は後者のプロミスのほうをよく利用していますので、ここではプロミスを使ったサンプルを掲載しておきます。\nvows = require(\u0026#39;vows\u0026#39;) assert = require(\u0026#39;assert\u0026#39;) http = require(\u0026#39;http\u0026#39;) vows .describe(\u0026#39;http\u0026#39;) .addBatch \u0026#39;GET google.co.jp\u0026#39;: topic: -\u0026gt; promise = new (require(\u0026#39;events\u0026#39;).EventEmitter)() options = host: \u0026#39;www.google.co.jp\u0026#39;, port: 80, path: \u0026#39;/\u0026#39;, method: \u0026#39;GET\u0026#39;, headers: \u0026#39;Content-length\u0026#39;: 0 req = http.request options, (res) -\u0026gt; res.setEncoding(\u0026#39;utf8\u0026#39;) res.on \u0026#39;data\u0026#39;, (chunk) -\u0026gt; promise.emit \u0026#39;success\u0026#39;, chunk req.end() return promise \u0026#39;should be received\u0026#39;: (topic) -\u0026gt; assert.ok topic .export module 上記コードを見れば分かると思いますが、プロミスとはトピックの戻り値をEventEmitterにして、successイベントが発生すると各テストを実行していく仕組みです。うまくイベントが発生しなかった場合はcallback not firedというエラーが起きてテストに失敗します。\n（非同期周りのテストはまた別の機会に…）\nまとめ 駆け足でVowsを紹介してみましたが如何でしょうか？Node.jsでのテストは面倒くさいという印象が強いですが（自分だけですかね…）JavaScriptは色々な書き方が出来て、油断するとコードが大変な事になったりするので是非テストは書いていきたいですね。\nVowsはCoffeeScriptで書けるので、いちいちテストコードでhogehoge(function() { \u0026hellip; });とか書いてられない人にもお勧めです！\n参考サイト  Vows « Asynchronous BDD for Node Sinon.JS – Versatile standalone test spies, stubs and mocks for JavaScript Node.js 用のテスティングフレームワーク Vows Node.js 用のテスティングフレームワーク Vows その 2 Node.js 用のテスティングフレームワーク Vows その 3  "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2011/09/01/upgrade-rails31.html",
                "title": "Rails v3.0.xからv3.1.0にアップグレードした時のメモ",
                "section": "post",
                "date" : "2011.09.01",
                "body": "Rails v3.1.0が出たのでv3.0.10で開発しているプロジェクトの対応を行いました。その時のメモを残しておきます。\nといっても、このRailsプロジェクトはJSONを返すだけの単純なREST APIでしたので修正箇所は少なかったです。あまり参考にならないかもしれません。。。\nGemfileを開き、Rails, Rake, mysql2のバージョンを上げます。\n-gem \u0026#39;rails\u0026#39;, \u0026#39;3.0.10\u0026#39; -gem \u0026#39;rake\u0026#39;, \u0026#39;0.8.7\u0026#39; -gem \u0026#39;mysql2\u0026#39;, \u0026#39;0.2.11\u0026#39; +gem \u0026#39;rails\u0026#39;, \u0026#39;3.1.0\u0026#39; +gem \u0026#39;rake\u0026#39;, \u0026#39;0.9.2\u0026#39; +gem \u0026#39;mysql2\u0026#39;, \u0026#39;0.3.7\u0026#39; おなじみBundlerでgemを更新します。\n$ bundle update 問題なく動作するかテストを走らせてみます。\n$ rake spec rake aborted! undefined method `debug_rjs=' for ActionView::Base:Class Tasks: TOP =\u0026gt; spec =\u0026gt; db:test:prepare =\u0026gt; db:abort_if_pending_migrations =\u0026gt; environment (See full trace by running task with --trace) ……どうやらdebug_rjs というメソッドが無くなったようです。config/environments/development.rbから該当の行を削除します。\n- config.action_view.debug_rjs = true 以上を修正するだけで対応することが出来ました。色々と書き直しが発生しなくて一安心です。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2011/08/14/consistent-hashing-nodejs.html",
                "title": "Consistent HashingをNode.jsで実装してみた",
                "section": "post",
                "date" : "2011.08.14",
                "body": "Node.js から Key Value Store などを利用する際に、キーを複数のノードに分散させる汎用的なライブラリがあったら便利なのではと思い実装してみました。\nソースコードはGitHubで公開しています。ライセンスはMIT Licenseとします。\ngit clone git://github.com/dakatsuka/node-consistent-hashing.git また、npmでもインストール出来るようにしました。\nnpm install consistent-hashing 使い方 基本的な使い方は下記の通りです。\nvar ConsistentHashing = require(\u0026#39;consistent-hashing\u0026#39;); var cons = new ConsistentHashing([\u0026#34;node1\u0026#34;, \u0026#34;node2\u0026#34;, \u0026#34;node3\u0026#34;]); console.log(cons.getNode(\u0026#34;key1\u0026#34;)); // =\u0026gt; node3 console.log(cons.getNode(\u0026#34;key2\u0026#34;)); // =\u0026gt; node2 console.log(cons.getNode(\u0026#34;key3\u0026#34;)); // =\u0026gt; node1 console.log(cons.getNode(\u0026#34;key4\u0026#34;)); // =\u0026gt; node2 試しにA..Zまでのキーを分散させてみます。\nvar nodes = {}; var chars = [ \u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;, \u0026#39;C\u0026#39;, \u0026#39;D\u0026#39;, \u0026#39;E\u0026#39;, \u0026#39;F\u0026#39;, \u0026#39;G\u0026#39;, \u0026#39;H\u0026#39;, \u0026#39;I\u0026#39;, \u0026#39;J\u0026#39;, \u0026#39;K\u0026#39;, \u0026#39;L\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;N\u0026#39;, \u0026#39;O\u0026#39;, \u0026#39;P\u0026#39;, \u0026#39;Q\u0026#39;, \u0026#39;R\u0026#39;, \u0026#39;S\u0026#39;, \u0026#39;T\u0026#39;, \u0026#39;U\u0026#39;, \u0026#39;V\u0026#39;, \u0026#39;W\u0026#39;, \u0026#39;X\u0026#39;, \u0026#39;Y\u0026#39;, \u0026#39;Z\u0026#39; ]; chars.forEach(function(c) { var node = cons.getNode(c); if (nodes[node]) { nodes[node].push(c); } else { nodes[node] = []; nodes[node].push(c); } }); console.log(nodes); // { node3: [ \u0026#39;A\u0026#39;, \u0026#39;F\u0026#39;, \u0026#39;H\u0026#39;, \u0026#39;J\u0026#39;, \u0026#39;N\u0026#39;, \u0026#39;S\u0026#39;, \u0026#39;U\u0026#39;, \u0026#39;W\u0026#39;, \u0026#39;X\u0026#39; ], // node1: [ \u0026#39;B\u0026#39;, \u0026#39;C\u0026#39;, \u0026#39;E\u0026#39;, \u0026#39;G\u0026#39;, \u0026#39;L\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;Q\u0026#39;, \u0026#39;R\u0026#39;, \u0026#39;V\u0026#39;, \u0026#39;Y\u0026#39;, \u0026#39;Z\u0026#39; ], // node2: [ \u0026#39;D\u0026#39;, \u0026#39;I\u0026#39;, \u0026#39;K\u0026#39;, \u0026#39;O\u0026#39;, \u0026#39;P\u0026#39;, \u0026#39;T\u0026#39; ] } ノードの追加と削除が出来ます。\ncons.addNode(\u0026#34;node4\u0026#34;); cons.removeNode(\u0026#34;node1\u0026#34;); また、new するときに仮想ノード数を変更する事が出来ます（デフォルト値は160）。\nvar cons = new ConsistentHashing([\u0026#34;node1\u0026#34;, \u0026#34;node2\u0026#34;, \u0026#34;node3\u0026#34;], { replicas: 200 }); ハッシュ値を出すときのアルゴリズムも変更する事が出来ます（デフォルト値はmd5）。\n// md5, sha1, sha256, sha512を選択出来ます。 var cons = new ConsistentHashing([\u0026#34;node1\u0026#34;, \u0026#34;node2\u0026#34;, \u0026#34;node3\u0026#34;], { algorithm: \u0026#39;sha1\u0026#39; }); "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2011/08/01/firefox-websocket.html",
                "title": "Firefox Nightly, Aurora で WebSocket を使うには",
                "section": "post",
                "date" : "2011.08.01",
                "body": "Google Chromeのノリで new WebSocket() としても全く動く気配が無く、ググってもあまり情報が出てこなかったので、地味に手こずりました。\nFirefoxのNightly版、Aurora版でWebSocketを使用する場合はプレフィックスを付ける必要があるようです。\nvar ws = new MozWebSocket(\u0026#34;ws://xxxxx\u0026#34;); これで動きました。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2011/07/18/connect-middleware.html",
                "title": "connect middlewareでexpressを拡張しよう",
                "section": "post",
                "date" : "2011.07.18",
                "body": "connect (express) は Ruby の Rack と同じようにミドルウェアを使うことで簡単に拡張する事が出来ます。このミドルウェアの使い方・作り方を知っているだけで express での開発が相当楽になりますので覚えておいて損は無いでしょう。\nミドルウェアを使う ミドルウェアを express に組み込むには use メソッドを使います。つまり、普段よく使う bodyParser や cookieParser, logger なども実は connect のミドルウェアです。\nvar express = require(\u0026#39;express\u0026#39;) var app = express.createServer(); app.configure(function() { app.use(app.logger()); app.use(app.bodyParser()); app.use(app.cookieParser()); }); 公式で用意されているミドルウェアとその使い方は Connect – middleware framework for nodejs をご覧ください。また、サードパーティ製のミドルウェアも最近充実してきました。チェックしておくと良いでしょう。\nミドルウェアを自作する connectのミドルウェアは簡単に自作することが出来ます。試しに、アクセスがあるたびにコンソールにHTTPのリクエストヘッダを出力するミドルウェアを作ってみます。\nmiddleware.js に下記コードを記述します。\nvar requestHeader = function() { return function(req, res, next) { console.log(req.headers); next(); }; }; exports.requestHeader = requestHeader; 同一ディレクトリに app.js を作成し、下記コードを記述します。\nvar express = require(\u0026#39;express\u0026#39;) , middleware = require(\u0026#39;./middleware\u0026#39;) , app = express.createServer(); app.configure(function() { app.use(middleware.requestHeader()); }); app.get(\u0026#39;/\u0026#39;, function(req, res) { res.send(\u0026#34;Hello World\u0026#34;); }); app.listen(3000); node app.js でサーバを立ち上げ、 http://localhost:3000/ にブラウザで実際にアクセスしてみましょう。コンソールにUserAgentなどの情報が出力されるはずです。\nまとめ 上でHTTPヘッダを出力する実用性皆無なミドルウェアを作成しましたが、コードは非常にシンプルで分かりやすいと思います。『req / res 引数でデータを取得する事ができ、適宜 req / res に対し改変・追加などを行い、next(); で次のミドルウェアに処理を渡す』 この動きを抑えておけば大丈夫です。\nUserAgentで処理を振り分けやモバイル端末の検出、認証処理などはミドルウェアとして実装する事で、他プロジェクトでの使い回しもでき、且つコードの見通しも良くなるのでおすすめです。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2011/07/14/red5.html",
                "title": "さくらのVPS（Ubuntu 10.04）にRed5を入れたときのメモ",
                "section": "post",
                "date" : "2011.07.14",
                "body": "とある事情でさくらのVPSにRed5（ストリーミングサーバ）を入れたので、その時のメモをブログに残しておきます。なお、さくらのVPSで動かしているOSはUbuntu 10.04です。\n※ Red5とはRTMPを使ったオープンソースのストリーミングサーバですが、詳しい説明は割愛します。\nRed5はSun Javaで動かした方が良いらしいので、まずsun-java6をインストールします。\nsudo apt-get install python-software-properties sudo add-apt-repository 'deb http://archive.canonical.com/ lucid partner' sudo apt-get update sudo apt-get install sun-java6-jre sun-java6-jdk ant java-common java-package Subversionをインストールします。\nsudo apt-get install subversion Red5のソースをSubversionでチェックアウトしてきます。\ncd /usr/localbin # Red5を入れるディレクトリを指定（お好きな場所に） sudo svn co http://red5.googlecode.com/svn/java/server/trunk red5 Red5をビルドします。\ncd ./red5 sudo ant prepare sudo ant dist Red5を起動。\ncd ./dist sudo nohup sh red5.sh \u0026amp; http://hostname:5080/ にアクセスして Red5 の画面が出てれば起動成功です。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2011/06/19/nodejs-redis-pubsub.html",
                "title": "Redis の Pub/Sub を使って Node.js + WebSocket のスケールアウトを実現する方法",
                "section": "post",
                "date" : "2011.06.19",
                "body": "Node におけるスケールアーキテクチャ考察(Scale 編)というエントリーを読んで、RedisはPub/Sub型通信をサポートしているという事を知りました。エントリーでも言及されているように、Pub/Subを使えば Node.js + WebSocket サーバをスケールする際に、中継サーバの役割を果たす事が出来るはずです。\nそんな訳で実際に Node.js と Redis を使って Pub/Sub の実験を行なってみました。ユーザが別々のNode.jsサーバに接続していてもWebSocketを通してメッセージのやり取りを出来るようにします。\nイメージとしてはこんな感じです。\n  下準備 Ubuntuの場合は apt-get で1発でインストールする事が出来ます。\n$ sudo apt-get install redis npmでredisモジュールをインストールします。\n$ npm install redis Node.js から Redis の Pub/Sub を使ってみる 試しにPub/Subとはどんなものか試してみましょう。Node.jsのコンソールを起動します。\n$ node コンソールに下記コードを入力します。\nvar sys = require(\u0026#39;sys\u0026#39;); var redis = require(\u0026#39;redis\u0026#39;); var subscriber = redis.createClient(6379, \u0026#39;localhost\u0026#39;); subscriber.subscribe(\u0026#39;hoge channel\u0026#39;); subscriber.on(\u0026#34;message\u0026#34;, function(channel, message) { sys.puts(channel + \u0026#34; :\u0026#34; + message); }); 別のターミナルで、下記コマンドを実行します。\n$ redis-cli publish \u0026quot;hoge channel\u0026quot; \u0026quot;Hello World!\u0026quot; Node.js のコンソール画面に 「Hello World!」と表示されるはずです。これがPub/SubのSubにあたります。\nでは、今度はNode.js側からメッセージを送ってみましょう。先ほどのredis-cliを実行したターミナルで下記コマンドを実行します。\n$ redis-cli subscribe \u0026quot;hoge channel\u0026quot; Reading messages... (press Ctrl-c to quit) 1. \u0026quot;subscribe\u0026quot; 2. \u0026quot;hoge channel\u0026quot; 3. (integer) 1 Node.jsのコンソールに下記コードを入力します。\npublisher = redis.createClient(6379, \u0026#39;localhost\u0026#39;); publisher.publish(\u0026#34;hoge channel\u0026#34;, \u0026#34;FooBar\u0026#34;); Node.js のコンソール画面と redis-cli を実行した画面両方に「FooBar」と表示されますね。これで Redis の Pub/Sub の動きは何となく掴めたかと思います。\nWebSocket を使ったチャットもどきを実装する // This program is free software. It comes without any warranty, to // the extent permitted by applicable law. You can redistribute it // and/or modify it under the terms of the Do What The Fuck You Want // To Public License, Version 2, as published by Sam Hocevar. See // http://sam.zoy.org/wtfpl/COPYING for more details.  var sys = require(\u0026#39;sys\u0026#39;) , opts = require(\u0026#39;opts\u0026#39;) , ws = require(\u0026#39;websocket-server\u0026#39;) , redis = require(\u0026#39;redis\u0026#39;) , server = ws.createServer() , subscriber = redis.createClient(6379, \u0026#39;localhost\u0026#39;) , publisher = redis.createClient(6379, \u0026#39;localhost\u0026#39;); opts.parse([ { \u0026#39;short\u0026#39;: \u0026#39;p\u0026#39;, \u0026#39;long\u0026#39;: \u0026#39;port\u0026#39;, \u0026#39;description\u0026#39;: \u0026#39;WebSocket Port\u0026#39;, \u0026#39;value\u0026#39;: true, \u0026#39;required\u0026#39;: true } ]); subscriber.on(\u0026#34;error\u0026#34;, function(err) { sys.debug(err); }); publisher.on(\u0026#34;error\u0026#34;, function(err) { sys.debug(err); }); subscriber.subscribe(\u0026#34;chat\u0026#34;); subscriber.on(\u0026#34;message\u0026#34;, function(channel, message) { sys.puts(message); server.broadcast(message); }); server.addListener(\u0026#34;connection\u0026#34;, function(connection) { sys.puts(\u0026#34;client connected: \u0026#34; + connection.id); connection.addListener(\u0026#34;message\u0026#34;, function(message) { publisher.publish(\u0026#34;chat\u0026#34;, message); }); }); server.addListener(\u0026#34;close\u0026#34;, function(connection) { sys.puts(\u0026#34;client disconnected: \u0026#34; + connection.id); }); server.listen(opts.get(\u0026#39;port\u0026#39;)); 上記コードをapp.jsとして保存し、複数のポートで立ち上げます（別途 npm で websocket-server と opts をインストールする必要があります）。\n$ node app.js -p 8001 $ node app.js -p 8002 $ node app.js -p 8003 $ node app.js -p 8004 Google Chrome の JavaScript コンソールを複数のタブで開き、下記のように入力します。\nvar connection = new WebSocket(\u0026#34;ws://localhost:8001\u0026#34;); connection.onmessage = function(event) { console.log(event.data) } connection.send(\u0026#34;Hello!!\u0026#34;); 複数のタブで connection.send(……) をたくさん入力してみると分かりやすいと思います。どのタブで入力してもメッセージが表示されるはずです。\nまとめ 今回は Redis の Pub/Sub を試す目的でしたので、チャットプログラム自体はメッセージを broadcast する事しか出来ません。しかし、Redis を通してやり取りするデータ形式をJSONにしておけば、色々な情報を各々の node.js サーバで共有する事ができるので、実用性が上がるのではないでしょうか。\nまた、Redis自体もレプリケーションが可能なので中継サーバもスケールする事が出来ると思います（未検証）。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2011/06/18/nodejs-opts.html",
                "title": "node.js で コマンドライン引数を取るには",
                "section": "post",
                "date" : "2011.06.18",
                "body": "node.js でコマンドライン引数を取りたい場合は opts というモジュールを使うことで簡単に実現出来ます。\noptsモジュールは npm でインストールします。\nnpm install opts 試しに引数で指定したポート番号でHTTPサーバを立ち上げるコードを書いてみました。\nvar http = require(\u0026#39;http\u0026#39;) , opts = require(\u0026#39;opts\u0026#39;); opts.parse([ { \u0026#39;short\u0026#39;: \u0026#39;p\u0026#39;, \u0026#39;long\u0026#39;: \u0026#39;port\u0026#39;, \u0026#39;description\u0026#39;: \u0026#39;HTTP port\u0026#39;, \u0026#39;value\u0026#39;: true, \u0026#39;required\u0026#39;: false }, ]); var port = opts.get(\u0026#39;port\u0026#39;) || 3000 server = http.createServer(function(req, res) { res.writeHead(200, {\u0026#39;Content-Type\u0026#39;: \u0026#39;text/html\u0026#39;}); res.write(\u0026#39;\u0026amp;lt;h1\u0026amp;gt;Hello World!\u0026amp;lt;/h1\u0026amp;gt;\u0026#39;); res.end(); }); server.listen(port); 実行。\nnode app.js -p 3001 requiredをtrueにして引数を省略して起動するとちゃんとエラーになります。\n$ node app.js Missing required option: p Usage: node /path/app.js [options] HTTP port -p, --port \u0026lt;value\u0026gt; (required) "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2011/06/14/npm-package-json.html",
                "title": "npm と package.json でパッケージ管理",
                "section": "post",
                "date" : "2011.06.14",
                "body": "node.js で Ruby の Bundler(Gemfile) のようにパッケージとバージョンを管理するには、package.json というファイルを作成すれば良いようです。\npackage.json のdependenciesに必要なパッケージ名とバージョンを指定していきます。バージョンは\u0026quot;2.3.11\u0026quot;のように直接指定する事はもちろん、\u0026quot;\u0026gt;= 0.0.1\u0026quot;のように記述する事も出来ます。ここら辺はBundlerと一緒ですね。\n{ \u0026#34;name\u0026#34;: \u0026#34;example-app\u0026#34; , \u0026#34;version\u0026#34;: \u0026#34;0.0.1\u0026#34; , \u0026#34;private\u0026#34;: true , \u0026#34;dependencies\u0026#34;: { \u0026#34;express\u0026#34;: \u0026#34;2.3.11\u0026#34; , \u0026#34;jade\u0026#34;: \u0026#34;\u0026gt;= 0.0.1\u0026#34; , \u0026#34;socket.io\u0026#34;: \u0026#34;0.6.18\u0026#34; } } package.json の記述が終わったら下記コマンドでパッケージを一括でインストールする事が出来ます。\nnpm install -g オプションを付けずに実行すれば ./node_modules ディレクトリ内にインストールされます。.gitignore に ./node_modules を追加しておくと良さそうです。\n参考サイト  Packages/1.1 – CommonJS Spec Wiki  "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2011/06/09/express-redis.html",
                "title": "node.js + express でセッションストアを Redis に変更する方法",
                "section": "post",
                "date" : "2011.06.09",
                "body": "express のセッションは標準だとメモリストアなので、再起動するたびにセッションが消えてしまいます。そこでセッションストアを Redis にしてセッションを永続化出来るようにしてみます。\n下記環境で動作を確認しました。\n Node.js v0.4.8 express v2.3.11 connect-redis v1.0.5  npm で connect-redis をインストールします。\nnpm install connect-redis app.js を次のように書き換えます。\nvar express = require(\u0026#39;express\u0026#39;); var RedisStore = require(\u0026#39;connect-redis\u0026#39;)(express); var app = express.createServer(); app.use(express.cookieParser()); app.use(express.session({ secret: \u0026#34;secret key\u0026#34;, store: new RedisStore(), cookie: { maxAge: 86400 * 1000 } })); maxAge でセッション（クッキー）の有効期限を指定する事が出来ます。cookie: 自体を省略するとデフォルトは4時間のようです。指定したい場合は上記のようにミリ秒で指定する事が出来ます。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2011/06/08/node-express-twitter.html",
                "title": "node.js + expressでTwitter認証",
                "section": "post",
                "date" : "2011.06.08",
                "body": "node.js + express でTwitter認証をしてみました。今回は取得した情報をセッションに格納していますが、これを MySQL や MongoDB に保存すれば「Twitterでログイン」みたいな事は簡単に出来そうですね。\n下記環境で動作確認しています。\n Node.js v0.4.8 express v2.3.11 jade v0.12.1 oauth v0.9.0  実装する 必要なモジュールを npm でインストールします。\nnpm install express oauth jade app.js は下記のように実装しました。\n// This program is free software. It comes without any warranty, to // the extent permitted by applicable law. You can redistribute it // and/or modify it under the terms of the Do What The Fuck You Want // To Public License, Version 2, as published by Sam Hocevar. See // http://sam.zoy.org/wtfpl/COPYING for more details.  var express = require(\u0026#39;express\u0026#39;); var app = express.createServer(); var oauth = new (require(\u0026#39;oauth\u0026#39;).OAuth)( \u0026#39;https://api.twitter.com/oauth/request_token\u0026#39;, \u0026#39;https://api.twitter.com/oauth/access_token\u0026#39;, \u0026#39;CONSUMER KEY\u0026#39;, \u0026#39;CONSUMER SECRET\u0026#39;, \u0026#39;1.0\u0026#39;, \u0026#39;http://localhost:3000/auth/twitter/callback\u0026#39;, \u0026#39;HMAC-SHA1\u0026#39; ); app.configure(function() { app.use(express.logger()); app.use(express.bodyParser()); app.use(express.cookieParser()); app.use(express.session({ secret: \u0026#34;secret\u0026#34; })); app.set(\u0026#39;view engine\u0026#39;, \u0026#39;jade\u0026#39;) }); app.dynamicHelpers({ session: function(req, res) { return req.session; } }); app.get(\u0026#39;/\u0026#39;, function(req, res) { res.render(\u0026#39;index\u0026#39;, { layout: false }); }); app.get(\u0026#39;/auth/twitter\u0026#39;, function(req, res) { oauth.getOAuthRequestToken(function(error, oauth_token, oauth_token_secret, results) { if(error) { res.send(error) } else { req.session.oauth = {}; req.session.oauth.token = oauth_token; req.session.oauth.token_secret = oauth_token_secret; res.redirect(\u0026#39;https://twitter.com/oauth/authenticate?oauth_token=\u0026#39; + oauth_token); } }); }); app.get(\u0026#39;/auth/twitter/callback\u0026#39;, function(req, res) { if(req.session.oauth) { req.session.oauth.verifier = req.query.oauth_verifier; oauth.getOAuthAccessToken(req.session.oauth.token, req.session.oauth.token_secret, req.session.oauth.verifier, function(error, oauth_access_token, oauth_access_token_secret, results) { if(error) { res.send(error); } else { req.session.oauth.access_token = oauth_access_token; req.session.oauth.access_token_secret = oauth_access_token_secret; req.session.user_profile = results res.redirect(\u0026#39;/\u0026#39;); } } ); } }); app.get(\u0026#39;/signout\u0026#39;, function(req, res) { delete req.session.oauth; delete req.session.user_profile; res.redirect(\u0026#39;/\u0026#39;); }); app.listen(3000); views/index.jade はこんな感じに。\n!!! 5 html(lang=\u0026quot;ja\u0026quot;) head title node.js sample app body h1 node.js sample app - if (session.user_profile) p= \u0026quot;Welcome, \u0026quot; + session.user_profile.screen_name p a(href=\u0026quot;/signout\u0026quot;) Sign out - else p a(href=\u0026quot;/auth/twitter\u0026quot;) Sign in with twitter 以上、2ファイルを作成したら下記コマンドで起動します。\nnode app.js http://localhost:3000/ にアクセスし「Sign in with twitter」のリンクをクリックすれば Twitter に飛んで認証する事が出来ます。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2011/06/06/nave-npm-node.html",
                "title": "Ubuntu 11.04 + nave + npm で Node.js 環境を構築する",
                "section": "post",
                "date" : "2011.06.06",
                "body": "近々 Node.js を使う機会がありそうなので Node.js を Ubuntu にインストールしてみました。\nnave か nvm にするか迷ったのですが、nvm は zsh と相性が悪くて nvm 本体に手を入れないといけないので物ぐさな私は nave を使う事にしました。\n準備 まず Node.js をインストールするために必要なパッケージ類を apt-get で導入します。\nsudo apt-get install git-core curl build-essential libssl-dev naveをインストール naveの最新版をGithubからcloneしてきます。\ngit clone git://github.com/isaacs/nave.git .nave 正常に動作するか確認。\n$ .nave/nave.sh help Usage: nave \u0026lt;cmd\u0026gt; Commands: .... 毎回 ./nave/nave.sh と入力するのは面倒なのでパスが通っているディレクトリにシンボリックを貼りました。\ncd ~/bin ln -s ../.nave/nave.sh nave これで nave と入力するだけで呼び出せるようになります。\nNode.jsをインストール nave を使って最新版をインストールしてみます。\nnave install latest インストールが終わったら下記コマンドで確認。\n$ nave ls src: 0.4.8 installed: 0.4.8 0.4.8が入ったようです。\n試しに0.4.7を入れてみましょう。\n$ nave install 0.4.7 $ nave ls src: 0.4.7 0.4.8 installed: 0.4.7 0.4.8 nave use で使用したいバージョンを指定します。\n$ nave use 0.4.8 Already installed: 0.4.8 using 0.4.8 $ node -v v0.4.8 npmをインストール nave use して node.js を使える状態にした上で、下記コマンドでインストールします。\ncurl http://npmjs.org/install.sh | sh インストールされたか確認。\n$ npm -v 1.0.9-1 以上です。Ruby + rvm よりちょっとインストールが手間ですけど使えるようになりました。今度は express あたりをイジくってみようと思います。\n参考リンク  Node.js isaacs/nave – GitHub npm – Node Package Manager Node.jsとnvmを初めてインストールするときのハマりポイントと対策 – ess sup zshでnvmを使うときに必要なこと(2011-05-10現在版) – Inquisitive!  "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2011/06/01/omniauth-mixi.html",
                "title": "Rails3 + OmniAuth で mixi OpenID を使うための設定",
                "section": "post",
                "date" : "2011.06.01",
                "body": "OmniAuthを使ってTwitterやFacebookと連携・認証をする方法はググればたくさん出てくるのですが、mixi OpenIDを使ったやり方は出てこなかったので調べてみました。\nOmniAuthの設定 config/initializers/omniauth.rbに以下を記述して保存します。OpenID.fetcher.ca_fileを指定しないと Warning が出まくるのでしっかり指定してあげましょう。\nrequire \u0026#39;omniauth/openid\u0026#39; require \u0026#39;openid/fetchers\u0026#39; require \u0026#39;openid/store/filesystem\u0026#39; OpenID.fetcher.ca_file = \u0026#34;/usr/lib/ssl/certs/ca-certificates.crt\u0026#34; Rails.application.config.middleware.use OmniAuth::Builder do provider :openid, OpenID::Store::Filesystem.new(\u0026#34;/tmp\u0026#34;), :name =\u0026gt; \u0026#34;mixi\u0026#34;, :identifier =\u0026gt; \u0026#34;mixi.jp\u0026#34; end providerにTwitterやFacebookを追加すれば、3サイトで認証出来るようになります。\n参考サイト UserモデルやSessionsControllerの実装などは、@jugyoさんの OmniAuth で簡単 Twitter 認証！の通りにやれば完璧だと思います。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2011/05/27/grape.html",
                "title": "APIの作成に特化したRuby製フレームワーク grape を試してみた",
                "section": "post",
                "date" : "2011.05.27",
                "body": "RESTful API の作成に特化したマイクロフレームワーク grape の存在を知ったので調査してみる事にしました。API の実装 に Rails の ActionController は重厚すぎる、Sinatra は軽いけど手間がかかる。。。という中で作られたこのフレームワーク、はたしてその実力は…\ngrape の特徴 grape の特徴は概ね以下の通りです。grape 自体が Rack アプリケーションなので Rails3 に組み込むことが出来ます。というよりは組み込んで使うのが前提のようです（勿論単体でも動きます）。\n Rack アプリケーション Sinatra ライクな DSL 自動で JSON にシリアライズ（#serializable_hash または #to_json が存在すればOKみたい）  grape を使ってみる 特徴を掴んだところで、実際にインストールして使ってみます。Rails3 の一部として使う場合は Gemfile に下記1行を追加して、おなじみ bundle install を実行します。\ngem \u0026#34;grape\u0026#34; 今回は lib/api.rb に実装していきます。実装したコードは下記をご覧下さい。prefix を指定すると /api/articles/1 という感じのURLになります。コメントアウトしてますが、version を指定すると /1/articles/1 のようにアクセス出来るようになるみたいです（これに何のメリットがあるのかはちょっと分かりませんでした）。\n用意されている DSL の詳細は、intridea/grape – GitHub や YARD documentation for the Grape API などを見て下さい。\n# lib/api.rb module TestApp class API \u0026lt; Grape::API # version 1 prefix \u0026#34;api\u0026#34; resource \u0026#34;articles\u0026#34; do get \u0026#34;:id\u0026#34; do Article.find(params[:id]) end end end end APIの実装が終わったら次はRailsへの組み込みです。Rails3 から lib の中は自動で読み込まれないので initializers で呼び出すようにします。\n# config/initializers/api.rb require \u0026#34;#{Rails.root/lib/api\u0026#34; 最後に TestApp::API を routes.rb でマウントして完成です。\n# config/routes.rb TestApp::Application.routes.draw do mount TestApp::API =\u0026gt; \u0026#34;/\u0026#34; end ここまで出来たら rails s で WEBRick を起動し、http://localhost:3000/api/articles/1 にアクセスしてみましょう。Article.find(1) の実行結果が JSON で返ってくるはずです。\n軽くベンチマークしてみた 試しに ActionController と grape どちらがパフォーマンス良いのかをベンチマークしてみました。\nコントローラの実装は次のようにしました。\n# app/controllers/articles_controller.rb class ArticlesController \u0026lt; ApplicationController respond_to :json def show respond_with Article.find(params[:id]) end end # config/routes.rb TestApp::Application.routes.draw do resources :articles end Apache Bench で測定してみます。測定環境ですが、ローカルは自宅のiMac、リモートはさくらのVPS 4G（unicorn 使用）で行いました。ですのでベンチマーク結果はあくまで参考程度に考えてください。\ngrape\nConcurrency Level: 10 Time taken for tests: 5.039 seconds Complete requests: 1000 Failed requests: 0 Write errors: 0 Total transferred: 545000 bytes HTML transferred: 345000 bytes Requests per second: 198.47 [#/sec] (mean) Time per request: 50.385 [ms] (mean) Time per request: 5.039 [ms] (mean, across all concurrent requests) Transfer rate: 105.63 [Kbytes/sec] received ActionController\nConcurrency Level: 10 Time taken for tests: 7.573 seconds Complete requests: 1000 Failed requests: 0 Write errors: 0 Total transferred: 643000 bytes HTML transferred: 355000 bytes Requests per second: 132.05 [#/sec] (mean) Time per request: 75.731 [ms] (mean) Time per request: 7.573 [ms] (mean, across all concurrent requests) Transfer rate: 82.92 [Kbytes/sec] received grape のほうが少し速い結果となりました。何回かやってみたのですが、多少誤差はあるものの grape のほうが速そうです。\n総評 Sinatra ライクな DSL なおかげでかなりシンプルに書けることが分かりました。ただ、Rails3 からは respond_with が使えるようになったので、コード量ではあまり差は無くなってしまいますね。通常のHTMLページとAPIを分離したい場合やパフォーマンスアップを狙いたい場合には良いかもしれません。\nロードマップを見ると、OAuth認証やXMLでの出力、Streaming APIの対応も予定されているようです。\n関連リンク  The Grapes of Rapid / Slide  "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2011/05/25/cap-subdirectory.html",
                "title": "複数のRailsアプリが同居しているGitリポジトリをデプロイする方法",
                "section": "post",
                "date" : "2011.05.25",
                "body": "複数のRailsアプリが１つのリポジトリに同居しているような状態で Capistrano を使ってデプロイしたい場合、そのままでは動作しないので少々手を加える必要があります。\n下記のようにRailsアプリがサブディレクトリにある場合を想定しています。\nrepogitory/ ├── admin ├── mobile ├── share Capfileを書き換える 通常の手順通り、Rails.root 直下に Capfile を設置し config/deploy.rb にレシピを書いていくのですが、上記のようにリポジトリ直下 = Rails.root では無い場合、Capfile を少し変更する必要があります。\nStackoverflow の Deploying a Git subdirectory in Capistrano を参考に（というかほぼそのままですが）Capfile を以下のようにします。オリジナルと違う箇所はcpのオプションです。オリジナルのほうはシンボリックリンクをシンボリックリンクとしてコピーしますが、このコードは実体ファイルをコピーします。\nrequire \u0026#39;capistrano/recipes/deploy/strategy/remote_cache\u0026#39; class RemoteCacheSubdir \u0026lt; Capistrano::Deploy::Strategy::RemoteCache private def repository_cache_subdir if configuration[:deploy_subdir] then File.join(repository_cache, configuration[:deploy_subdir]) else repository_cache end end def copy_repository_cache logger.trace \u0026#34;copying the cached version to #{configuration[:release_path]}\u0026#34; if copy_exclude.empty? run \u0026#34;cp -RpL #{repository_cache_subdir}#{configuration[:release_path]}\u0026amp;\u0026amp; #{mark}\u0026#34; else exclusions = copy_exclude.map { |e| \u0026#34;--exclude=\\\u0026#34;#{e}\\\u0026#34;\u0026#34; }.join(\u0026#39; \u0026#39;) run \u0026#34;rsync -lrpt #{exclusions}#{repository_cache_subdir}/* #{configuration[:release_path]}\u0026amp;\u0026amp; #{mark}\u0026#34; end end end set :strategy, RemoteCacheSubdir.new(self) Capfile を書き換えたら deploy.rb を次のようにすれば指定したサブディレクトリだけをデプロイする事が出来ます。\nrequire \u0026#39;capistrano/ext/multistage\u0026#39; require \u0026#39;bundler/capistrano\u0026#39; require \u0026#39;erb\u0026#39; set :application, \u0026#34;app\u0026#34; set :scm, :git set :repository, \u0026#34;git://domain.com/path/to/repository.git\u0026#34; set :deploy_subdir, \u0026#34;/path/to/app\u0026#34; # require https://gist.github.com/970910 to Capfile set :deploy_via, :copy set :use_sudo, false set :bundle_without, [:development, :test] そもそも 何故このような構成になってるかというと、admin、mobileでモデルとライブラリを共通化したくなった為です。共通ファイルを share に放り込み、各Railsアプリからはシンボリックリンクで参照する形にしています。最初は Git の submodule を考えたのですがどうもしっくり来なかったんですよね。。。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2011/05/24/git-flow.html",
                "title": "Gitを使った開発・運用フローの紹介",
                "section": "post",
                "date" : "2011.05.24",
                "body": "私の所属している会社では、2年程前にバージョン管理システムをSubversionからGitに移行し、現在まで開発フローを試行錯誤してきました。ようやく形になってきたということで、守秘義務に接触しない程度に紹介＆考察していきたいと思います。\n形になってきたとはいえ、まだまだ試行錯誤中ですので色々なツッコミは大歓迎です。\n現在の開発フローの俯瞰図 現在の開発フローを俯瞰してみると大体下記図のような感じになっています。途中で図を書くのが面倒になった都合上、Jenkinsさんが１人しか居ませんが、実際はmasterブランチの他にreleaseブランチも監視してもらっています。\n以降この図を元に話を進めていきたと思います。\n  Gitoriousを利用して自由に開発 GitoriousというGitHubに似たサービスがあります。このGitoriousはオープンソースとしても公開されていますので社内に設置して利用する事が出来ます。\n見た目はGitHubとだいぶ違いますが利用方法は似通っていて、まずプロジェクトの中央リポジトリが存在し、それを各人がフォークして開発をしていくスタイルになります。GitHubのPull request（GitoriousではMerge requestと呼ぶ）と同等の機能もあるので、俯瞰図にも書いてある通り非常にGitHubを利用した開発に近くなっていると思います。\nGitoriousを利用するメリット・デメリット このGitoriousを利用した開発フローのメリットとしては以下が挙げられます。\n 必ずフォークしてから開発するので、仮に滅茶苦茶な実装をコミットしても周りに影響が無い。 周りに影響が無いので、Git初心者の社員にも心置きなくGitを弄り倒してもらう事が出来る。 Pull request で変更内容がDiffで見れるので、コードレビューするのが楽になる。 Pull request は独立したブランチになっているので、開発者はダメ出しされた後にPull requestに対して再度push出来る。  まぁ、GitHubを利用した場合と同じようなメリットですね。逆にデメリットとしては以下が挙がってきます。\n 管理者が休んだりサボったりするとあっという間にPull requestが溜まってしまう。 管理者、開発者共にGitの知識がかなり要求される。 push, pull, merge, rebaseのルールを決めておかないとコンフリクト地獄に陥る可能性が大。  マスターブランチの運用と新規開発時のフロー マスターブランチは開発の先端として扱っています。開発途中なのでバグが含まれている可能性がありますが、毎日・もしくはプッシュ後にナイトリー環境にデプロイしています。常に最新のコードをデプロイしておくことは重要で、バグの早期発見は勿論ですが、「プロジェクトの動いている感」を偉い方々に見てもらう狙いもあります（うちは自社企画が多いので…）\n新規開発を担当する開発者は、mainlineのマスターブランチとローカルリポジトリのマスターブランチをPullで同期を取りつつ、作業毎にトピックブランチを切って開発を行っています。\n開発が終わったらトピックブランチをリモートリポジトリにpushして、そのブランチをPull requestします。一連の流れをコマンドで表すと次の通りになります。\n$ git checkout master $ git pull mainline master $ git checkout -b feature-hoge --commit-- $ git pull --rebase mainline master $ git push origin feature-hoge 管理者がPull requestを取り込む際は次のようにします。\n$ git checkout master $ git checkout -b merge-request/198 $ git pull git://xxxxx/project_name/mainline.git refs/merge-request/198 $ git rebase master $ git checkout master $ git merge merge-request/198 --no-ff マスターブランチにマージする時に–no-ffオプションを付けることで下記コマンドで取り込んだトピックブランチ一覧を表示する事が出来ます。開発が活発な初期段階では大量にPull requestが飛んでくるのでどのトピックブランチまでマージ出来たか判断するのに有効です。\n$ git log --oneline --abbrev-commit --merges master リリースブランチの運用とメンテナンスフロー リリースブランチはあるタイミングでマスターブランチから作成されます。このリリースブランチをプロダクション環境にデプロイし、サイト運用中に出た不具合の修正や次期リリースまでの繋ぎ機能の開発をこのブランチで行っていきます。\nうちはサイトの性質上、且つ社内事情的にリリースの間隔がかなり空いてしまう場合が多いので、マスターブランチが次期リリースに向けての開発用、リリースブランチが現行安定版の保守用という感じにしています。\n基本的なフローはマスターブランチの運用と同じで、開発者がトピックブランチをPull requestし、管理者が取り込む流れになります。マスターブランチでも直っていないバグ修正は、cherry-pickでマスターブランチに取り込む事もあります。\n今後の課題 若干諦めてはいるのですが、マスターブランチとリリースブランチの内容が完全に違うモノになっていった時にcherry-pickすら厳しくなったらどうしようかな・・・と思ってたりします。まぁ、そんなになるまでリリースを温存しておくなって話なんですけどね…。社風の改革は開発フローを変えるより大変です。\nあとこのフローとRedmineを使ったTiDDをどうシームレスに連携していくかが現在最大の課題となっています。例えばコミットログにcloses #1って記述したコミットをcherry-pickで各ブランチに取り込むと、二重に処理が走ったりなど…。この辺りはまだ手探りですね。\nまとめ Gitは非常に柔軟なバージョン管理システムだと思います。ここで紹介した開発フロー以外にも様々なフローがありますので、参考にしながら開発現場にあったやり方を見つけていくと良いんじゃないでしょうか。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2011/05/14/hirb-rails-console.html",
                "title": "hirb を導入して rails console を快適に利用する",
                "section": "post",
                "date" : "2011.05.14",
                "body": "Rails 3: Fully Loaded | Intridea Blog で hirb という gem が紹介されていたので試してみることにしました。hirb は Rails Console 上で ActiveRecord の結果を見やすく整形してくれるツールのようです。\nle に下記コードを追加して bundle install を実行してインストールします。\ngroup :development do gem \u0026#39;hirb\u0026#39; gem \u0026#39;hirb-unicode\u0026#39; end あとは rails console を起動して Hirb.enable と打つだけで使用可能になります。\nruby-1.9.2-p180 \u0026gt; Hirb.enable =\u0026gt; true ruby-1.9.2-p180 \u0026gt; Prefecture.limit(3) Prefecture Load (0.3ms) SELECT `prefectures`.* FROM `prefectures` LIMIT 3 +----+--------+ | id | name | +----+--------+ | 1 | 北海道 | | 2 | 青森県 | | 3 | 岩手県 | +----+--------+ 3 rows in set すばらしい！ちなみにウインドウが狭い場合は自動で文字を省略するので見にくくなることも無さそうです。\nruby-1.9.2-p180 \u0026gt; Gender.limit(3) Gender Load (0.4ms) SELECT `genders`.* FROM `genders` LIMIT 3 +----+------+---------------+---------------+ | id | name | created_at | updated_at | +----+------+---------------+---------------+ | 1 | 女性 | 2011-04-27... | 2011-04-27... | | 2 | 男性 | 2011-04-27... | 2011-04-27... | | 3 | 秘密 | 2011-04-27... | 2011-04-27... | +----+------+---------------+---------------+ 3 rows in set 私は毎回 Hirb.enable と入力するのが面倒なので $HOME/.irbrc に書いて自動で実行されるようにしました。\nif defined? Rails::Console ActiveRecord::Base.logger = Logger.new(STDOUT) ActiveResource::Base.logger = Logger.new(STDOUT) if defined? Hirb Hirb.enable end end "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2011/04/24/ubuntu-server-10-04-mogilefs.html",
                "title": "Ubuntu Server 10.04に分散ファイルシステム MogileFSを入れてみた",
                "section": "post",
                "date" : "2011.04.24",
                "body": "Ubuntu Server 10.04 に 分散ファイルシステム「MogileFS」をインストール＆初期設定をして動作するところまで書いてみます。\nMogileFS には次のような特徴があります。\n Perl で実装されている HTTPを利用（NFSとか使わなくてOK） 自動フェイルオーバー 自動レプリケーション そこそこ実績がある（たしかはてなでも使われていたはず）  以下参考にさせて頂いたサイトです。\n 分散ファイルシステム MogileFS について : Tech Talk Blog – Six Apart MogileFS のインストールと初期設定 : Tech Talk Blog – Six Apart MogileFSで構築する高速スケーラブルな分散ファイルシステム – builder PerlbalでMogileFSを更に高速化、効率化する – builder OSS分散ファイルシステムMogileFS で組む素敵システム  動作環境  Ubuntu Server 10.04 LTS / 64bit MySQL 5.1 Perl 5.10.1  MogileFSが依存しているライブラリなどを入れる あらかじめGCC、MySQLをインストールしておきます。\nsudo apt-get install build-essential mysql-server-5.1 libmysqlclient16-dev 次にMogileFSのインストールに必要なライブラリをCPANでインストールします。\n$ sudo cpan cpan[1]\u0026gt; install YAML capn[2]\u0026gt; install Net::Netmask cpan[3]\u0026gt; install Danga::Socket cpan[4]\u0026gt; install IO::AIO cpan[5]\u0026gt; install IO::WrapTie cpan[6]\u0026gt; install DBI cpan[7]\u0026gt; install DBD::mysql cpan[8]\u0026gt; install Perlbal MogileFSのインストール MogileFS-Clientのソースをダウンロード、展開、インストールします。\n$ cd /usr/local/src $ sudo wget http://search.cpan.org/CPAN/authors/id/D/DO/DORMANDO/MogileFS-Client-1.14.tar.gz $ sudo tar zxvf sudo tar zxvf MogileFS-Client-1.14.tar.gz $ cd MogileFS-Client-1.14/ $ sudo perl Makefile.PL $ sudo make $ sudo make install MogileFS-Utilsのソースをダウンロード、展開、インストールします。\n$ cd /usr/local/src $ sudo wget http://search.cpan.org/CPAN/authors/id/D/DO/DORMANDO/MogileFS-Utils-2.19.tar.gz $ sudo tar zxvf MogileFS-Utils-2.19.tar.gz $ cd MogileFS-Utils-2.19/ $ sudo perl Makefile.PL $ sudo make $ sudo make install MogileFS-Serverのソースをダウンロード、展開、インストールします。\n$ cd /usr/local/src $ sudo wget http://search.cpan.org/CPAN/authors/id/D/DO/DORMANDO/MogileFS-Server-2.46.tar.gz $ sudo tar zxvf MogileFS-Server-2.46.tar.gz $ cd MogileFS-Server-2.46/ $ sudo perl Makefile.PL $ sudo make $ sudo make install MogileFSの初期設定 DBにスキーマを作成します。一発でDB、ユーザーを作成してくれるコマンドがあるので利用します。\nmogdbsetup --dbrootuser=root --dbrootpass=hogehoge --dbuser=mogilefs --dbpass=mogilefs --yes Trackerの設定（mogilefsd） デフォルトだと /etc/mogilefs/mogilefsd.conf を読みに行きます。特に変更する必要も無いのでデフォルトのままいきます。変更したい場合は -c で指定出来ます。\n$ sudo mkdir /etc/mogilefs /etc/mogilefs/mogilefsd.conf はこのページを参考にして次のようにしました。\ndaemonize = 1 db_dsn = DBI:mysql:mogilefs:host=127.0.0.1 db_user = mogilefs db_pass = mogilefs conf_port = 7001 listener_jobs = 10 Trackerは root ユーザーでは実行出来ませんので 専用のユーザーを作ってあげる必要があります。\nsudo useradd -s /bin/false mogilefs sudo -u mogilefs mogilefsd psコマンドで起動しているか確認。\n$ ps ax | grep mogilefsd 11160 ? S 0:00 mogilefsd 11161 ? S 0:00 mogilefsd [replicate] 11162 ? S 0:00 mogilefsd [delete] 11163 ? S 0:00 mogilefsd [queryworker] 11164 ? S 0:00 mogilefsd [queryworker] 11165 ? S 0:00 mogilefsd [queryworker] 11166 ? S 0:00 mogilefsd [queryworker] 11167 ? S 0:00 mogilefsd [queryworker] 11168 ? S 0:00 mogilefsd [queryworker] 11169 ? S 0:00 mogilefsd [queryworker] 11170 ? S 0:00 mogilefsd [queryworker] 11171 ? S 0:00 mogilefsd [queryworker] 11172 ? S 0:00 mogilefsd [queryworker] 11173 ? S 0:00 mogilefsd [monitor] 11174 ? S 0:00 mogilefsd [reaper] 11175 ? S 0:00 mogilefsd [job_master] 11176 ? SN 0:00 mogilefsd [fsck] Storage nodeの設定（mogstored） デフォルトだと /etc/mogilefs/mogstored.conf を読みに行きます。Trackerと同様、変更したい場合は -c で指定出来ます。\nhttplisten = 0.0.0.0:7500 mgmtlisten = 0.0.0.0:7501 docroot = /var/mogdata /etc/mogilefs/mogstored.conf で指定したdocrootのディレクトリを作成します。\nsudo mkdir /var/mogdata Trackerとは違いStorage nodeは root ユーザーで起動させます。\n$ sudo mogstored -d $ ps ax | grep mogstored 11209 ? Ss 0:00 mogstored 11210 ? S 0:00 mogstored [diskusage] 11211 ? S 0:00 mogstored [iostat] Storage node の登録 上記インストール・初期設定が終われば、あとはmogadmコマンドを使用して設定していくことが出来ます。\nTrackerが正常に動作しているか確認。\n$ mogadm check Checking trackers... 127.0.0.1:7001 ... OK Checking hosts... No devices found on tracker(s). TrackerはOKと出ていますが、Checking hosts…ではNo devicesと出てしまっていますので、mogadm host add で Storage node を登録します。\n$ mogadm host add localhost --port=7500 $ mogadm check Checking trackers... 127.0.0.1:7001 ... OK Checking hosts... [ 1] localhost ... skipping; status = down No devices found on tracker(s). Deviceの登録 $ mogadm device add localhost 1 $ mogadm device add localhost 2 $ sudo mkdir /var/mogdata/{dev1,dev2} $ mogadm device list localhost [1]: down used(G) free(G) total(G) dev1: down 0.000 0.000 0.000 dev2: down 0.000 0.000 0.000 downとなっているので有効にしてあげます。\n$ mogadm host mark localhost alive $ mogadm check Checking trackers... 127.0.0.1:7001 ... OK Checking hosts... [ 1] localhost ... OK Checking devices... host device size(G) used(G) free(G) use% ob state I/O% ---- ------------ ---------- ---------- ---------- ------ ---------- ----- [ 1] dev1 7.109 1.066 6.042 15.00% writeable 0.0 [ 1] dev2 7.109 1.066 6.042 15.00% writeable 0.0 ---- ------------ ---------- ---------- ---------- ------ total: 14.217 2.132 12.085 15.00% これでようやくMogileFSが使用可能になりました！\nMogileFSのクライアントはPerl以外でも出ていますので、分散ストレージとして色々使い道があるのではないでしょうか。私の会社ではRailsアプリの画像ストレージとして利用しています。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2011/04/19/rails3-1-1.html",
                "title": "Rails 3.1 を試してみる（導入編）",
                "section": "post",
                "date" : "2011.04.19",
                "body": "Rails3.1の機能を試せると聞いたので、早速下記サイトを参考にローカル環境に入れてみました。噂のCoffeeScriptやSCSSが使えるようになっています。\n edge rails(Rails 3.1)の新機能を調べてみる – おもしろWEBサービス開発日記  インストールその1 rvmにRails3.1専用のgemsetを用意しました。Rubyのバージョンは Ruby 1.9.2-p180 です。\nrvm gemset create rails31 rvm gemset use rails31 この状態だとRakeしか入っていません。\n$ gem list *** LOCAL GEMS *** rake (0.8.7) Railsアプリ用のディレクトリを作成します。\nmkdir rails_app cd rails_app vim Gemfile Gemfileを作ってRailsのGithubリポジトリを指定します。\n# Gemfile source \u0026#34;http://rubygems.org/\u0026#34; gem \u0026#39;rails\u0026#39;, :git =\u0026gt; \u0026#39;git://github.com/rails/rails.git\u0026#39; BundlerとRails3.1をインストールします。\ngem install bundler bundle install インストールされたRailsのバージョンを確認してみましょう。\n$ bundle exec rails -v Rails 3.1.0.beta 無事入ってそうです。\nインストールその2 Railsが入ったことを確認出来たら、実際にRailsアプリを生成してみます。先ほど作成したGemfileとコンフリクトしますが、気にせず上書きしてしまいましょう。\n$ bundle exec rails new . exist create README create Rakefile create config.ru create .gitignore force Gemfile create app create app/assets/javascripts/application.js create app/assets/stylesheets/application.css create app/controllers/application_controller.rb create app/helpers/application_helper.rb create app/mailers create app/models create app/views/layouts/application.html.erb create app/mailers/.gitkeep create app/models/.gitkeep create config create config/routes.rb create config/application.rb create config/environment.rb create config/environments create config/environments/development.rb create config/environments/production.rb create config/environments/test.rb create config/initializers create config/initializers/backtrace_silencers.rb create config/initializers/inflections.rb create config/initializers/mime_types.rb create config/initializers/secret_token.rb create config/initializers/session_store.rb create config/locales create config/locales/en.yml create config/boot.rb create config/database.yml create db create db/seeds.rb create doc create doc/README_FOR_APP create lib create lib/tasks create lib/tasks/.gitkeep create log create log/.gitkeep create public create public/404.html create public/422.html create public/500.html create public/favicon.ico create public/index.html create public/robots.txt create public/images create public/images/rails.png create script create script/rails create test/fixtures create test/fixtures/.gitkeep create test/functional create test/functional/.gitkeep create test/integration create test/integration/.gitkeep create test/unit create test/unit/.gitkeep create test/performance/browsing_test.rb create test/test_helper.rb create tmp/cache create tmp/cache/.gitkeep create vendor/assets/javascripts/jquery.js create vendor/assets/javascripts/jquery_ujs.js create vendor/assets/stylesheets create vendor/assets/stylesheets/.gitkeep create vendor/plugins create vendor/plugins/.gitkeep 新しく生成されたGemfileを眺めてみます。\nsource \u0026#39;http://rubygems.org\u0026#39; gem \u0026#39;rails\u0026#39;, \u0026#39;3.1.0.beta\u0026#39; # Bundle edge Rails instead: # gem \u0026#39;rails\u0026#39;, :git =\u0026gt; \u0026#39;git://github.com/rails/rails.git\u0026#39; # gem \u0026#39;arel\u0026#39;, :git =\u0026gt; \u0026#39;git://github.com/rails/arel.git\u0026#39; # gem \u0026#39;rack\u0026#39;, :git =\u0026gt; \u0026#39;git://github.com/rack/rack.git\u0026#39; # gem \u0026#39;sprockets\u0026#39;, :git =\u0026gt; \u0026#34;git://github.com/sstephenson/sprockets.git\u0026#34; gem \u0026#39;sqlite3\u0026#39; # Asset template engines gem \u0026#39;sass\u0026#39;, \u0026#39;~\u0026gt; 3.1.0.alpha\u0026#39; gem \u0026#39;coffee-script\u0026#39; # Use unicorn as the web server # gem \u0026#39;unicorn\u0026#39; # Deploy with Capistrano # gem \u0026#39;capistrano\u0026#39; # To use debugger # gem \u0026#39;ruby-debug19\u0026#39;, :require =\u0026gt; \u0026#39;ruby-debug\u0026#39; group :test do # Pretty printed test output gem \u0026#39;turn\u0026#39;, :require =\u0026gt; false end 相変わらず標準のDBはSQLite3のようです。またsassとcoffee-scriptのgemが書かれていますね。さて、このままbundle installを実行するとRubygemsにrails 3.1.0.beta’なんて無いと怒られてしまうのでコメントアウトし、コメントアウトされているBundle edge Rails instead以下を有効にします。\n# gem \u0026#39;rails\u0026#39;, \u0026#39;3.1.0.beta\u0026#39; # Bundle edge Rails instead: gem \u0026#39;rails\u0026#39;, :git =\u0026gt; \u0026#39;git://github.com/rails/rails.git\u0026#39; gem \u0026#39;arel\u0026#39;, :git =\u0026gt; \u0026#39;git://github.com/rails/arel.git\u0026#39; gem \u0026#39;rack\u0026#39;, :git =\u0026gt; \u0026#39;git://github.com/rack/rack.git\u0026#39; gem \u0026#39;sprockets\u0026#39;, :git =\u0026gt; \u0026#34;git://github.com/sstephenson/sprockets.git\u0026#34; 再度bundle installを実行。\nbundle install Scaffoldで生成されたものを覗く 実際何が変わったかはScaffoldで生成されたファイルを見てみるのが一番早いと思いますので、適当にジェネレートしてみます。\n$ bundle exec rails g scaffold article subject:string body:text invoke active_record create db/migrate/20110419121620_create_articles.rb create app/models/article.rb invoke test_unit create test/unit/article_test.rb create test/fixtures/articles.yml route resources :articles invoke scaffold_controller create app/controllers/articles_controller.rb invoke erb create app/views/articles create app/views/articles/index.html.erb create app/views/articles/edit.html.erb create app/views/articles/show.html.erb create app/views/articles/new.html.erb create app/views/articles/_form.html.erb invoke test_unit create test/functional/articles_controller_test.rb invoke helper create app/helpers/articles_helper.rb invoke test_unit create test/unit/helpers/articles_helper_test.rb create app/assets/stylesheets/scaffold.css.scss invoke assets create app/assets/javascripts/articles.js.coffee create app/assets/stylesheets/articles.css.scss 現状のRails EdgeだとまだRSpecが標準にはなっていないようです。その代わりapp/assetsというディレクトリが新たに出現していて、その中に.coffeeと.scssなファイルが作られています。\napp/assets/stylesheets/scaffold.css.scssを覗いてみましょう。\nbody { background-color: #fff; color: #333; } body, p, ol, ul, td { font-family: verdana, arial, helvetica, sans-serif; font-size: 13px; line-height: 18px; } pre { background-color: #eee; padding: 10px; font-size: 11px; } a { color: #000; \u0026amp;:visited { color: #666; } \u0026amp;:hover { color: #fff; background-color:#000; } } div.field, div.actions { margin-bottom: 10px; } #notice { color: green; } .field_with_errors { padding: 2px; background-color: red; display: table; } #error_explanation { width: 450px; border: 2px solid red; padding: 7px; padding-bottom: 0; margin-bottom: 20px; background-color: #f0f0f0; h2 { text-align: left; font-weight: bold; padding: 5px 5px 5px 15px; font-size: 12px; margin: -7px; margin-bottom: 0px; background-color: #c00; color: #fff; } ul li { font-size: 12px; list-style: square; } } まとめ 今回はRails3.1をインストールし、Scaffoldの生成物を眺めただけです。。。実を言うと、私は最近までCoffeeScriptもSCSSも完全にノーマークでして、両方ともさわり程度しか知りませんでした(^^; 油断するとあっという間に置き去りにされそうです。\n次回はCoffeeScriptとSCSSがどれくらい便利なのか色々触ってみたいと思います（多分）。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2011/04/04/patch-rails3-mail.html",
                "title": "RFCに違反している（ドットが連続する）メールアドレスをRails3で扱うには",
                "section": "post",
                "date" : "2011.04.04",
                "body": "Rails3のActionMailer（Mail）で、DoCoMoやauに存在するRFC違反のメールアドレス（@の前にドットが連続するやつ）を受信するときの対処方法を書いておきます。\nRails2以前（TMail）のときはFromがnilになって取得出来なくて、仕方なくパーサを書き換えるという結構面倒な事をしていましたが、Rails3では一応取得することは出来ます。ただし、Fromのフォーマットによって挙動が変わってきますので注意が必要です。\n具体的には下記のようになります。\n# 通常のメールアドレスの場合 ruby-1.9.2-p180 \u0026gt; mail.from =\u0026gt; [\u0026quot;d.akatsuka@gmail.com\u0026quot;] ruby-1.9.2-p180 \u0026gt; mail.from.class =\u0026gt; Mail::AddressContainer # @の前にドットが連続するメールアドレスの場合 ruby-1.9.2-p180 \u0026gt; mail.from =\u0026gt; d.akatsuka...@gmail.com ruby-1.9.2-p180 \u0026gt; mail.from.class =\u0026gt; ActiveSupport::Multibyte::Chars # @の前にドットが連続し、かつ名前が入っている場合 ruby-1.9.2-p180 \u0026gt; mail.from =\u0026gt; Dai Akatsuka \u0026lt;d.akatsuka...@gmail.com\u0026gt; ruby-1.9.2-p180 \u0026gt; mail.from.class =\u0026gt; ActiveSupport::Multibyte::Chars # @の前にドットが連続し、かつマルチバイトな名前が入っている場合 ruby-1.9.2-p180 \u0026gt; mail.from =\u0026gt; \u0026quot;赤塚 \u0026lt;d.akatsuka...@gmail.com\u0026gt;\u0026quot; ruby-1.9.2-p180 \u0026gt; mail.from.class =\u0026gt; String こ、これは面倒臭い（# ＾ω＾）\nFromのフォーマットによってオブジェクトまで変わってしまうと扱うのが面倒です。（しかもメールアドレスだけではなくて名前まで取得してしまうという。。）\nそこでどのフォーマットのメールアドレスが来ても、FromをStringで取得出来るパッチを書きました。\n# coding: utf-8 module Mail class Message def from_with_patch_rfc_violation str = from_without_patch_rfc_violation begin str = str.join rescue str = str.to_s end str.scan(/^.*?([a-zA-Z0-9._-]+@[a-zA-Z0-9._-]+?)(?![a-zA-Z0-9._-]).*$/).flatten.first end alias_method_chain :from, :patch_rfc_violation end end 上記パッチを config/initializers に mail_patch.rb として保存するだけでOKです。\nruby-1.9.2-p180 \u0026gt; mail.from =\u0026gt; \u0026#34;d.akatsuka...@gmail.com\u0026#34; ruby-1.9.2-p180 \u0026gt; mail.from.class =\u0026gt; String 一応某サイトに仕込んで2週間ほど経過していますが、特に不具合は出ていないようです。もし同様の件で困っている方が居ましたらお試しください。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2011/02/22/rails3-helpers.html",
                "title": "Rails3でビュー以外からヘルパーを呼び出す方法",
                "section": "post",
                "date" : "2011.02.22",
                "body": "例えばコントローラやモデル、もしくはバッチ処理でヘルパーを使いたい時がたまにあるんですよね。いつも忘れてしまうのでブログに残しておきます。\nApplicationController.helpers.image_tag( ..... ) "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2011/02/09/ruby-decoration-mail.html",
                "title": "Rubyでデコメールをパースするライブラリを作ってみた",
                "section": "post",
                "date" : "2011.02.09",
                "body": "モバイルサイトを開発・運営していると割と早い段階で上がってくる要望があります。\nそれは「デコメールに対応したい」\n悪名高い「かんたんログイン」の次くらいに多い印象です。今回はこのデコメールをパースするライブラリを作成してみました。今のところデコメールの作成までは想定していませんが、自分が必要になったら実装し出すかもしれません（笑）\nライブラリの特徴  Rails3から採用されたActionMailerのバックエンド、Mailライブラリを少し拡張して利用します。 デコメールのHTMLをXHTMLとインラインCSSに変換します。 デコメールのHTMLからHTMLタグ、HEADタグ、BODYタグが削除されて本文のみ取得出来ます。 デコメール画像のURLをContent-IDから自動でファイル名に置き換えます（変更可能）。 DoCoMo / au / SoftBankから送られてくるメールをパース出来ます。  動作環境 Ruby 1.9.2-136 で動作検証を行っています。まだ試してませんが1.8.7でも動作すると思われます。\nインストール gemコマンドでインストールします\ngem install decoration_mail もしくはGithubのリポジトリからcloneしてきます。\ngit clone git://github.com/dakatsuka/decoration_mail.git 使用方法 Mail::Messageクラスにdecorationというメソッドを追加していて、それを呼び出す事によってデコメールをパースした結果を返します。使い方は下記コードの通りです。\n# coding: utf-8 require \u0026#39;rubygems\u0026#39; require \u0026#39;mail\u0026#39; require \u0026#39;decoration_mail\u0026#39; # 普通は標準入力から受け取ると思います。 # Rails3ならreceiveメソッド内で既にインスタンスとして存在してるはずです。 @mail = Mail.read(\u0026#34;/path/to/sample.eml\u0026#34;) @deco = @mail.decoration @html = @deco.save do |image| File.open(\u0026#34;/path/to/#{image.filename}\u0026#34;, \u0026#34;wb\u0026#34;) {|f| f.write(image.body)} end puts @html # =\u0026gt; \u0026#39;\u0026lt;div style=\u0026#34;......\u0026#39; # デコメール本文（XHTML） saveメソッドの中で使えるブロック変数はデコメール画像のインスタンスが格納されています。このブロック変数では下記メソッドが使用可能です。\n@html = @deco.save do |image| image.content_id # =\u0026gt; Content-ID 例： cid:xxxxxx image.filename # =\u0026gt; 画像のファイル名 image.body # =\u0026gt; 画像データ end またpathを指定することで画像のURLを任意に指定することが出来ます（指定しない場合は画像のファイル名になります）。\n@html = @deco.save do |image| image.path = \u0026#34;http://image.example.com/#{image.filename}\u0026#34; end puts @html # =\u0026gt; \u0026lt;img\u0026gt;タグのsrcが変わる さらにsaveメソッドにother_imagesというオプションを指定することで、デコメール内で使用されていない添付画像をデコメに貼り付けることが出来ます。\n# デコメールの上部に挿入 @html = @deco.save(:other_images =\u0026gt; :top) do |image| end # デコメールの下部に挿入 @html = @deco.save(:other_images =\u0026gt; :bottom) do |image| end puts @html # =\u0026gt; 出力されるXHTMLに添付画像のIMGタグが追加されています。 デコメールで使用していない画像を無視したい場合は、image.content_idがnilかどうかで判定出来ます。\nif image.content_id else end 以上です！まだ作ったばかり＆手元の実機が数台しか無いためバグが出る可能性があります。。。。その時は是非Twitter、もしくはGithub経由で報告して頂けると幸いです。\nGithub: https://github.com/dakatsuka/decoration_mail\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2011/01/24/rails3-jpmobile-cucumber.html",
                "title": "Ruby1.9 + Rails3 + jpmobileで構築したサイトをcucumberでテストするためのTips",
                "section": "post",
                "date" : "2011.01.24",
                "body": "地味に苦戦したのでメモしておきます。これだから携帯向けサイトは大変・・・\n開発環境\n Ruby 1.9.2-p136 Ruby on Rails 3.0.3 jpmobile 0.1.4 cucumber 0.10.0 ( capybara 0.4.0 )  インストール cucumberを動かすためのgemをインストールします。今回はバックエンドにcapybaraを使用します。（WebratはRails3だとうまく動きませんでした）\n# Gemfile group :test do gem \u0026#39;rspec-rails\u0026#39; gem \u0026#39;cucumber-rails\u0026#39; gem \u0026#39;capybara\u0026#39; end Bundlerでインストールし、cucumberをRailsプロジェクトに組み込みます。\nbundle install rails g cucumber:install ja --rspec --capybara capybaraのUserAgentを偽装する モバイルサイトのテストなので、UAを偽装してアクセスしたいところです。ところがcapybaraは、HTTPヘッダをカスタマイズする機能が標準では備わっていないようなので、自力で何とかしないといけません。ググってみると、Testing custom headers and ssl with Cucumber and Capybara という記事を発見しました。ここにcapybaraでHTTPヘッダを変える方法が書いてあります。\nこの記事を参考に下記ソースを features/support/headers_hack.rb に保存します。\nmodule RackTestMixin def self.included(mod) mod.class_eval do # This is where we save additional entries. def hacked_env @hacked_env ||= {} end # Alias the original method for further use. alias_method :original_env, :env # Override the method to merge additional headers. # Plus this implicitly makes it public. def env original_env.merge(hacked_env) end end end end Capybara::Driver::RackTest.send :include, RackTestMixin module HeadersHackHelper def add_headers(headers) page.driver.hacked_env.merge!(headers) end end World(HeadersHackHelper) そして、features/step_definitions/mobile_support.rb というファイルを作成して、下記コードを貼り付けます。\n# coding: utf-8 前提 /^携帯端末でアクセスしている$/ do add_headers({\u0026#39;HTTP_USER_AGENT\u0026#39; =\u0026gt; \u0026#39;KDDI-CA39 UP.Browser/6.2.0.13.1.5 (GUI) MMP/2.0\u0026#39;, \u0026#39;HTTP_X_UP_SUBNO\u0026#39; =\u0026gt; \u0026#39;subscriber\u0026#39;}) end これで、各シナリオの前提に「携帯端末でアクセスしている」と書くことによってUAが偽装された状態でテストが実行されます。\nちなみに偽装するUAは、セッション・クッキーの仕様上、DoCoMoではなくauをお勧めします。\ninvalid byte sequence in Shift_JIS を黙らせる capybaraの仕様なのかcucumberの仕様なのか分からないのですが、フォームで入力される文字はUTF-8固定になるようです。\njpmobileのmobile_filterを有効にしていると、半角カタカナなどが混ざったデータがポストされた時に invalid byte sequence in Shift_JIS というエラーが発生してしまいます。\nこれを回避するために、テストが実行される時のみmobile_filterを動作させないようにします。若干無理矢理ですが、config/application.rb の mobile_filter 呼び出し箇所を次のように変更します。\nunless Rails.env == \u0026#34;test\u0026#34; config.jpmobile.mobile_filter config.jpmobile.form_accept_charset_conversion = true end 以上で、通常のサイトをテストする感じでモバイルサイトもテスト出来るようになるはずです。\n何か間違っている箇所やもっとベストな方法があったら教えて下さい！\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2010/12/23/rails3-cover-me.html",
                "title": "Rails3 + cover_me でテストカバレッジ",
                "section": "post",
                "date" : "2010.12.23",
                "body": "Ruby 1.9 + Rails3 で rcov がうまく動かなかったので cover_me というカバレッジツールを使ってみる事にしました。\nGemfileに下記行を追加して、\ngem \u0026#34;cover_me\u0026#34; 下記コマンドでインストールします。\n$ bundle install $ rails g cover_me:install あとはいつも通りrake specを実行すれば、自動でcoverageディレクトリが作成されその中にカバレッジ結果が格納されます（HTML形式）。\nお手軽です！\nちなみにMacではテスト終了後自動でブラウザが起動してHTMLを表示してくれましたが、Ubuntuではエラーが出たため、下記コードをlib/tasks/cover_me.rakeの先頭に追加して自動でブラウザが起動しないようにしました。\nCoverMe.config do |c| c.at_exit = Proc.new {} end "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2010/11/29/activerecord-dirty.html",
                "title": "ActiveRecordオブジェクトの属性変更を確認・取得する",
                "section": "post",
                "date" : "2010.11.29",
                "body": "ActiveRecord（Rails3だとActiveModel）は、自分自身（オブジェクト）のプロパティが変更されたかどうか、またどのプロパティがどのように変更されたのかなどを取得する機能が備わっています。\n管理画面で操作ログなどを実装する時に役立ちそうです。\n変更無し：\n@user = User.find_by_email(\u0026#34;old@exmaple.com\u0026#34;) @user.changed? # =\u0026gt; false @user.changes # =\u0026gt; {} emailを変更してみる：\n@user = User.find_by_email(\u0026#34;old@exmaple.com\u0026#34;) @user.email = \u0026#34;new@exmaple.com\u0026#34; @user.changed? # =\u0026gt; true @user.changes # =\u0026gt; {\u0026#34;email\u0026#34;=\u0026gt;[\u0026#34;old@exmaple.com\u0026#34;, \u0026#34;new@exmaple.com\u0026#34;]} @user.email_change # =\u0026gt; [\u0026#34;old@exmaple.com\u0026#34;, \u0026#34;new@example.com\u0026#34;] @user.email_was # =\u0026gt; \u0026#34;old@exmaple.com\u0026#34; "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2010/11/22/sharing-sessions-rails2-rails3.html",
                "title": "Rails2とRails3でセッションを共有する",
                "section": "post",
                "date" : "2010.11.22",
                "body": "サブドメインが異なるRails2アプリとRails3アプリでセッションを共有したい場合、Cookie Session Storeに互換性が無いみたいでそのまま共有しようとすると問題が発生します。\n具体的にどういう問題があるかというと、\n Rails2はCookieのKeyをSymbolとして扱う。しかしRails3はStringとして扱っている。 Flash周りは何とマーシャルしてCookieに保存されている。Rails2とRails3でモジュール・クラス名が異なっているのでアンマーシャル時にuninitialized constantが発生する。  まず1つ目の問題ですが、幸いなことにRails3はKeyがSymbolでも読み込みが可能です。ただし一度でも読み込むとStringに変換されてRails2からは読めなくなります。ということは、Rails2でStringなKeyを認識出来るようにすれば、この問題は解決出来そうです。\n2つ目の問題は、双方に存在しないモジュール・クラスを予め定義しておけばエラーは出ないはずです。\n以上を踏まえてRails2、Rails3にモンキーパッチを当てます。\nRails2側 config/initializersにaccept_rails3_session.rbなど適当に名前をつけて下記ソースをコピペします。\nmodule ActionDispatch module Flash class FlashHash \u0026lt; Hash def method_missing(m, *a, \u0026amp;b) end end end end module ActionController module Session class CookieStore private def unmarshal(cookie) if cookie data = persistent_session_id!(@verifier.verify(cookie)) data.symbolize_keys! end rescue ActiveSupport::MessageVerifier::InvalidSignature nil end def requires_session_id?(data) if data data.respond_to?(:key?) \u0026amp;\u0026amp; !data.key?(:session_id) \u0026amp;\u0026amp; !data.key?(\u0026#34;session_id\u0026#34;) else true end end end end end config/initializers/session_store.rbを開き、:key、:secret、:domainを設定します。この3つはRails3側も同じにする必要があります。\nActionController::Base.session = { :key =\u0026gt; \u0026#39;_session\u0026#39;, :secret =\u0026gt; \u0026#39;xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\u0026#39;, :domain =\u0026gt; \u0026#39;.example.com\u0026#39; } Rails3側 config/initializersにaccept_rails2_session.rbなど適当に名前をつけて下記ソースをコピペします。\nmodule ActionController module Flash class FlashHash \u0026lt; Hash def method_missing(m, *a, \u0026amp;b) end end end end config/initializers/session_store.rbを開き、:keyと:domainをRails2側で設定した値と同じ値にします。\nAppName::Application.config.session_store :cookie_store, :key =\u0026gt; \u0026#39;_session\u0026#39;, :domain =\u0026gt; \u0026#39;.example.com\u0026#39; config/initializers/secret_token.rbを開き、Rails2側で設定した:secretと同じ値にします。\nAppName::Application.config.secret_token = \u0026#39;xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\u0026#39; 以上です！これでRails2とRails3でセッションを共有出来るようになります。\nまだ残る問題点  Rails2側がRuby1.8.xでRails3側がRuby1.9.2の構成で、Rails2で作成したFlash MessageをRails3側で読み出すとincompatible character encodingsになります。 Rails2側で作成したFlash MessageをRails3側で呼び出すとFlashが消えてくれません。  Flash周りはもう少し考えないと厳しいかもしれません。。。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2010/11/14/rvm-gemset.html",
                "title": "RVMのgemsetを使ってみる",
                "section": "post",
                "date" : "2010.11.14",
                "body": "Rubyの開発環境にRVMを使っている場合は、bundle install –pathを使うよりもgemsetという機能を使ったほうがお手軽に管理出来るみたいです。\n$ rvm gemset create hoge-project $ rvm gemset use hoge-project $ bundle install どのgemsetを使用しているか確認\n$ rvm gemset name hoge-project gemsetの一覧を表示\n$ rvm gemset list gemsets : for ruby-1.9.2-p0 (found in /home/user/.rvm/gems/) global hoge-project "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2010/11/09/bundle-install.html",
                "title": "bundle installするときはpathを指定しよう",
                "section": "post",
                "date" : "2010.11.09",
                "body": "Rails3からBundlerが導入されgemの管理がしやすくなりましたが、色々なRailsアプリでほいほいbundle installを実行するとシステムにインストールされるgemが結構カオスになってきます。また、Rails2とRails3が同居する開発環境だとかなり面倒くさくなります。精神衛生上あまり宜しくありません。\nそこでbundlerにオプションを渡してgemを任意のディレクトリにインストールし、gemをRailsプロジェクト毎に管理することをオススメします。\nRails3の場合、使い方はこんな感じになります。\nまず、プロジェクト用のディレクトリを作成し、Gemfileを記述します。\nmkdir newapp cd ./newapp vim Gemfile Gemfileにはrailsだけ指定します。\nsource \u0026#34;http://rubygems.org\u0026#34; gem \u0026#34;rails\u0026#34;, \u0026#34;3.0.1\u0026#34; Gemfileを書き終わったらbundleコマンドを使いRailsをインストールします。ここではvendor/bundlerというディレクトリにgemをインストールします。\nbundle install --path vendor/bundler インストールが終わったらRailsプロジェクトを作成します。RailsがGemfileを上書きしていいか質問してくるのでyesと答えて上書きしてしまいましょう。なお、インストールするディレクトリを変えた場合、そのディレクトリにはパスが通っていないのでbundle execを通してRailsを実行する必要があります。\nbundle exec rails new . あとは上書きされたGemfileを開いて、RSpecなりhamlなり導入したいgemを書いてbundle installしましょう。\n毎回bundle execなんて打つの面倒過ぎるって人は、.bashrcや.zshrcにエイリアス設定しちゃいましょう。私は下記のようにしています。\nalias be=\u0026#34;bundle exec\u0026#34; こうすることで、\nbe rake db:migrate be rails s みたいな感じで使っていくことが出来ます。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2010/11/01/mobile-site-in-cucumber.html",
                "title": "cucumberで携帯サイトをテストするには",
                "section": "post",
                "date" : "2010.11.01",
                "body": "達人出版会から出版された「はじめる！Cucumber」という本を本日購入しました。日本語で丁寧に書かれている良書で、cucumberをこれから触ってみたい方にはオススメです。\nさて、このcucumberを携帯サイトのプロジェクトで使った場合、そのままだとUAで弾かれたりして使用出来ないかもしれません。その場合は、下記をfeatures/support/env.rbに追記することによって、UAの偽装と個体識別番号の付与が出来ます。\n前提 /^携帯でアクセスしている$/ do header(\u0026#39;user_agent\u0026#39;, \u0026#39;DoCoMo/2.0 P906i(c100;TB;W24H15)\u0026#39;) header(\u0026#39;x_dcmguid\u0026#39;, \u0026#39;subscriber\u0026#39;) end "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2010/10/31/streaming-api-to-mongodb.html",
                "title": "Twitter Streaming APIをMongoDBに保存して遊んでみる",
                "section": "post",
                "date" : "2010.10.31",
                "body": "TwitterのストリーミングAPIを利用する場合、かなりのデータ量が流れてくるので、リアルタイムに解析・集計などを行うと処理が追いつかない可能性が出てきます。\nそこで、流れてきたデータをいったんどこかに保存しておいて後からバッチ処理で解析をしていく事になると思います。今回はその保存先にMongoDBをチョイスします。\nなぜMongoDBなのか  RDBMSに比べて高速 BSON形式で保存するので、JSONの階層構造をそのまま維持して保存可能 NoSQLながらGROUP BYライクな集計処理が可能  ということで、試しにストリーミングAPIのsampleから流れてくるデータをMongoDBに保存するスクリプトを書いてみました。このスクリプトを動かすには、別途MongoDB本体と「json」「bson_ext」「mongo」の3つのgemが必要になります。\n# coding: utf-8 # This program is free software. It comes without any warranty, to # the extent permitted by applicable law. You can redistribute it # and/or modify it under the terms of the Do What The Fuck You Want # To Public License, Version 2, as published by Sam Hocevar. See # http://sam.zoy.org/wtfpl/COPYING for more details. require \u0026#39;rubygems\u0026#39; require \u0026#39;net/https\u0026#39; require \u0026#39;openssl\u0026#39; require \u0026#39;uri\u0026#39; require \u0026#39;json\u0026#39; require \u0026#39;mongo\u0026#39; USERNAME = \u0026#34;\u0026#34; PASSWORD = \u0026#34;\u0026#34; con = Mongo::Connection.new db = con.db(\u0026#39;twitter\u0026#39;) tweets = db.collection(\u0026#39;tweets\u0026#39;) uri = URI.parse(\u0026#39;https://stream.twitter.com/1/statuses/sample.json\u0026#39;) https = Net::HTTP.new(uri.host, uri.port) https.use_ssl = true https.verify_mode = OpenSSL::SSL::VERIFY_NONE https.verify_depth = 5 https.start do |h| request = Net::HTTP::Get.new(uri.request_uri) request.basic_auth(USERNAME, PASSWORD) h.request(request) do |response| response.read_body do |chunk| parsed = JSON.parse(chunk) rescue next tweets.insert(parsed) end end end 実際に動かしてみた結果 上記スクリプトを15分程度動かしてみて、MongoDBのshellから色々クエリを投げてみました。\n$ mongo twitter MongoDB shell version: 1.6.3 connecting to: twitter // 件数を取得する \u0026gt; db.tweets.find().count() 2093 // 日本語のツイートの件数を取得する（もしかしたら日本語で登録しているユーザーかな？） \u0026gt; db.tweets.find({\u0026quot;user.lang\u0026quot;: \u0026quot;ja\u0026quot;}).count() 568 // タイムゾーンを指定して件数を取得する \u0026gt; db.tweets.find({\u0026quot;user.time_zone\u0026quot; : \u0026quot;Tokyo\u0026quot;}).count() 363 \u0026gt; db.tweets.find({\u0026quot;user.time_zone\u0026quot; : \u0026quot;Osaka\u0026quot;}).count() 38 // Twitterクライアントを指定して検索 \u0026gt; db.tweets.find({\u0026quot;source\u0026quot; : /TweetDeck/i}).count() 72 \u0026gt; db.tweets.find({\u0026quot;source\u0026quot; : /Twitter for iPhone/i}).count() 99 さらにMongoDB shellではJavaScriptが使用出来るので、ちょっとコードを書くだけでTwitterクライアントのランキングを作成することも出来ます。\nfunction count_source(order) { var result = db.tweets.group({ key: { source:true }, reduce: function(obj, prev) { prev.count++; }, initial: { count: 0 }, }); if (order == \u0026#34;asc\u0026#34;) { return result.sort( function(a, b) { return a[\u0026#39;count\u0026#39;] \u0026gt; b[\u0026#39;count\u0026#39;] ? 1 : -1; } ); } else if (order == \u0026#34;desc\u0026#34;) { return result.sort( function(a, b) { return a[\u0026#39;count\u0026#39;] \u0026lt; b[\u0026#39;count\u0026#39;] ? 1 : -1; } ); } } // ランキングを昇順に並び替え \u0026gt; count_source(\u0026#34;asc\u0026#34;) // ランキングを降順に並び替え \u0026gt; count_source(\u0026#34;desc\u0026#34;) これを応用すればランキングサイトなども簡単に作れそうですね。まぁ、その前にタイムアウトした場合の再接続処理とか、デーモン化とかやるべき事がたくさんありそうですが。。。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2007/09/07/vim-css.html",
                "title": "Vim7でCSSをオムニ補完",
                "section": "post",
                "date" : "2007.09.07",
                "body": "CSSも標準で対応してるみたい。以下の行を.vimrcに貼り付けるだけ。\nautocmd FileType css set omnifunc=csscomplete#CompleteCSSC-x C-oで動作しますが、場合によっては普通に入力したほうが早いかも…。background-color等を入力する時には効果を発揮しそうです。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2007/09/05/fedora8.html",
                "title": "Intel G33チップ搭載のPCにFedora8をインストールするには",
                "section": "post",
                "date" : "2007.09.05",
                "body": "そのままDVDを突っ込んでもACPIのチェックでコケてインストーラが起動しないので、起動オプションでACPIを無効にします。\n最初の「Welcome to Fedora！」画面が表示されたら\nInstall or upgrade an existing system を選択しTabキーを押します。押したら枠下のほうに\n\u0026gt; vmlinuz initrd=initrd.img と表示され入力出来る状態になるので\n\u0026gt; vmlinuz initrd=initrd.img acpi=off と書き加えてEnterを押します。=を入力するには、^（へ）キーを押します（英語キーボードとして認識されてるので）以上でひとまずインストールは出来ます。しかしCore2Quadなのに1Coreしか認識してませんでしたorz\nちなみにUbuntu7.10（Gusty）だと正常にインストール出来ました。新チップセットは鬼門ですね。。。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2007/09/03/install-railsl.html",
                "title": "Ruby on Railsを導入する",
                "section": "post",
                "date" : "2007.09.03",
                "body": "Railsで動くツールをいくつか試してみたくなったので、Ubuntuで環境を構築してみました。しょうもないですが手順をメモっておきます。\nRubyをapt-getでインストールします。libredcloth-rubyはredMineのWikiで使われるみたいです。\n$ sudo apt-get install ruby rubygems libredcloth-ruby gemでRailsをインストールします。\n$ sudo gem install rails rake /var/lib/gems/1.8/binにパスを通します。.bashrcをエディタで開いて\nPATH=\u0026#34;$PATH\u0026#34;:/var/lib/gems/1.8/bin 上記を最下部に追加します。即反映させたい場合は\n$ source ~/.bashrc 確認\n$ which rails rake /var/lib/gems/1.8/bin/rails /var/lib/gems/1.8/bin/rake "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2007/08/27/akihabara.html",
                "title": "秋葉原に行ってきました",
                "section": "post",
                "date" : "2007.08.27",
                "body": "以下購入したものリスト。今週末あたりにDebian突っ込んでファイルサーバにする予定です。\n Intel Core2Quad Q6600 Intel DG33FBC crucial 1GB PC2-6400 UnBuffered x2 3ware 9500S-4LP ST3750640AS(750G SATA300 7200) x4 Owltech M12 SS-600HM Antec P182  "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2007/06/13/nvidia-beryl.html",
                "title": "NVIDIA + Berylでウインドウの中身が真っ黒になる",
                "section": "post",
                "date" : "2007.06.13",
                "body": "たくさんウインドウを表示したり、既存のウインドウをリサイズしたりするとこの現象が起こるようです。\nこの現象を回避するには、Berylマネージャを右クリックして、[Berylのより高度なオプション] → [描画プラットフォーム]で AIGLXを強制 にチェックを入れます。これで多分直ります。\nまたウインドウの移動やエフェクトがカクカクする場合は、[Berylの設定] → General Option を開いて以下のように変更すればスムーズに動きます。\n リフレッシュレートを検出 のチェックを外す リフレッシュレートを200に設定 VBlankに同期 のチェックを外す  "
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2007/05/24/qr.html",
                "title": "QRコードを生成するPHP拡張モジュールをインストール",
                "section": "post",
                "date" : "2007.05.24",
                "body": "必要なパッケージやインストールの仕方をメモしておきます。モジュールの使用方法やDebian以外の環境の人は、こちらの記事（讃容日記）を見たほうが良いでしょう。\nインストール まず必要なパッケージを導入します。ここではaptitudeを使ってますがapt-getでも問題ありません。\nsudo aptitude install php4-gd php4-dev graphviz-dev PHP5を使ってる場合は4を5に変えるだけです。\n手順はこんな感じです。1行ずつコピペしていけばOKです。\nwget http://www.opendogs.org/pub/php_qr-0.1.0.tgz tar zxvf php_qr-0.1.0.tgz cd php_qr-0.1.0 mkdir -p ext/gd ln -s /usr/include/graphviz ext/gd/libgd phpize ./configure --enable-qr --enable-qr-gd make sudo make install sudoを使ってない人はsu -でrootになってからmake installしましょう。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2007/04/29/ich-ac97.html",
                "title": "ICH6 AC97で音を出す",
                "section": "post",
                "date" : "2007.04.29",
                "body": "私の使っているノートPC（LaVie G Type J）は、デフォルトのままだと音が出てくれませんorz。どうやら915GM ExpressのICH6でこの症状が出るようです。\n設定を変えれば音が出た  パネル上にあるスピーカーアイコンをダブルクリックしてAlsa mixerを開きます [編集]→設定 表示するトラックの選択でExternal Amplifierにチェックを入れ閉じる [スイッチ]というタブが増えているので、そこを開く External Amplifierのチェックを外す  これで音が出るようになりました。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2007/04/22/install-wine-with-ie-on-ubuntu-feisty.html",
                "title": "Ubuntu FeistyにWineとIEを無理矢理インストール",
                "section": "post",
                "date" : "2007.04.22",
                "body": "64bit環境だと apt-get install wine で導入出来なかったので \u0026ndash;force-architecture オプションで無理矢理入れる方法。\nWineをインストール i386用のdebパッケージを落としてきます。\ncd /tmp wget http://wine.budgetdedicated.com/apt/pool/main/w/wine/wine_0.9.35~winehq0~ubuntu~7.04-1_i386.deb ia32-libsを入れた後（入ってなかったら）dpkgでインストール。\nsudo apt-get install ia32-libs sudo dpkg -i --force-architecture wine_0.9.35~winehq0~ubuntu~7.04-1_i386.deb IEs4Linuxをインストール 事前にcabextractをいれておきます。\nsudo apt-get install cabextract IEs4Linuxのbeta6をダウンロードしてインストールします。\nwget http://www.tatanka.com.br/ies4linux/downloads/ies4linux-2.5beta6.tar.gz tar zxvf ies4linux-2.5beta6.tar.gz cd ies4linux-* ./ies4linux デフォルトのまま作業を進めるとデスクトップにIEのアイコンが出来ますので、それをダブルクリックすればIEが起動します。\n…JAを選んでインストールしたせいかメニューが激しく文字化けしました。もしかしたら英語で入れたほうが幸せになれるかもしれません。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2007/04/21/build-jd-on-ubuntu-feisty.html",
                "title": "64bit環境のUbuntu FeistyでJDをビルド",
                "section": "post",
                "date" : "2007.04.21",
                "body": "Feistyの日本語ローカライズ版が出ました。しかしAMD64への対応はもうちょっとかかるみたいなので、気が短い私はリリースまでの間JD（2ちゃんねるブラウザ）を自前でビルドして使おうと思います。\nアンインストールも手軽に出来るようにdebパッケージ化までしてみます。\n必要なパッケージをインストール まずdebパッケージを作成するのに必要なツールをインスコします。（余計なものまで入れたかも…\nsudo apt-get install autoconf automake libtool libc6-dev dpkg-dev gpc fakeroot debhelper lintian devscripts g++ dh-make g77 次にJDのビルドに必要なライブラリを入れておきます。\nsudo apt-get install libgtkmm-2.4-dev zlib1g-dev libssl-dev パッケージ化 最新のソースをダウンロードしてきて適当なディレクトリに解凍します。\nmkdir /tmp/deb cd /tmp/deb wget http://keihanna.dl.sourceforge.jp/jd4linux/24814/jd-1.8.8-070403.tgz tar zxvf jd-1.8.8-070403.tgz cd jd-1.8.8-070403 autoreconfを実行します。\nautoreconf -i パッケージの基本情報ファイルを作る\ndh_make -e clavice@dotted.jp -s -f ../jd-1.8.8-070403.tgz 個人用なので何も変更せずこのままパッケージ化\ndpkg-buildpackage -rfakeroot ビルドが終わるとひとつ上の階層（ここでは/tmp/deb）にパッケージが出来上がっています。\nインストール 出来上がったパッケージ jd-1.8.8_070403-1_amd64.deb をダブルクリックしてインストール出来ます。\n起動方法は、\njd です。かなりやっつけですがこれでJDが使えるようになります。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2007/04/20/holidays.html",
                "title": "2連休",
                "section": "post",
                "date" : "2007.04.20",
                "body": "Ubuntu 7.04とCentOS5をKVMで動かして色々と遊んでみようと思います。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2007/04/08/feisty-ipamona.html",
                "title": "FeistyでIPAモナーフォントを使う",
                "section": "post",
                "date" : "2007.04.08",
                "body": "日本語ローカライズ版が出るまでの繋ぎとして。\n$ cd /tmp $ wget http://www.geocities.jp/ipa_mona/opfc-ModuleHP-1.1.1_withIPAMonaFonts-1.0.5.tar.gz $ tar zxvf opfc-ModuleHP-1.1.1_withIPAMonaFonts-1.0.5.tar.gz $ cd opfc-*/fonts $ sudo mkdir /usr/share/fonts/truetype/ttf-ipamona $ sudo cp *.ttf /usr/share/fonts/truetype/ttf-ipamona これで次回ログイン時からデフォルトのフォントがIPAモナーフォントになります。ならない場合は、\n$ sudo gedit /etc/fonts/local.conf で、geditを起動して\n\u0026lt;fontconfig\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;test qual=\u0026#34;any\u0026#34; name=\u0026#34;family\u0026#34;\u0026gt; \u0026lt;string\u0026gt;sans-serif\u0026lt;/string\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; mode=\u0026#34;prepend\u0026#34; binding=\u0026#34;strong\u0026#34;\u0026gt; \u0026lt;string\u0026gt;IPAMonaPGothic\u0026lt;/string\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;test qual=\u0026#34;any\u0026#34; name=\u0026#34;family\u0026#34;\u0026gt; \u0026lt;string\u0026gt;serif\u0026lt;/string\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; mode=\u0026#34;prepend\u0026#34; binding=\u0026#34;strong\u0026#34;\u0026gt; \u0026lt;string\u0026gt;IPAMonaPMincho\u0026lt;/string\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;test qual=\u0026#34;any\u0026#34; name=\u0026#34;family\u0026#34;\u0026gt; \u0026lt;string\u0026gt;monospace\u0026lt;/string\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; mode=\u0026#34;prepend\u0026#34; binding=\u0026#34;strong\u0026#34;\u0026gt; \u0026lt;string\u0026gt;IPAMonaGothic\u0026lt;/string\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;/fontconfig\u0026gt; 上記を貼りつけて保存すればフォントが置き換わるはずです。多分\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2007/04/07/anthy.html",
                "title": "Firefox上でのAnthyの挙動がおかしすぎる件",
                "section": "post",
                "date" : "2007.04.07",
                "body": "変換キーを押すと漢字に変換されず空白が挿入されてしまう謎現象が頻繁に起きています。調べてみるとscim-bridge-client-gtkを入れれば直る模様。\n$ sudo apt-get install scim-bridge-client-gtk 直った！\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2007/04/06/nautilus.html",
                "title": "Nautilusの右クリックメニューをカスタマイズ",
                "section": "post",
                "date" : "2007.04.06",
                "body": "Xfce4.4のファイルマネージャであるThunarやKDEのKonquerorには「ターミナルで開く」みたいなメニューがあるんですが、何故かNautilusにはデフォルトでありません。\nあまりにも不便なので自作でもしようかと思ったのですが既にパッケージとして存在していました。\n$ sudo apt-get install nautilus-open-terminal 一度ログアウトして、再ログインすると使えるようになります。\nちなみに自分でメニューを作成する場合はnautilus-actionsを入れます。\n$ sudo apt-get install nautilus-actions [メインメニュー] → [システム] → [設定] → [Nautilus アクションの設定] で新規アクションを設定できます。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2007/04/05/meld.html",
                "title": "SubversionとGUI差分ツール（Meld）を組み合わせてみる",
                "section": "post",
                "date" : "2007.04.05",
                "body": "MeldとはGUIで差分表示が出来るツールです。Shift_JIS、EUC-JP、UTF-8等の文字コードに対応し、インターフェースも日本語化されていて使い勝手は上々です。単体でもSubversionに対応しているようですが、ここではsvn diff用の外部ツールに設定をしてみます。\nMeldをインストール DebianやUbuntuの場合はパッケージ化されているので導入は簡単です。\n$ sudo apt-get install meld 日本語を含むファイルを扱う場合は同時にpython-japanese-codecsもインストールしておくと良いでしょう。\nSubversionの設定 基本的には/etc/subversion/config内のdiff-cmdの値を編集すればいいのですが、diff-cmdにはファイル名のみで引数を設定出来ないようです。ですので、meldを呼び出すためのシェルスクリプトをあらかじめ作っておく必要があります。\n#!/bin/sh  # 外部Diffプログラム DIFF=\u0026#34;meld\u0026#34; # 引数の指定 LEFT=${6} RIGHT=${7} $DIFF $LEFT $RIGHT \u0026amp; こんな内容のファイルをどこか適当な場所に保存し、chmod +xで実行権限を与えておきます。\n次に/etc/subversion/configを開き、\n# diff-cmd = diff_program (diff, gdiff, etc.) diff-cmd = 上で作ったファイルのフルパス と、diff-cmdの値を書き換えて保存します。これでsvn diffで呼び出されるツールがmeldに切り替わります。\n注意点 多数のファイルを編集していて、その親ディレクトリでファイル名を指定せずにsvn diffとやるとファイル数分のMeldが立ち上がります…\nあとsvn-diff.vimをすでに導入している方はやらないほうがいいでしょう。\n"
            }
        
    ,
        
            {
                "ref": "https://blog.dakatsuka.jp/2007/04/04/ubuntu-feisty.html",
                "title": "Ubuntu Feistyのインストール",
                "section": "post",
                "date" : "2007.04.04",
                "body": "サブで使用しているノートPC（NEC LaVie G Type J）にUbuntu 7.04βを入れたのでそのメモ。\nマシンスペックはこんな感じです。二世代ほど前のB5ノートです。\n   CPU MEM HDD GPU     Pentium-M 1.2GHz 1.25G 80GB Intel 915GM    ではインストール LiveCDをドライブに挿入してPCを起動させます。無事に起動したらまずGNOMEターミナルを開いて\nsudo apt-get install gparted とタイプしてGNOME Partition Editorをインストールします。NICが認識されていてDHCPな環境ならばサクっと入ります。というかEdgyにはデフォルトで入っていたのに何故外されたのでしょうか…不思議です。\n私はgpartedを使って以下のようにパーティションを切りました。ReiserFSなのは私の好みです。普通はext3で問題ないと思います。\n   Mount Point Size FS     /boot 100MB ReiserFS   / 12GB ReiserFS   /home 65GB ReiserFS   swap 2GG linux-swap    後はデスクトップにあるInstallアイコンをダブルクリックして、ウィザードに従って進めていくだけでインストールが終わります。簡単すぎる…\nインストール後の環境設定などはまた後日ということで。\n"
            }
        
    
]